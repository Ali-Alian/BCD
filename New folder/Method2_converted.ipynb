{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1189f5ec",
   "metadata": {},
   "source": [
    "# Method2 converted to Method1 structure\n",
    "\n",
    "This notebook contains Method2 logic restructured to follow the Method1 cell layout.\n",
    "\n",
    "**Notes:**\n",
    "- GLCM features are computed first, then LBP, then intensity stats.\n",
    "- Pipelines and GroupKFold usage are included as in Method1 structure.\n",
    "- Run cells sequentially.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c67429ce-e063-4668-814b-27ff260a79de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.2-cp313-cp313-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.22.0 in e:\\university\\rbcd\\bcd\\bcd\\venv\\lib\\site-packages (from scikit-learn) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.8.0 in e:\\university\\rbcd\\bcd\\bcd\\venv\\lib\\site-packages (from scikit-learn) (1.16.2)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.7.2-cp313-cp313-win_amd64.whl (8.7 MB)\n",
      "   ---------------------------------------- 0.0/8.7 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.8/8.7 MB 4.6 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 1.8/8.7 MB 4.9 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 3.1/8.7 MB 5.6 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 4.5/8.7 MB 5.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 5.8/8.7 MB 5.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 6.8/8.7 MB 6.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 7.9/8.7 MB 5.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 8.4/8.7 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.7/8.7 MB 5.2 MB/s eta 0:00:00\n",
      "Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.5.2 scikit-learn-1.7.2 threadpoolctl-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "797f79c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell: imports\n",
    "import os, math, time, pickle, json\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import skew\n",
    "from skimage.feature import local_binary_pattern, graycomatrix, graycoprops\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GroupKFold, GridSearchCV, GroupShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, recall_score, roc_auc_score, confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea690eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell: Metadata & helpers\n",
    "def read_metadata(meta_path):\n",
    "    # robust whitespace-delimited read; uppercase column names\n",
    "    df = pd.read_csv(meta_path, delim_whitespace=True, dtype=str)\n",
    "    df.columns = [c.strip().upper() for c in df.columns]\n",
    "    # try known label columns\n",
    "    if 'SEVERITY' in df.columns:\n",
    "        df['CANCER'] = df['SEVERITY'].map({'B':1, 'M':1}).fillna(0).astype(int)\n",
    "    elif 'CLASS' in df.columns:\n",
    "        df['CANCER'] = df['CLASS'].map({'B':1, 'M':1}).fillna(0).astype(int)\n",
    "    else:\n",
    "        # fallback: if a numeric label column exists, try to use it\n",
    "        for col in ['LABEL', 'DIAGNOSIS', 'PATHOLOGY']:\n",
    "            if col in df.columns:\n",
    "                try:\n",
    "                    df['CANCER'] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
    "                    break\n",
    "                except Exception:\n",
    "                    pass\n",
    "        if 'CANCER' not in df.columns:\n",
    "            raise ValueError(\"Cannot find SEVERITY/CLASS or equivalent label column in metadata.\")\n",
    "    # numeric conversions\n",
    "    for c in ['RADIUS','X','Y']:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "        else:\n",
    "            df[c] = pd.NA\n",
    "    # patient id inference from REFNUM (e.g., mdb001/mdb002 -> patient grouping)\n",
    "    def _ref_to_patient(ref):\n",
    "        try:\n",
    "            s = str(ref)\n",
    "            digits = ''.join(ch for ch in s if ch.isdigit())\n",
    "            if digits == '':\n",
    "                return None\n",
    "            n = int(digits)\n",
    "            return ((n-1)//2) + 1\n",
    "        except Exception:\n",
    "            return None\n",
    "    if 'REFNUM' in df.columns:\n",
    "        df['patient_id'] = df['REFNUM'].map(_ref_to_patient)\n",
    "    else:\n",
    "        df['patient_id'] = None\n",
    "    return df\n",
    "\n",
    "def preprocess_img(img):\n",
    "    # CLAHE equalization; expects grayscale uint8 input\n",
    "    if img is None:\n",
    "        return None\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    return clahe.apply(img)\n",
    "\n",
    "def roi_from_row(img_eq, row, image_size=1024, median_radius=48, min_side=32):\n",
    "    # Return square ROI; if lesion coords available use them, else center crop using median_radius\n",
    "    label = int(row['CANCER']) if 'CANCER' in row else 0\n",
    "    x = row.get('X', None); y = row.get('Y', None); r = row.get('RADIUS', None)\n",
    "    H, W = img_eq.shape\n",
    "    if label == 1 and pd.notna(x) and pd.notna(y) and pd.notna(r):\n",
    "        cx = int(x)\n",
    "        cy = int(image_size - float(y))  # convert MIAS bottom-left -> top-left\n",
    "        radius = int(r)\n",
    "        x0 = max(0, cx-radius); x1 = min(W, cx+radius)\n",
    "        y0 = max(0, cy-radius); y1 = min(H, cy+radius)\n",
    "        roi = img_eq[y0:y1, x0:x1]\n",
    "        if roi.size == 0:\n",
    "            roi = img_eq.copy()\n",
    "    else:\n",
    "        radius = int(median_radius)\n",
    "        cx, cy = W//2, H//2\n",
    "        x0 = max(0, cx-radius); x1 = min(W, cx+radius)\n",
    "        y0 = max(0, cy-radius); y1 = min(H, cy+radius)\n",
    "        roi = img_eq[y0:y1, x0:x1]\n",
    "    # pad if too small\n",
    "    h,w = roi.shape\n",
    "    if h < min_side or w < min_side:\n",
    "        top = max(0, (min_side-h)//2); bottom = max(0, min_side-h-top)\n",
    "        left = max(0, (min_side-w)//2); right = max(0, min_side-w-left)\n",
    "        roi = cv2.copyMakeBorder(roi, top, bottom, left, right, cv2.BORDER_REFLECT)\n",
    "    return roi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84d87bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell: Feature extraction functions (GLCM first, then LBP, then intensity stats)\n",
    "def compute_glcm_features(roi, distances=(1,), angles=(0, np.pi/4, np.pi/2, 3*np.pi/4), levels=32):\n",
    "    roi_q = (roi / (256.0/levels)).astype(np.uint8)\n",
    "    glcm = graycomatrix(roi_q, distances=list(distances), angles=list(angles), levels=levels, symmetric=True, normed=True)\n",
    "    props = ['contrast','dissimilarity','homogeneity','energy','correlation']\n",
    "    feats = [float(graycoprops(glcm, p).mean()) for p in props]\n",
    "    return np.array(feats, dtype=float)\n",
    "\n",
    "def compute_lbp_hist(roi, P=8, radii=(1,3), n_bins=59):\n",
    "    feats = []\n",
    "    for R in radii:\n",
    "        lbp = local_binary_pattern(roi, P, R, method='uniform')\n",
    "        hist, _ = np.histogram(lbp.ravel(), bins=n_bins, range=(0, n_bins))\n",
    "        s = hist.sum()\n",
    "        if s == 0:\n",
    "            feats.extend([0.0]*n_bins)\n",
    "        else:\n",
    "            feats.extend((hist.astype(float)/s).tolist())\n",
    "    return np.array(feats, dtype=float)\n",
    "\n",
    "def intensity_stats(roi):\n",
    "    return np.array([float(roi.mean()), float(roi.std()), float(roi.min()), float(roi.max())], dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02aace29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell: convert helper and sample plotting utility\n",
    "def convert(o):\n",
    "    if isinstance(o, (np.integer,)):\n",
    "        return int(o)\n",
    "    if isinstance(o, (np.floating,)):\n",
    "        return float(o)\n",
    "    if isinstance(o, (np.ndarray,)):\n",
    "        return o.tolist()\n",
    "    return str(o)\n",
    "\n",
    "def plot_sample_rois(sample_rois, outpath):\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig = plt.figure(figsize=(10,4))\n",
    "    for idx, (ref, lab, grp, roi_img) in enumerate(sample_rois):\n",
    "        ax = fig.add_subplot(2,3, idx+1)\n",
    "        ax.imshow(roi_img, cmap='gray'); ax.set_title(f\"{ref} L={lab} G={grp}\"); ax.axis('off')\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(outpath)\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d394468",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alima\\AppData\\Local\\Temp\\ipykernel_17284\\1157845512.py:4: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(meta_path, delim_whitespace=True, dtype=str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Metadata rows: 324\n",
      "[INFO] median_radius: 43\n",
      "[INFO] Found images: 324\n",
      "[INFO] Extracted features shape: (324, 127)\n",
      "Label distribution: Counter({np.int64(0): 207, np.int64(1): 117})\n",
      "[INFO] Saved features.pkl\n",
      "[INFO] Saved sample_rois.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cell: Feature extraction loop (run this cell to extract features and save features.pkl)\n",
    "# Edit args below for paths and sizes if needed (these match Method1 CLI names)\n",
    "class Args:\n",
    "    images = \"all-mias\"\n",
    "    meta = \"data2.txt\"\n",
    "    outdir = \"results_method2\"\n",
    "    target_size = 128\n",
    "    min_side = 32\n",
    "    image_size = 1024\n",
    "    P = 8\n",
    "    lbp_radii = [1,3]\n",
    "    lbp_bins = 59\n",
    "    glcm_distances = [1]\n",
    "    glcm_levels = 32\n",
    "    select_k = 100\n",
    "    rf_estimators = 300\n",
    "    n_permutations = 200\n",
    "    perm_test_holdout_fraction = 0.2\n",
    "    n_jobs = -1\n",
    "    random_state = 42\n",
    "\n",
    "args = Args()\n",
    "\n",
    "os.makedirs(args.outdir, exist_ok=True)\n",
    "\n",
    "df = read_metadata(args.meta)\n",
    "print(\"[INFO] Metadata rows:\", len(df))\n",
    "radii = pd.to_numeric(df['RADIUS'], errors='coerce').dropna()\n",
    "median_radius = int(radii.median()) if radii.size>0 else 48\n",
    "print(\"[INFO] median_radius:\", median_radius)\n",
    "\n",
    "images = sorted([f for f in os.listdir(args.images) if f.lower().endswith('.pgm')])\n",
    "print(\"[INFO] Found images:\", len(images))\n",
    "\n",
    "features = []\n",
    "labels = []\n",
    "groups = []\n",
    "sample_rois = []\n",
    "\n",
    "for fname in images:\n",
    "    ref = os.path.splitext(fname)[0]\n",
    "    row = df[df['REFNUM'] == ref]\n",
    "    if row.empty:\n",
    "        # debug info: no metadata row\n",
    "        # print(f\"[DEBUG] No metadata for {ref}\")\n",
    "        continue\n",
    "    row = row.iloc[0]\n",
    "    img_path = os.path.join(args.images, fname)\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        print(f\"[WARN] cannot read {img_path}, skipping\")\n",
    "        continue\n",
    "    img_eq = preprocess_img(img)\n",
    "    if img_eq is None:\n",
    "        print(f\"[WARN] preprocessed image too small: {img_path}\")\n",
    "        continue\n",
    "    roi = roi_from_row(img_eq, row, image_size=args.image_size, median_radius=median_radius, min_side=args.min_side)\n",
    "    roi_resized = cv2.resize(roi, (args.target_size, args.target_size), interpolation=cv2.INTER_AREA)\n",
    "    # compute features: GLCM first, then LBP, then intensity\n",
    "    glcm_feats = compute_glcm_features(roi_resized, distances=tuple(args.glcm_distances), angles=(0, math.pi/4, math.pi/2, 3*math.pi/4), levels=args.glcm_levels)\n",
    "    lbp_feats = compute_lbp_hist(roi_resized, P=args.P, radii=tuple(args.lbp_radii), n_bins=args.lbp_bins)\n",
    "    int_feats = intensity_stats(roi_resized)\n",
    "    feat_vec = np.concatenate([glcm_feats, lbp_feats, int_feats]).astype(float)\n",
    "    features.append(feat_vec)\n",
    "    labels.append(int(row['CANCER']))\n",
    "    groups.append(row['patient_id'])\n",
    "    if len(sample_rois) < 6:\n",
    "        sample_rois.append((ref, int(row['CANCER']), row['patient_id'], roi_resized))\n",
    "\n",
    "X = np.vstack(features) if len(features)>0 else np.zeros((0, args.lbp_bins*len(args.lbp_radii) + 5))\n",
    "y = np.array(labels, dtype=int)\n",
    "groups_arr = np.array(groups)\n",
    "print(\"[INFO] Extracted features shape:\", X.shape)\n",
    "print(\"Label distribution:\", Counter(y))\n",
    "\n",
    "with open(os.path.join(args.outdir, \"features.pkl\"), \"wb\") as f:\n",
    "    pickle.dump({\"X\": X, \"y\": y, \"groups\": groups_arr, \"cfg\": vars(args)}, f)\n",
    "print(\"[INFO] Saved features.pkl\")\n",
    "\n",
    "# save sample rois preview\n",
    "plot_sample_rois(sample_rois, os.path.join(args.outdir, \"sample_rois.png\"))\n",
    "print(\"[INFO] Saved sample_rois.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66346653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Running GroupKFold with n_splits = 5\n",
      "[INFO] Outer fold 1: train=258 test=66\n",
      "[FOLD 1][rf] acc=0.909 rec=0.739 auc=0.935\n",
      "[FOLD 1][svm] acc=0.909 rec=0.739 auc=0.913\n",
      "[INFO] Outer fold 2: train=258 test=66\n",
      "[FOLD 2][rf] acc=0.894 rec=0.750 auc=0.928\n",
      "[FOLD 2][svm] acc=0.879 rec=0.714 auc=0.896\n",
      "[INFO] Outer fold 3: train=260 test=64\n",
      "[FOLD 3][rf] acc=0.859 rec=0.667 auc=0.965\n",
      "[FOLD 3][svm] acc=0.891 rec=0.708 auc=0.931\n",
      "[INFO] Outer fold 4: train=260 test=64\n",
      "[FOLD 4][rf] acc=0.969 rec=0.895 auc=0.953\n",
      "[FOLD 4][svm] acc=0.922 rec=0.789 auc=0.958\n",
      "[INFO] Outer fold 5: train=260 test=64\n",
      "[FOLD 5][rf] acc=0.891 rec=0.739 auc=0.918\n",
      "[FOLD 5][svm] acc=0.844 rec=0.739 auc=0.870\n",
      "[INFO] saved report.json and final models\n",
      "{\n",
      "  \"n_samples\": 324,\n",
      "  \"n_features\": 127,\n",
      "  \"label_counts\": {\n",
      "    \"0\": 207,\n",
      "    \"1\": 117\n",
      "  },\n",
      "  \"unique_groups\": 162,\n",
      "  \"cv_rf\": {\n",
      "    \"mean_acc\": 0.9043560606060606,\n",
      "    \"std_acc\": 0.03602594344053369,\n",
      "    \"mean_rec\": 0.7579328756674295,\n",
      "    \"std_rec\": 0.07458530716073254,\n",
      "    \"mean_auc\": 0.9396991276906477\n",
      "  },\n",
      "  \"cv_svm\": {\n",
      "    \"mean_acc\": 0.8888257575757577,\n",
      "    \"std_acc\": 0.026976838197380355,\n",
      "    \"mean_rec\": 0.7380707202789581,\n",
      "    \"std_rec\": 0.02861660141617468,\n",
      "    \"mean_auc\": 0.9134860248447204\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cell: Training, nested group-aware CV and final model fit\n",
    "# Assumes features.pkl produced by previous cell\n",
    "with open(os.path.join(args.outdir, \"features.pkl\"), \"rb\") as f:\n",
    "    dd = pickle.load(f)\n",
    "X = dd['X']; y = dd['y']; groups_arr = dd['groups']\n",
    "\n",
    "n_groups = len(set([g for g in groups_arr if g is not None]))\n",
    "n_splits = min(5, max(2, n_groups))\n",
    "print(\"[INFO] Running GroupKFold with n_splits =\", n_splits)\n",
    "\n",
    "outer_cv = GroupKFold(n_splits=n_splits)\n",
    "inner_cv = GroupKFold(n_splits=max(2, n_splits-1))\n",
    "\n",
    "selector = SelectKBest(mutual_info_classif, k=min(args.select_k, X.shape[1]))\n",
    "scaler = StandardScaler()\n",
    "rf_clf = RandomForestClassifier(n_estimators=args.rf_estimators, class_weight='balanced', random_state=args.random_state)\n",
    "svm_clf = SVC(probability=True, class_weight='balanced', random_state=args.random_state)\n",
    "\n",
    "pipelines = {\n",
    "    'rf': Pipeline([('scaler', scaler), ('select', selector), ('clf', rf_clf)]),\n",
    "    'svm': Pipeline([('scaler', scaler), ('select', selector), ('clf', svm_clf)])\n",
    "}\n",
    "\n",
    "rf_grid = {'clf__n_estimators': [args.rf_estimators]}\n",
    "svm_grid = {'clf__C': [1.0], 'clf__gamma': ['scale']}\n",
    "\n",
    "results = {k: [] for k in pipelines.keys()}\n",
    "best_models = {}\n",
    "\n",
    "fold = 0\n",
    "for train_idx, test_idx in outer_cv.split(X, y, groups_arr):\n",
    "    fold += 1\n",
    "    Xtr, Xte = X[train_idx], X[test_idx]\n",
    "    ytr, yte = y[train_idx], y[test_idx]\n",
    "    gtr, gte = groups_arr[train_idx], groups_arr[test_idx]\n",
    "    print(f\"[INFO] Outer fold {fold}: train={len(train_idx)} test={len(test_idx)}\")\n",
    "\n",
    "    for name, pipe in pipelines.items():\n",
    "        param_grid = rf_grid if name=='rf' else svm_grid\n",
    "        gs = GridSearchCV(pipe, param_grid, cv=inner_cv, scoring='roc_auc', n_jobs=args.n_jobs, refit=True)\n",
    "        gs.fit(Xtr, ytr, groups=gtr)\n",
    "        best = gs.best_estimator_\n",
    "        ypred = best.predict(Xte)\n",
    "        yprob = best.predict_proba(Xte)[:,1] if hasattr(best, \"predict_proba\") else best.decision_function(Xte)\n",
    "        acc = accuracy_score(yte, ypred)\n",
    "        rec = recall_score(yte, ypred, zero_division=0)\n",
    "        auc = roc_auc_score(yte, yprob) if len(np.unique(yte))>1 else float('nan')\n",
    "        cm = confusion_matrix(yte, ypred)\n",
    "        results[name].append({'fold': fold, 'acc': acc, 'recall': rec, 'auc': auc, 'cm': cm, 'best_params': gs.best_params_})\n",
    "        best_models[name] = gs.best_estimator_\n",
    "        print(f\"[FOLD {fold}][{name}] acc={acc:.3f} rec={rec:.3f} auc={auc:.3f}\")\n",
    "\n",
    "# summarize and save report\n",
    "summary = {'n_samples': int(X.shape[0]), 'n_features': int(X.shape[1]), 'label_counts': dict(pd.Series(y).value_counts()), 'unique_groups': int(len(set(groups_arr)))}\n",
    "for name in results:\n",
    "    arr_acc = np.array([r['acc'] for r in results[name]])\n",
    "    arr_rec = np.array([r['recall'] for r in results[name]])\n",
    "    arr_auc = np.array([r['auc'] for r in results[name] if not np.isnan(r['auc'])])\n",
    "    summary[f'cv_{name}'] = {'mean_acc': float(np.nanmean(arr_acc)), 'std_acc': float(np.nanstd(arr_acc)), 'mean_rec': float(np.nanmean(arr_rec)), 'std_rec': float(np.nanstd(arr_rec)), 'mean_auc': float(np.nanmean(arr_auc)) if arr_auc.size>0 else None}\n",
    "\n",
    "# refit final models on full data and save\n",
    "for name, model in best_models.items():\n",
    "    try:\n",
    "        model.fit(X, y)\n",
    "        with open(os.path.join(args.outdir, f\"final_model_{name}.pkl\"), \"wb\") as f:\n",
    "            pickle.dump(model, f)\n",
    "    except Exception as e:\n",
    "        print(\"Could not refit/save\", name, e)\n",
    "\n",
    "with open(os.path.join(args.outdir, \"report.json\"), \"w\") as f:\n",
    "    json.dump(summary, f, indent=2, default=convert)\n",
    "\n",
    "print(\"[INFO] saved report.json and final models\")\n",
    "print(json.dumps(summary, indent=2, default=convert))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc73e955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Permutation real_auc: 1.0 pvalue: 0.004975124378109453\n",
      "[INFO] saved perm_scores_sample.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cell: Permutation testing (group-wise). This uses a held-out group split.\n",
    "with open(os.path.join(args.outdir, \"features.pkl\"), \"rb\") as f:\n",
    "    dd = pickle.load(f)\n",
    "X = dd['X']; y = dd['y']; groups_arr = dd['groups']\n",
    "\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=args.perm_test_holdout_fraction, random_state=args.random_state)\n",
    "train_idx_perm, test_idx_perm = next(gss.split(X, y, groups_arr))\n",
    "Xtr_perm, Xte_perm = X[train_idx_perm], X[test_idx_perm]\n",
    "ytr_perm, yte_perm = y[train_idx_perm], y[test_idx_perm]\n",
    "gtr_perm, gte_perm = groups_arr[train_idx_perm], groups_arr[test_idx_perm]\n",
    "\n",
    "# Load final RF (if saved) or train fresh\n",
    "rf_path = os.path.join(args.outdir, \"final_model_rf.pkl\")\n",
    "if os.path.exists(rf_path):\n",
    "    with open(rf_path, \"rb\") as f:\n",
    "        rf_model = pickle.load(f)\n",
    "else:\n",
    "    rf_model = RandomForestClassifier(n_estimators=args.rf_estimators, class_weight='balanced', random_state=args.random_state)\n",
    "    rf_model.fit(Xtr_perm, ytr_perm)\n",
    "\n",
    "if hasattr(rf_model, \"predict_proba\"):\n",
    "    yprob = rf_model.predict_proba(Xte_perm)[:,1]\n",
    "else:\n",
    "    yprob = rf_model.decision_function(Xte_perm)\n",
    "\n",
    "real_auc = roc_auc_score(yte_perm, yprob) if len(np.unique(yte_perm))>1 else float('nan')\n",
    "perm_scores = []\n",
    "n_perm = args.n_permutations\n",
    "for i in range(n_perm):\n",
    "    # permute labels at the group level\n",
    "    perm_groups = np.unique(gtr_perm)\n",
    "    perm_map = np.random.permutation(perm_groups)\n",
    "    group_to_label = {g: int(pd.Series(ytr_perm[gtr_perm==g]).mode().iloc[0]) for g in perm_groups}\n",
    "    # create a permuted label vector for training by shuffling group labels\n",
    "    permuted_group_labels = np.random.permutation([group_to_label[g] for g in perm_groups])\n",
    "    ytr_p = ytr_perm.copy()\n",
    "    for g, lab in zip(perm_groups, permuted_group_labels):\n",
    "        ytr_p[gtr_perm==g] = lab\n",
    "    # fit clone\n",
    "    rf_clone = RandomForestClassifier(n_estimators=args.rf_estimators, class_weight='balanced', random_state=args.random_state)\n",
    "    rf_clone.fit(Xtr_perm, ytr_p)\n",
    "    try:\n",
    "        prob_p = rf_clone.predict_proba(Xte_perm)[:,1]\n",
    "        auc_p = roc_auc_score(yte_perm, prob_p) if len(np.unique(yte_perm))>1 else float('nan')\n",
    "    except:\n",
    "        auc_p = float('nan')\n",
    "    perm_scores.append(auc_p)\n",
    "\n",
    "pvalue = (np.sum(np.array(perm_scores) >= real_auc) + 1) / (len(perm_scores) + 1)\n",
    "print(\"[INFO] Permutation real_auc:\", real_auc, \"pvalue:\", pvalue)\n",
    "# Save sample of permutation scores\n",
    "with open(os.path.join(args.outdir, \"perm_scores_sample.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(perm_scores[:min(1000,len(perm_scores))], f)\n",
    "print(\"[INFO] saved perm_scores_sample.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40d50c2-0c90-415a-8d97-e4de624b979d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b0c0c1-4020-459b-8d33-208aaf5ad5b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ec599ff-ad63-4d81-8a8e-53b7f023c695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] groups_arr type: <class 'numpy.ndarray'>, shape: (324,)\n",
      "[INFO] Held-out train samples: 258, test samples: 66\n",
      "[INFO] Unique train groups: 129, Unique test groups: 33\n",
      "[INFO] Selected best_models['rf']\n",
      "\n",
      "=== Held-out evaluation: Selected Model ===\n",
      "Accuracy: 0.8788\n",
      "Recall: 0.7917\n",
      "AUC: 0.9330357142857143\n",
      "Confusion Matrix:\n",
      " [[39  3]\n",
      " [ 5 19]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91        42\n",
      "           1       0.86      0.79      0.83        24\n",
      "\n",
      "    accuracy                           0.88        66\n",
      "   macro avg       0.88      0.86      0.87        66\n",
      "weighted avg       0.88      0.88      0.88        66\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Held-out evaluation (robust) ---\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import classification_report, confusion_matrix, recall_score, accuracy_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Ensure X, y, groups (or groups_arr) exist in the notebook\n",
    "# Use existing variable names if different (e.g., groups_arr)\n",
    "try:\n",
    "    # prefer existing groups_arr if present\n",
    "    groups_arr = globals().get('groups_arr', globals().get('groups', None))\n",
    "    if groups_arr is None:\n",
    "        raise NameError(\"No 'groups' or 'groups_arr' variable found. Please run feature extraction cell first.\")\n",
    "    # convert to numpy array if needed\n",
    "    if isinstance(groups_arr, list):\n",
    "        groups_arr = np.array(groups_arr)\n",
    "    elif hasattr(groups_arr, \"values\"):  # pandas Series\n",
    "        groups_arr = groups_arr.values\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Error preparing groups array: {e}\")\n",
    "\n",
    "print(f\"[INFO] groups_arr type: {type(groups_arr)}, shape: {getattr(groups_arr,'shape',None)}\")\n",
    "\n",
    "# Create a patient-wise held-out split\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.20, random_state=42)\n",
    "train_idx, test_idx = next(gss.split(X, y, groups_arr))\n",
    "\n",
    "Xtr, Xte = X[train_idx], X[test_idx]\n",
    "ytr, yte = y[train_idx], y[test_idx]\n",
    "gtr, gte = groups_arr[train_idx], groups_arr[test_idx]\n",
    "\n",
    "print(f\"[INFO] Held-out train samples: {len(train_idx)}, test samples: {len(test_idx)}\")\n",
    "print(f\"[INFO] Unique train groups: {len(set(gtr))}, Unique test groups: {len(set(gte))}\")\n",
    "\n",
    "# Select a model from best_models (robust)\n",
    "chosen_model = None\n",
    "if 'best_models' in globals():\n",
    "    bm = globals()['best_models']\n",
    "    # dict (e.g., {'rf': model, 'svm': model})\n",
    "    if isinstance(bm, dict):\n",
    "        if 'rf' in bm:\n",
    "            chosen_model = bm['rf']\n",
    "            print(\"[INFO] Selected best_models['rf']\")\n",
    "        else:\n",
    "            # pick first model in dict\n",
    "            first_key = next(iter(bm.keys()))\n",
    "            chosen_model = bm[first_key]\n",
    "            print(f\"[INFO] Selected best_models['{first_key}']\")\n",
    "    elif isinstance(bm, list):\n",
    "        if len(bm) > 0:\n",
    "            chosen_model = bm[-1]\n",
    "            print(\"[INFO] Selected last model from best_models list\")\n",
    "# If nothing found, fallback to fresh RF\n",
    "if chosen_model is None:\n",
    "    print(\"[WARN] best_models not found or empty â€” falling back to a fresh RandomForest.\")\n",
    "    chosen_model = RandomForestClassifier(n_estimators=300, class_weight='balanced', random_state=42)\n",
    "\n",
    "# Fit chosen model on training partition (refit to be safe)\n",
    "chosen_model.fit(Xtr, ytr)\n",
    "\n",
    "# Evaluate\n",
    "ypred = chosen_model.predict(Xte)\n",
    "if hasattr(chosen_model, \"predict_proba\"):\n",
    "    yprob = chosen_model.predict_proba(Xte)[:,1]\n",
    "elif hasattr(chosen_model, \"decision_function\"):\n",
    "    yprob = chosen_model.decision_function(Xte)\n",
    "else:\n",
    "    yprob = None\n",
    "\n",
    "acc = accuracy_score(yte, ypred)\n",
    "rec = recall_score(yte, ypred, zero_division=0)\n",
    "cm = confusion_matrix(yte, ypred)\n",
    "auc = float('nan')\n",
    "if yprob is not None and len(np.unique(yte)) > 1:\n",
    "    try:\n",
    "        auc = roc_auc_score(yte, yprob)\n",
    "    except Exception as e:\n",
    "        print(\"[WARN] Could not compute AUC:\", e)\n",
    "\n",
    "print(\"\\n=== Held-out evaluation: Selected Model ===\")\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"Recall: {rec:.4f}\")\n",
    "print(f\"AUC: {auc}\")\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(yte, ypred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0bb36dbf-dbdf-4f2d-aebb-61371419d84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (324,)\n",
      "train_idx type: <class 'numpy.ndarray'> len: 258\n"
     ]
    }
   ],
   "source": [
    "print(type(groups_arr), getattr(groups_arr,'shape',None))\n",
    "print(\"train_idx type:\", type(train_idx), \"len:\", len(train_idx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743aa7c2-7849-451c-a86e-bc32472e4cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
