{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29de2276-7ca5-4f67-aba5-7196a654ae0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import albumentations as A\n",
    "from glob import glob # Used to easily find file paths\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e448a322-c346-47d9-ac01-86f24fe454f6",
   "metadata": {},
   "source": [
    "## CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a46a6816-7eb1-46f4-8806-4768dfbec542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REFNUM</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>RADIUS</th>\n",
       "      <th>CANCER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>REFNUM</td>\n",
       "      <td>X</td>\n",
       "      <td>Y</td>\n",
       "      <td>RADIUS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mdb001</td>\n",
       "      <td>535</td>\n",
       "      <td>425</td>\n",
       "      <td>197</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mdb002</td>\n",
       "      <td>522</td>\n",
       "      <td>280</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mdb003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mdb004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   REFNUM    X    Y  RADIUS  CANCER\n",
       "0  REFNUM    X    Y  RADIUS       0\n",
       "1  mdb001  535  425     197       1\n",
       "2  mdb002  522  280      69       1\n",
       "3  mdb003  NaN  NaN     NaN       0\n",
       "4  mdb004  NaN  NaN     NaN       0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data2.txt', sep='\\s+', \n",
    "                 names=['REFNUM','BG','CLASS','SEVERITY','X','Y','RADIUS'], na_values=[''])\n",
    "# Filter to your task (binary cancer detection)\n",
    "df['CANCER'] = df['SEVERITY'].apply(lambda x: 1 if x in ['B', 'M'] else 0)\n",
    "df = df[['REFNUM','X','Y','RADIUS','CANCER']]\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f797ca86-1ce8-4165-95fd-3393bbb80ee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REFNUM</th>\n",
       "      <th>BG</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>SEVERITY</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>RADIUS</th>\n",
       "      <th>CANCER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>REFNUM</td>\n",
       "      <td>BG</td>\n",
       "      <td>CLASS</td>\n",
       "      <td>SEVERITY</td>\n",
       "      <td>X</td>\n",
       "      <td>Y</td>\n",
       "      <td>RADIUS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mdb001</td>\n",
       "      <td>G</td>\n",
       "      <td>CIRC</td>\n",
       "      <td>B</td>\n",
       "      <td>535</td>\n",
       "      <td>425</td>\n",
       "      <td>197</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mdb002</td>\n",
       "      <td>G</td>\n",
       "      <td>CIRC</td>\n",
       "      <td>B</td>\n",
       "      <td>522</td>\n",
       "      <td>280</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mdb003</td>\n",
       "      <td>D</td>\n",
       "      <td>NORM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mdb004</td>\n",
       "      <td>D</td>\n",
       "      <td>NORM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   REFNUM  BG  CLASS  SEVERITY    X    Y  RADIUS  CANCER\n",
       "0  REFNUM  BG  CLASS  SEVERITY    X    Y  RADIUS       0\n",
       "1  mdb001   G   CIRC         B  535  425     197       1\n",
       "2  mdb002   G   CIRC         B  522  280      69       1\n",
       "3  mdb003   D   NORM       NaN  NaN  NaN     NaN       0\n",
       "4  mdb004   D   NORM       NaN  NaN  NaN     NaN       0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = ['REFNUM', 'BG', 'CLASS', 'SEVERITY', 'X', 'Y', 'RADIUS']\n",
    "df = pd.read_csv('data2.txt', sep=\"\\s+\", names=col_names, header=None)\n",
    "df['CANCER'] = df['SEVERITY'].apply(lambda x: 1 if x in ['B', 'M'] else 0)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad777b0-eef8-4c64-b46f-fb26c3598548",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a7d7fa7-35fa-4e81-9b3c-40b0b078c8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_labeling(img_files, txt_path):\n",
    "    full_data = []\n",
    "    cordinates = []\n",
    "    # count_cancer = 0\n",
    "    # img_coordinate = defaultdict(list)\n",
    "    \n",
    "    for i, filename in enumerate(sorted(os.listdir(img_files))): # Opens the image file and go throuth all the image \n",
    "        if filename.endswith(\".pgm\"): # display only if the image is pgm\n",
    "            image_path = os.path.join(img_files, filename) # Getting the Image path EX => all-mias\\mdb001.pgm\n",
    "            text = txt_file[i].strip() # spliting the data in the text file \n",
    "            pairing = {\"Image\": image_path, \"Text\": text} # putting both image and the text in the dictinory \n",
    "            full_data.append(pairing) # adding all the data to the list \n",
    "\n",
    "    for pairing in full_data:\n",
    "        txt_value = pairing['Text'] # ceperating the image with the text\n",
    "        img_value = pairing['Image']\n",
    "        \n",
    "        img = cv2.imread(img_value) # creating the array\n",
    "        txt_parts = txt_value.split() # spleting text in to multiple in array so to filter the data which they have the cordinates\n",
    "        \n",
    "        # Converting the image to GRAY and then to RGB and prepare for drawing\n",
    "        img_gray = cv2.imread(img_value, cv2.IMREAD_GRAYSCALE)  \n",
    "        img_rgb = cv2.cvtColor(img_gray, cv2.COLOR_GRAY2RGB)\n",
    "       \n",
    "        \n",
    "        # Cheking if the text line contain the cordinate or not\n",
    "        if len(txt_parts) == 7 and img is not None: \n",
    "            # Getting the cordinate for each image one by one \n",
    "\n",
    "            get_txt_data = txt_parts[4] + \" \" + txt_parts[5] + \" \" +txt_parts[6] # joining the X , Y , R\n",
    "            x, y, r = map(int, get_txt_data.split())\n",
    "            \n",
    "            y_adj = 1024 - y\n",
    "            cv2.circle(img_rgb, (x, y_adj), r, (0,255,0), 3)\n",
    "            \n",
    "            mask = np.zeros(img_rgb.shape[:2], dtype=np.uint8)\n",
    "            cv2.circle(mask, (x, y_adj), r, 255, -1)\n",
    "            roi = cv2.bitwise_and(img_rgb, img_rgb, mask=mask)\n",
    "\n",
    "            # plt.imshow(img_rgb, cmap='gray')\n",
    "            # plt.title(\"Example .pgm Image\")\n",
    "            # plt.axis('off')  # Hide axis ticks\n",
    "            # plt.show()\n",
    "\n",
    "# reading the Image file \n",
    "images_path = \"all-mias\"\n",
    "\n",
    "# reading the txt file \n",
    "txt_path = \"data2.txt\"\n",
    "with open(txt_path, \"r\") as file:\n",
    "    txt_file = file.readlines()[1:]\n",
    "\n",
    "data_labeling(images_path, txt_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2721e400-749e-4467-a227-4a8fbb40ee0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a80dd459-d460-4aa5-bb82-81488842eb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aa23147\\AppData\\Roaming\\Python\\Python310\\site-packages\\albumentations\\core\\validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training with Albumentations and tf.data pipeline...\n",
      "Epoch 1/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.6034 - auc: 0.4883 - loss: 0.6803 - val_accuracy: 0.6406 - val_auc: 0.5000 - val_loss: 0.6640\n",
      "Epoch 2/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.6195 - auc: 0.5697 - loss: 0.6650 - val_accuracy: 0.6406 - val_auc: 0.5000 - val_loss: 0.6554\n",
      "Epoch 3/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.6470 - auc: 0.4944 - loss: 0.6505 - val_accuracy: 0.6406 - val_auc: 0.5000 - val_loss: 0.6529\n",
      "Epoch 4/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.6527 - auc: 0.4970 - loss: 0.6472 - val_accuracy: 0.6406 - val_auc: 0.5000 - val_loss: 0.6533\n",
      "Epoch 5/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.6594 - auc: 0.5119 - loss: 0.6417 - val_accuracy: 0.6406 - val_auc: 0.5000 - val_loss: 0.6535\n",
      "Epoch 6/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.6220 - auc: 0.5511 - loss: 0.6669 - val_accuracy: 0.6406 - val_auc: 0.5000 - val_loss: 0.6531\n",
      "Epoch 7/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.6335 - auc: 0.5624 - loss: 0.6563 - val_accuracy: 0.6406 - val_auc: 0.5000 - val_loss: 0.6529\n",
      "Epoch 8/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.6235 - auc: 0.5339 - loss: 0.6639 - val_accuracy: 0.6406 - val_auc: 0.5652 - val_loss: 0.6529\n",
      "Epoch 9/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.6498 - auc: 0.4386 - loss: 0.6525 - val_accuracy: 0.6406 - val_auc: 0.5000 - val_loss: 0.6529\n",
      "Epoch 10/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.6734 - auc: 0.5868 - loss: 0.6289 - val_accuracy: 0.6406 - val_auc: 0.5000 - val_loss: 0.6529\n",
      "Epoch 11/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.6665 - auc: 0.4798 - loss: 0.6403 - val_accuracy: 0.6406 - val_auc: 0.5000 - val_loss: 0.6529\n",
      "Epoch 12/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.6417 - auc: 0.4513 - loss: 0.6562 - val_accuracy: 0.6406 - val_auc: 0.5000 - val_loss: 0.6529\n",
      "Epoch 13/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.6401 - auc: 0.4911 - loss: 0.6561 - val_accuracy: 0.6406 - val_auc: 0.5000 - val_loss: 0.6529\n",
      "Epoch 14/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.6541 - auc: 0.4536 - loss: 0.6517 - val_accuracy: 0.6406 - val_auc: 0.5122 - val_loss: 0.6529\n",
      "Epoch 15/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.5969 - auc: 0.5272 - loss: 0.6768 - val_accuracy: 0.6406 - val_auc: 0.5000 - val_loss: 0.6530\n",
      "Epoch 16/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.6625 - auc: 0.4968 - loss: 0.6405 - val_accuracy: 0.6406 - val_auc: 0.5000 - val_loss: 0.6529\n",
      "Epoch 17/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.6374 - auc: 0.5230 - loss: 0.6543 - val_accuracy: 0.6406 - val_auc: 0.5000 - val_loss: 0.6529\n",
      "Epoch 18/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.6325 - auc: 0.4081 - loss: 0.6614 - val_accuracy: 0.6406 - val_auc: 0.5000 - val_loss: 0.6530\n",
      "Epoch 19/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.6458 - auc: 0.5686 - loss: 0.6449 - val_accuracy: 0.6406 - val_auc: 0.5000 - val_loss: 0.6530\n",
      "Epoch 20/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.6668 - auc: 0.5326 - loss: 0.6356 - val_accuracy: 0.6406 - val_auc: 0.5000 - val_loss: 0.6530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "TRAIN_DIR = 'dataset_for_training/train/'\n",
    "VALIDATION_DIR = 'dataset_for_training/validation/'\n",
    "\n",
    "# --- Step 1: Define the Albumentations Transform Pipeline ---\n",
    "# This is where you define all your desired augmentations.\n",
    "# These will be applied to the training images only.\n",
    "# This is a powerful set of augmentations suitable for medical images.\n",
    "train_transform = A.Compose([\n",
    "    # Geometric transformations\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=15, p=0.7),\n",
    "    A.ElasticTransform(p=0.3, alpha=50, sigma=5),\n",
    "    A.Normalize(mean=[0.5], std=[0.5]),\n",
    "    A.GridDistortion(p=0.5),\n",
    "    \n",
    "    # Brightness and contrast transformations\n",
    "    A.RandomBrightnessContrast(\n",
    "    brightness_limit=(-0.2, 0.3),  # Range\n",
    "    contrast_limit=(-0.1, 0.1),    # Range\n",
    "    p=1.0\n",
    "    ),\n",
    "    A.CLAHE(p=0.8), # This is excellent for enhancing contrast in medical images\n",
    "    \n",
    "    # Noise and blur\n",
    "    A.GaussNoise(p=0.5),\n",
    "    A.Blur(blur_limit=3, p=0.5),\n",
    "    # A.ToTensorV2()\n",
    "])\n",
    "\n",
    "# For validation, we only need to resize and rescale. No random augmentation.\n",
    "validation_transform = A.Compose([\n",
    "    # Validation data should not be augmented randomly\n",
    "])\n",
    "\n",
    "\n",
    "# --- Step 2: Build the tf.data Pipeline (Replaces ImageDataGenerator) ---\n",
    "\n",
    "# First, get all the file paths and their corresponding labels.\n",
    "train_image_paths = glob(os.path.join(TRAIN_DIR, '*/*.png'))\n",
    "validation_image_paths = glob(os.path.join(VALIDATION_DIR, '*/*.png'))\n",
    "\n",
    "# Create labels from the folder names (0 for 'cancer', 1 for 'normal')\n",
    "# Note: Keras's flow_from_directory sorts class names alphabetically.\n",
    "# 'cancer' comes before 'normal', so Keras assigns it class 0.\n",
    "train_labels = [0 if 'cancer' in path else 1 for path in train_image_paths]\n",
    "validation_labels = [0 if 'cancer' in path else 1 for path in validation_image_paths]\n",
    "\n",
    "\n",
    "def load_and_preprocess_image(image_path, label):\n",
    "    \"\"\"Loads, decodes, and resizes an image.\"\"\"\n",
    "    # Read the image file\n",
    "    image = tf.io.read_file(image_path)\n",
    "    # Decode to a tensor. We specify 3 channels as the model expects it.\n",
    "    image = tf.io.decode_png(image, channels=3)\n",
    "    # Resize the image to the target size\n",
    "    image = tf.image.resize(image, [IMG_SIZE[0], IMG_SIZE[1]])\n",
    "    # Rescale pixel values to [0, 1]\n",
    "    image = image / 255.0\n",
    "    return image, label\n",
    "\n",
    "def apply_augmentations(image, label, transform):\n",
    "    \"\"\"A wrapper function to apply Albumentations transforms within TensorFlow.\"\"\"\n",
    "    def augment(img):\n",
    "        aug_data = transform(image=img.numpy())\n",
    "        return aug_data['image']\n",
    "\n",
    "    # Use tf.py_function to run the python-based Albumentations library\n",
    "    # The [image] and Tout=[tf.float32] define the input and output types.\n",
    "    aug_image = tf.py_function(func=augment, inp=[image], Tout=tf.float32)\n",
    "    # Make sure the output shape is set correctly\n",
    "    aug_image.set_shape([IMG_SIZE[0], IMG_SIZE[1], 3])\n",
    "    return aug_image, label\n",
    "\n",
    "\n",
    "# Create the final training dataset object\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_image_paths, train_labels))\n",
    "train_dataset = (\n",
    "    train_dataset.shuffle(buffer_size=len(train_image_paths)) # Shuffle the data\n",
    "    .map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE) # Load and resize\n",
    "    .map(lambda x, y: apply_augmentations(x, y, train_transform), num_parallel_calls=tf.data.AUTOTUNE) # Apply augmentations\n",
    "    .batch(BATCH_SIZE) # Create batches\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE) # Pre-load the next batch for performance\n",
    ")\n",
    "\n",
    "# Create the final validation dataset object (without augmentation)\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((validation_image_paths, validation_labels))\n",
    "validation_dataset = (\n",
    "    validation_dataset\n",
    "    .map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE) # Just load and resize\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "# --- The rest of your code is now UNCHANGED ---\n",
    "\n",
    "# --- 3. Build the Model with Transfer Learning (Unchanged) ---\n",
    "base_model = tf.keras.applications.EfficientNetB0(weights='imagenet', include_top=False, input_shape=(*IMG_SIZE, 3))\n",
    "base_model.trainable = False\n",
    "x = base_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "predictions = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "model = tf.keras.Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# --- 4. Compile the Model (Unchanged) ---\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    ")\n",
    "\n",
    "# --- 5. Train the Model (Updated to use the new datasets) ---\n",
    "print(\"Starting model training with Albumentations and tf.data pipeline...\")\n",
    "history = model.fit(\n",
    "    train_dataset, # <-- Use the new training dataset\n",
    "    epochs=20,\n",
    "    validation_data=validation_dataset # <-- Use the new validation dataset\n",
    ")\n",
    "\n",
    "# --- 6. Save your trained model (Unchanged) ---\n",
    "model.save('breast_cancer_classifier_v2_albumentations.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0773c83-0968-46d0-8290-f4586a2bab6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the feature extraction model...\n",
      "Extracting features from the training set...\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1s/step\n",
      "Extracting features from the validation set...\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step\n",
      "Shape of training features: (256, 1280)\n",
      "Shape of validation features: (64, 1280)\n",
      "\n",
      "Training the Random Forest model...\n",
      "Random Forest training complete.\n",
      "\n",
      "Evaluating the model on the validation set...\n",
      "Validation Accuracy: 100.00%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  cancer (0)       1.00      1.00      1.00        23\n",
      "  normal (1)       1.00      1.00      1.00        41\n",
      "\n",
      "    accuracy                           1.00        64\n",
      "   macro avg       1.00      1.00      1.00        64\n",
      "weighted avg       1.00      1.00      1.00        64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Configuration ---\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "TRAIN_DIR = 'dataset_for_training/train/'\n",
    "VALIDATION_DIR = 'dataset_for_training/validation/'\n",
    "\n",
    "# --- Step 1: Create tf.data Datasets (Same as before) ---\n",
    "# We use the same high-performance pipeline to load our images.\n",
    "# This part is crucial for efficiently processing all images.\n",
    "\n",
    "def load_and_preprocess_image(image_path, label):\n",
    "    \"\"\"Loads, decodes, and resizes an image.\"\"\"\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.io.decode_png(image, channels=3)\n",
    "    image = tf.image.resize(image, [IMG_SIZE[0], IMG_SIZE[1]])\n",
    "    image = image / 255.0  # Rescale to [0, 1]\n",
    "    return image, label\n",
    "\n",
    "# Get file paths and labels\n",
    "train_image_paths = sorted(glob(os.path.join(TRAIN_DIR, '*/*.png')))\n",
    "validation_image_paths = sorted(glob(os.path.join(VALIDATION_DIR, '*/*.png')))\n",
    "\n",
    "# Keras assigns labels alphabetically: 'cancer' -> 0, 'normal' -> 1\n",
    "train_labels = [0 if 'cancer' in path else 1 for path in train_image_paths]\n",
    "validation_labels = [0 if 'cancer' in path else 1 for path in validation_image_paths]\n",
    "\n",
    "# Create the dataset objects\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_image_paths, train_labels))\n",
    "train_dataset = (\n",
    "    train_dataset\n",
    "    .map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((validation_image_paths, validation_labels))\n",
    "validation_dataset = (\n",
    "    validation_dataset\n",
    "    .map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "# --- Step 2: Build the Feature Extraction Model ---\n",
    "# We load the CNN base but add a pooling layer to get a flat feature vector.\n",
    "# This is NOT a classification model; its job is to turn an image into a list of numbers.\n",
    "print(\"Building the feature extraction model...\")\n",
    "base_model = tf.keras.applications.EfficientNetB0(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(*IMG_SIZE, 3),\n",
    "    pooling='avg' # Use 'avg' pooling to get a 1D feature vector per image\n",
    ")\n",
    "base_model.trainable = False # It's just a feature extractor, no training needed\n",
    "\n",
    "# Our new feature_extractor_model is the base_model itself\n",
    "feature_extractor_model = base_model\n",
    "\n",
    "\n",
    "# --- Step 3: Extract Features from All Images ---\n",
    "# We use the model's .predict() method to run all our images through it.\n",
    "# This will give us the tabular data needed for the Random Forest.\n",
    "print(\"Extracting features from the training set...\")\n",
    "X_train_features = feature_extractor_model.predict(train_dataset)\n",
    "\n",
    "print(\"Extracting features from the validation set...\")\n",
    "X_val_features = feature_extractor_model.predict(validation_dataset)\n",
    "\n",
    "# The labels are the same as before\n",
    "y_train = np.array(train_labels)\n",
    "y_val = np.array(validation_labels)\n",
    "\n",
    "print(f\"Shape of training features: {X_train_features.shape}\")\n",
    "print(f\"Shape of validation features: {X_val_features.shape}\")\n",
    "\n",
    "\n",
    "# --- Step 4: Train the Random Forest Classifier ---\n",
    "# Now we switch to scikit-learn to use its Random Forest implementation.\n",
    "print(\"\\nTraining the Random Forest model...\")\n",
    "# n_estimators: The number of trees in the forest.\n",
    "# random_state: For reproducibility.\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "# .fit() trains the model on our extracted features and labels\n",
    "rf_model.fit(X_train_features, y_train)\n",
    "print(\"Random Forest training complete.\")\n",
    "\n",
    "\n",
    "# --- Step 5: Evaluate the Random Forest Model ---\n",
    "print(\"\\nEvaluating the model on the validation set...\")\n",
    "# Use the trained model to make predictions on the validation features\n",
    "predictions = rf_model.predict(X_val_features)\n",
    "\n",
    "# Compare the predictions to the true labels\n",
    "accuracy = accuracy_score(y_val, predictions)\n",
    "print(f\"Validation Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Print a detailed report (precision, recall, f1-score)\n",
    "print(\"\\nClassification Report:\")\n",
    "# target_names uses the original folder names for clarity\n",
    "print(classification_report(y_val, predictions, target_names=['cancer (0)', 'normal (1)']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9667208e-1de6-41ca-ad8d-c197c2ee058d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dataset_for_training/validation\\\\cancer\\\\mdb021_roi.png', 'dataset_for_training/validation\\\\cancer\\\\mdb032_roi.png', 'dataset_for_training/validation\\\\cancer\\\\mdb058_roi.png', 'dataset_for_training/validation\\\\cancer\\\\mdb081_roi.png', 'dataset_for_training/validation\\\\cancer\\\\mdb102_roi.png', 'dataset_for_training/validation\\\\cancer\\\\mdb115_roi.png', 'dataset_for_training/validation\\\\cancer\\\\mdb126_roi.png', 'dataset_for_training/validation\\\\cancer\\\\mdb152_roi.png', 'dataset_for_training/validation\\\\cancer\\\\mdb155_roi.png', 'dataset_for_training/validation\\\\cancer\\\\mdb163_roi.png', 'dataset_for_training/validation\\\\cancer\\\\mdb184_roi.png', 'dataset_for_training/validation\\\\cancer\\\\mdb186_roi.png', 'dataset_for_training/validation\\\\cancer\\\\mdb188_roi.png', 'dataset_for_training/validation\\\\cancer\\\\mdb193_roi.png', 'dataset_for_training/validation\\\\cancer\\\\mdb198_roi.png', 'dataset_for_training/validation\\\\cancer\\\\mdb207_roi.png', 'dataset_for_training/validation\\\\cancer\\\\mdb223_roi.png', 'dataset_for_training/validation\\\\cancer\\\\mdb231_roi.png', 'dataset_for_training/validation\\\\cancer\\\\mdb239_roi.png', 'dataset_for_training/validation\\\\cancer\\\\mdb240_roi.png', 'dataset_for_training/validation\\\\cancer\\\\mdb252_roi.png', 'dataset_for_training/validation\\\\cancer\\\\mdb314_roi.png', 'dataset_for_training/validation\\\\cancer\\\\mdb315_roi.png', 'dataset_for_training/validation\\\\normal\\\\mdb004_normal_patch.png', 'dataset_for_training/validation\\\\normal\\\\mdb027_normal_patch.png', 'dataset_for_training/validation\\\\normal\\\\mdb036_normal_patch.png', 'dataset_for_training/validation\\\\normal\\\\mdb037_normal_patch.png', 'dataset_for_training/validation\\\\normal\\\\mdb053_normal_patch.png', 'dataset_for_training/validation\\\\normal\\\\mdb067_normal_patch.png', 'dataset_for_training/validation\\\\normal\\\\mdb070_normal_patch.png', 'dataset_for_training/validation\\\\normal\\\\mdb073_normal_patch.png', 'dataset_for_training/validation\\\\normal\\\\mdb076_normal_patch.png', 'dataset_for_training/validation\\\\normal\\\\mdb079_normal_patch.png', 'dataset_for_training/validation\\\\normal\\\\mdb082_normal_patch.png', 'dataset_for_training/validation\\\\normal\\\\mdb088_normal_patch.png', 'dataset_for_training/validation\\\\normal\\\\mdb103_normal_patch.png', 'dataset_for_training/validation\\\\normal\\\\mdb109_normal_patch.png', 'dataset_for_training/validation\\\\normal\\\\mdb135_normal_patch.png', 'dataset_for_training/validation\\\\normal\\\\mdb136_normal_patch.png', 'dataset_for_training/validation\\\\normal\\\\mdb140_normal_patch.png', 'dataset_for_training/validation\\\\normal\\\\mdb154_normal_patch.png', 'dataset_for_training/validation\\\\normal\\\\mdb159_normal_patch.png', 'dataset_for_training/validation\\\\normal\\\\mdb161_normal_patch.png', 'dataset_for_training/validation\\\\normal\\\\mdb166_normal_patch.png', 'dataset_for_training/validation\\\\normal\\\\mdb168_normal_patch.png', 'dataset_for_training/validation\\\\normal\\\\mdb183_normal_patch.png', 'dataset_for_training/validation\\\\normal\\\\mdb194_normal_patch.png', 'dataset_for_training/validation\\\\normal\\\\mdb210_normal_patch.png', 'dataset_for_training/validation\\\\normal\\\\mdb215_normal_patch.png', 'dataset_for_training/validation\\\\normal\\\\mdb224_normal_patch.png', 'dataset_for_training/validation\\\\normal\\\\mdb254_normal_patch.png', 'dataset_for_training/validation\\\\normal\\\\mdb257_normal_patch.png', 'dataset_for_training/validation\\\\normal\\\\mdb263_normal_patch.png', 'dataset_for_training/validation\\\\normal\\\\mdb269_normal_patch.png', 'dataset_for_training/validation\\\\normal\\\\mdb281_normal_patch.png', 'dataset_for_training/validation\\\\normal\\\\mdb285_normal_patch.png', 'dataset_for_training/validation\\\\normal\\\\mdb292_normal_patch.png', 'dataset_for_training/validation\\\\normal\\\\mdb295_normal_patch.png', 'dataset_for_training/validation\\\\normal\\\\mdb301_normal_patch.png', 'dataset_for_training/validation\\\\normal\\\\mdb303_normal_patch.png', 'dataset_for_training/validation\\\\normal\\\\mdb308_normal_patch.png', 'dataset_for_training/validation\\\\normal\\\\mdb313_normal_patch.png', 'dataset_for_training/validation\\\\normal\\\\mdb319_normal_patch.png', 'dataset_for_training/validation\\\\normal\\\\mdb322_normal_patch.png']\n",
      "\n",
      "--- Predicting for image: mdb186_roi.png ---\n",
      "Extracting features from the image...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "Classifying features with Random Forest...\n",
      "\n",
      "============== PREDICTION RESULT ==============\n",
      "The model predicts this image is: 'cancer'\n",
      "Confidence score: 100.00%\n",
      "=============================================\n",
      "(For verification, the true label is: 'cancer')\n"
     ]
    }
   ],
   "source": [
    "# --- Step 6: Function to Predict a Single New Image ---\n",
    "# This function encapsulates the entire prediction pipeline for a new image.\n",
    "\n",
    "def predict_single_image(image_path, feature_extractor, rf_classifier):\n",
    "    \"\"\"\n",
    "    Loads, preprocesses, and predicts the class for a single image file.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): The file path to the new image.\n",
    "        feature_extractor (tf.keras.Model): The trained CNN feature extractor.\n",
    "        rf_classifier (RandomForestClassifier): The trained Random Forest model.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the predicted label name and the confidence score.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Predicting for image: {os.path.basename(image_path)} ---\")\n",
    "\n",
    "    # 1. Load and preprocess the image using the same steps as training\n",
    "    # The label is a placeholder since we don't know it yet.\n",
    "    image_tensor, _ = load_and_preprocess_image(image_path, -1)\n",
    "\n",
    "    # 2. Add a batch dimension. The model was trained on batches, so it\n",
    "    # expects an input shape of (1, 224, 224, 3) instead of (224, 224, 3).\n",
    "    image_batch = tf.expand_dims(image_tensor, axis=0)\n",
    "\n",
    "    # 3. Extract features using the CNN model\n",
    "    print(\"Extracting features from the image...\")\n",
    "    features = feature_extractor.predict(image_batch)\n",
    "\n",
    "    # 4. Make a prediction using the trained Random Forest model\n",
    "    print(\"Classifying features with Random Forest...\")\n",
    "    # .predict() gives the class (0 or 1)\n",
    "    prediction_code = rf_classifier.predict(features)[0]\n",
    "    # .predict_proba() gives the probability for each class\n",
    "    prediction_proba = rf_classifier.predict_proba(features)[0]\n",
    "\n",
    "    # 5. Interpret the results into human-readable format\n",
    "    # The order 'cancer', 'normal' is based on how the labels were assigned alphabetically.\n",
    "    class_names = ['cancer', 'normal']\n",
    "    predicted_label = class_names[prediction_code]\n",
    "    confidence = prediction_proba[prediction_code]\n",
    "\n",
    "    return predicted_label, confidence\n",
    "\n",
    "# --- Example of How to Use the Function ---\n",
    "# This code assumes `feature_extractor_model` and `rf_model` are already\n",
    "# trained and exist in memory from the script in the Canvas.\n",
    "\n",
    "# Let's pick an example image from your validation set to test.\n",
    "# Make sure this file exists. We'll use the 10th image as an example.\n",
    "example_image_path = validation_image_paths[11]\n",
    "print(validation_image_paths)\n",
    "\n",
    "# Call the prediction function\n",
    "predicted_class, confidence_score = predict_single_image(\n",
    "    image_path=example_image_path,\n",
    "    feature_extractor=feature_extractor_model,\n",
    "    rf_classifier=rf_model\n",
    ")\n",
    "\n",
    "# Print the final result in a clean format\n",
    "print(\"\\n============== PREDICTION RESULT ==============\")\n",
    "print(f\"The model predicts this image is: '{predicted_class}'\")\n",
    "print(f\"Confidence score: {confidence_score * 100:.2f}%\")\n",
    "print(\"=============================================\")\n",
    "\n",
    "# As a check, let's see what the real label was\n",
    "true_label_code = validation_labels[9]\n",
    "true_label_name = 'cancer' if true_label_code == 0 else 'normal'\n",
    "print(f\"(For verification, the true label is: '{true_label_name}')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71955b23-586f-485f-968f-7f565aac1a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Displaying a sample validation image before evaluation...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating the model on the validation set...\n"
     ]
    }
   ],
   "source": [
    "# --- (This code goes right before Step 5) ---\n",
    "\n",
    "print(\"\\nDisplaying a sample validation image before evaluation...\")\n",
    "\n",
    "# Choose an example image to display (e.g., the 10th image)\n",
    "example_image_path = validation_image_paths[9]\n",
    "example_true_label_code = validation_labels[9]\n",
    "example_true_label_name = 'cancer' if example_true_label_code == 0 else 'normal'\n",
    "\n",
    "# Read the image file using OpenCV\n",
    "# We read it directly from the file for a clean, original view\n",
    "image_to_plot = cv2.imread(example_image_path)\n",
    "# Convert from BGR (OpenCV's default) to RGB for correct colors in matplotlib\n",
    "image_to_plot = cv2.cvtColor(image_to_plot, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Plot the image\n",
    "plt.imshow(image_to_plot)\n",
    "plt.title(f\"Sample Validation Image\\nTrue Label: '{example_true_label_name}'\")\n",
    "plt.axis('off')  # Hide the axes for a cleaner look\n",
    "plt.show()\n",
    "\n",
    "# --- Step 5: Evaluate the Random Forest Model ---\n",
    "# (Your existing code continues here...)\n",
    "print(\"\\nEvaluating the model on the validation set...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7dd5185-29b6-45b7-a19f-c6d52e4313be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = [].\n",
    "# for file in img_files:\n",
    "#     image = Image.open(file)\n",
    "#     img.append(image)\n",
    "# # images = [Image.open(file) for file in img_files]\n",
    "\n",
    "# columns = 5\n",
    "# rows = len(img) // columns + int(len(img) % columns !=0)\n",
    "\n",
    "# fig, axes = plt.subplots(rows, columns, figsize=(15,15))\n",
    "# axes = axes.flatten()\n",
    "\n",
    "# for idx, image in enumerate(img):\n",
    "#     axes[idx].imshow(image, cmap='gray')\n",
    "#     axes[idx].axis('off')\n",
    "#     axes[idx].set_title(f\"Image {idx+1}\")\n",
    "\n",
    "# for ax in axes[len(img):]:\n",
    "#     ax.axis('off')\n",
    "\n",
    "\n",
    "\n",
    "# print(f\"found {len(img_files)} .pgm images\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "#####################################################################\n",
    "# cols = 5\n",
    "# rows = len(images) // cols + int(len(images) % cols != 0)\n",
    "\n",
    "# # Create subplots\n",
    "# # fig, axes = plt.subplots(rows, cols, figsize=(15, 15))\n",
    "# fig, axes = plt.subplots(rows, cols, figsize=(15, 15))\n",
    "\n",
    "# axes = axes.flatten()  # Flatten in case of 2D array of axes\n",
    "\n",
    "# # Loop through images and plot each one\n",
    "# for idx, img in enumerate(images):\n",
    "#     axes[idx].imshow(img, cmap='gray')\n",
    "#     axes[idx].axis('off')\n",
    "#     axes[idx].set_title(f\"Image {idx+1}\")\n",
    "\n",
    "# # Turn off any unused subplots\n",
    "# for ax in axes[len(images):]:\n",
    "#     ax.axis('off')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149b047e-a933-464b-a99d-fcd1e88f7959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reading the Image file \n",
    "# img_files = glob.glob(\"all-mias\")\n",
    "# # img_files = \"all-mias\"\n",
    "# print(f\"found {len(img_files)} .pmg images\")\n",
    "\n",
    "# # reading the txt file \n",
    "# txt_path = \"info.txt\"\n",
    "# with open(txt_path, \"r\") as file:\n",
    "#     txt_file = file.readlines()\n",
    "\n",
    "# first_img = Image.open(img_files[11])\n",
    "# plt.imshow(first_img, cmap='gray')\n",
    "# plt.title(\"Example .pgm Image\")\n",
    "# plt.axis('off')  # Hide axis ticks\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6fbb8d0-ff8c-4646-8aad-a54e26e64e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl.metadata (355 bytes)\n",
      "Collecting imbalanced-learn (from imblearn)\n",
      "  Downloading imbalanced_learn-0.13.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in c:\\python3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.26.4)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in c:\\python3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.14.1)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in c:\\python3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.5.0)\n",
      "Collecting sklearn-compat<1,>=0.1 (from imbalanced-learn->imblearn)\n",
      "  Downloading sklearn_compat-0.1.3-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in c:\\python3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in c:\\python3\\lib\\site-packages (from imbalanced-learn->imblearn) (3.5.0)\n",
      "Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Downloading imbalanced_learn-0.13.0-py3-none-any.whl (238 kB)\n",
      "Downloading sklearn_compat-0.1.3-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: sklearn-compat, imbalanced-learn, imblearn\n",
      "\n",
      "   ------------- -------------------------- 1/3 [imbalanced-learn]\n",
      "   ------------- -------------------------- 1/3 [imbalanced-learn]\n",
      "   ---------------------------------------- 3/3 [imblearn]\n",
      "\n",
      "Successfully installed imbalanced-learn-0.13.0 imblearn-0.0 sklearn-compat-0.1.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imblearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7dafea9-1fa5-4bac-9e71-ac2efa8bdf0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.98      1.00      0.99        53\n",
      "      Cancer       1.00      0.98      0.99        46\n",
      "\n",
      "    accuracy                           0.99        99\n",
      "   macro avg       0.99      0.99      0.99        99\n",
      "weighted avg       0.99      0.99      0.99        99\n",
      "\n",
      "AUC: 0.9837981952420016\n",
      "SVM Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.98      1.00      0.99        53\n",
      "      Cancer       1.00      0.98      0.99        46\n",
      "\n",
      "    accuracy                           0.99        99\n",
      "   macro avg       0.99      0.99      0.99        99\n",
      "weighted avg       0.99      0.99      0.99        99\n",
      "\n",
      "AUC: 0.9909762100082035\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "from skimage import feature\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, GroupShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# --- 1. Data Loading with ROI Extraction ---\n",
    "col_names = ['REFNUM', 'BG', 'CLASS', 'SEVERITY', 'X', 'Y', 'RADIUS']\n",
    "df = pd.read_csv('data2.txt', sep=r\"\\s+\", names=col_names, header=None)\n",
    "df['CANCER'] = df['SEVERITY'].apply(lambda x: 1 if x in ['B', 'M'] else 0)\n",
    "\n",
    "images_path = \"all-mias\"\n",
    "all_images = []\n",
    "all_labels = []\n",
    "all_groups = []\n",
    "\n",
    "for filename in sorted(os.listdir(images_path)):\n",
    "    if filename.lower().endswith('.pgm'):\n",
    "        ref_num = os.path.splitext(filename)[0]\n",
    "        record = df[df['REFNUM'] == ref_num]\n",
    "        if not record.empty:\n",
    "            full_path = os.path.join(images_path, filename)\n",
    "            img = cv2.imread(full_path, cv2.IMREAD_GRAYSCALE)\n",
    "            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "            img = clahe.apply(img)\n",
    "            \n",
    "            label = record['CANCER'].iloc[0]\n",
    "            x, y, r = record[['X', 'Y', 'RADIUS']].iloc[0]\n",
    "            \n",
    "            if label == 1 and pd.notna(x) and pd.notna(y) and pd.notna(r):\n",
    "                # Crop ROI for Abnormal\n",
    "                x, y, r = int(x), int(y), int(r)\n",
    "                roi = img[max(0, y-r):min(1024, y+r), max(0, x-r):min(1024, x+r)]\n",
    "            else:\n",
    "                # Use full image for Normal or missing coordinates\n",
    "                roi = img\n",
    "                \n",
    "            all_images.append(roi)\n",
    "            all_labels.append(label)\n",
    "            all_groups.append(ref_num[:-1])  # Group by patient (e.g., 'mdb001' -> 'mdb00')\n",
    "\n",
    "# --- 2. Feature Extraction (LBP + GLCM) ---\n",
    "def extract_features(img, P=8, R=3):\n",
    "    # LBP\n",
    "    lbp = feature.local_binary_pattern(img, P, R, method='uniform')\n",
    "    # num_bins = int(lbp.max() + 1)\n",
    "    num_bins = P + 2\n",
    "    hist, _ = np.histogram(lbp, bins=num_bins, range=(0, num_bins))\n",
    "    \n",
    "    # GLCM\n",
    "    glcm = graycomatrix(img, distances=[1], angles=[0, np.pi/4, np.pi/2, 3*np.pi/4], levels=256)\n",
    "    glcm_features = [\n",
    "        graycoprops(glcm, 'contrast').mean(),\n",
    "        graycoprops(glcm, 'dissimilarity').mean(),\n",
    "        graycoprops(glcm, 'homogeneity').mean(),\n",
    "        graycoprops(glcm, 'energy').mean(),\n",
    "        graycoprops(glcm, 'correlation').mean()\n",
    "    ]\n",
    "    \n",
    "    return np.concatenate([hist, glcm_features])\n",
    "\n",
    "X = np.array([extract_features(img) for img in all_images])\n",
    "y = np.array(all_labels)\n",
    "groups = np.array(all_groups)\n",
    "\n",
    "# --- 3. Data Splitting and Scaling ---\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "train_idx, test_idx = next(gss.split(X, y, groups))\n",
    "X_train, X_test = X[train_idx], X[test_idx]\n",
    "y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# --- 4. Handle Imbalance ---\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# --- 5. Model Training ---\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=150, class_weight='balanced', random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "print(\"Random Forest Results:\")\n",
    "print(classification_report(y_test, y_pred_rf, target_names=['Normal', 'Cancer']))\n",
    "print(\"AUC:\", roc_auc_score(y_test, rf.predict_proba(X_test)[:, 1]))\n",
    "\n",
    "# SVM\n",
    "svm = SVC(probability=True, class_weight='balanced', random_state=42)\n",
    "param_grid = {'C': [0.1, 1, 10], 'gamma': ['scale', 0.1], 'kernel': ['rbf']}\n",
    "grid_svm = GridSearchCV(svm, param_grid, cv=5, scoring='roc_auc')\n",
    "grid_svm.fit(X_train, y_train)\n",
    "y_pred_svm = grid_svm.predict(X_test)\n",
    "print(\"SVM Results:\")\n",
    "print(classification_report(y_test, y_pred_svm, target_names=['Normal', 'Cancer']))\n",
    "print(\"AUC:\", roc_auc_score(y_test, grid_svm.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b51636b-8a9e-4dfa-b2ae-fffd8059effc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d2269a-8322-4012-b44b-b5dcb40ad269",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef8038a-b3a3-467a-8cbb-82cc6244a808",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b095fbf8-7acf-42ba-a15b-906a7c700a32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ff4bff-e167-4255-a4be-c27f752a64e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
