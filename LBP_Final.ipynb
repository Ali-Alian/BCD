{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9aa598cf-8b56-4dfc-8baf-d716e45659ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "from skimage import feature\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "# from skimage.feature import greycomatrix, greycoprops\n",
    "from glob import glob # Used to easily find file paths\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import recall_score, roc_auc_score, roc_curve, auc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5861b47-4095-43ea-96bf-5c6bdcb5efad",
   "metadata": {},
   "source": [
    "# LBP + GLCM\n",
    "\n",
    "### First step is to loud the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "56ba33b1-a4d1-4071-9ac8-42c8090127ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been louded successfully\n",
      "Image list 324\n",
      "Labels list 324\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REFNUM</th>\n",
       "      <th>BG</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>SEVERITY</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>RADIUS</th>\n",
       "      <th>CANCER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>REFNUM</td>\n",
       "      <td>BG</td>\n",
       "      <td>CLASS</td>\n",
       "      <td>SEVERITY</td>\n",
       "      <td>X</td>\n",
       "      <td>Y</td>\n",
       "      <td>RADIUS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mdb001</td>\n",
       "      <td>G</td>\n",
       "      <td>CIRC</td>\n",
       "      <td>B</td>\n",
       "      <td>535</td>\n",
       "      <td>425</td>\n",
       "      <td>197</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mdb002</td>\n",
       "      <td>G</td>\n",
       "      <td>CIRC</td>\n",
       "      <td>B</td>\n",
       "      <td>522</td>\n",
       "      <td>280</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mdb003</td>\n",
       "      <td>D</td>\n",
       "      <td>NORM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mdb004</td>\n",
       "      <td>D</td>\n",
       "      <td>NORM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   REFNUM  BG  CLASS  SEVERITY    X    Y  RADIUS  CANCER\n",
       "0  REFNUM  BG  CLASS  SEVERITY    X    Y  RADIUS       0\n",
       "1  mdb001   G   CIRC         B  535  425     197       1\n",
       "2  mdb002   G   CIRC         B  522  280      69       1\n",
       "3  mdb003   D   NORM       NaN  NaN  NaN     NaN       0\n",
       "4  mdb004   D   NORM       NaN  NaN  NaN     NaN       0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loud the data folder and the images\n",
    "col_names = ['REFNUM', 'BG', 'CLASS', 'SEVERITY', 'X', 'Y', 'RADIUS']\n",
    "df = pd.read_csv('data2.txt', sep=\"\\s+\", names=col_names, header=None)\n",
    "df['CANCER'] = df['SEVERITY'].apply(lambda x: 1 if x in ['B', 'M'] else 0)\n",
    "\n",
    "images_path = \"all-mias\"\n",
    "\n",
    "all_images = []\n",
    "all_labels = []\n",
    "all_groups = []\n",
    "\n",
    "for filename in sorted(os.listdir(images_path)):\n",
    "    if filename.lower().endswith('.pgm'):\n",
    "        ref_num = os.path.splitext(filename)[0]\n",
    "        record = df[df['REFNUM'] == ref_num]\n",
    "\n",
    "        if not record.empty:\n",
    "            full_path = os.path.join(images_path, filename)\n",
    "            img_array = cv2.imread(full_path, cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "            img_eq = clahe.apply(img_array)\n",
    "\n",
    "            labels = record['CANCER'].iloc[0]\n",
    "            x, y, radius = record[['X', 'Y', 'RADIUS']].iloc[0]\n",
    "            \n",
    "            # Handle ROI extraction\n",
    "            if labels == 1 and pd.notna(x) and pd.notna(y) and pd.notna(radius):\n",
    "                # Adjust for bottom-left origin: flip Y coordinate\n",
    "                x, y, radius = int(x), int(1024 - float(y)), int(radius)  # Y = 1024 - y for top-left origin\n",
    "                # Crop a square ROI around (x, y) with size 2*radius\n",
    "                roi = img_eq[max(0, y-radius):min(1024, y+radius), max(0, x-radius):min(1024, x+radius)]\n",
    "                # Ensure ROI is not empty; resize to a fixed size (e.g., 128x128) for consistency\n",
    "                if roi.size > 0:\n",
    "                    roi = cv2.resize(roi, (256, 256), interpolation=cv2.INTER_AREA)\n",
    "                else:\n",
    "                    roi = img_eq  # Fallback to full image if ROI is invalid\n",
    "            else:\n",
    "                # For normal images or missing coordinates, use the entire image resized\n",
    "                roi = cv2.resize(img_eq, (256, 256), interpolation=cv2.INTER_AREA)\n",
    "            \n",
    "            all_images.append(roi)\n",
    "            all_labels.append(labels)\n",
    "            all_groups.append(ref_num[:-1])\n",
    "\n",
    "print(\"Data has been louded successfully\")\n",
    "# plt.imshow(img_eq, cmap='gray')\n",
    "## Print out the table from dataset\n",
    "print(f\"Image list {len(all_images)}\")\n",
    "print(f\"Labels list {len(all_labels)}\")\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf41739-bef3-4258-af4f-2a110b4781f6",
   "metadata": {},
   "source": [
    "# GLCM\n",
    "\n",
    "#### 2 - applyed the Gray-Level Co-occurrence Matrix (GLCM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ef4f71f7-ab89-4c38-88f1-d18b3a783a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_glcm_features(patch, \n",
    "                          distances=[1, 3, 5], \n",
    "                          angles=[0, np.pi/4, np.pi/2, 3*np.pi/4], \n",
    "                          levels=256):\n",
    "    \"\"\"\n",
    "    Compute GLCM and summary stats for a single gray‑scale patch (2D ndarray).\n",
    "    Returns a dict: e.g. {'contrast_mean':…, 'contrast_var':…, 'homogeneity_mean':…, …}\n",
    "    \"\"\"\n",
    "    patch = (patch * (levels - 1)).astype(np.uint8) if patch.max() <= 1 else patch.astype(np.uint8)\n",
    "    \n",
    "    glcm = graycomatrix(patch,\n",
    "                        distances=distances,\n",
    "                        angles=angles,\n",
    "                        levels=levels,\n",
    "                        symmetric=True,\n",
    "                        normed=True)\n",
    "\n",
    "    props = ['contrast', 'dissimilarity', 'homogeneity', 'ASM', 'energy', 'correlation']\n",
    "    feats = {}\n",
    "    for prop in props:\n",
    "        mat = graycoprops(glcm, prop)  # shape = (len(distances), len(angles))\n",
    "        feats[f'{prop}_mean'] = mat.mean()\n",
    "        feats[f'{prop}_var']  = mat.var()\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34864d5e-b9d8-474d-aabb-86019b95d617",
   "metadata": {},
   "source": [
    "# LBP\n",
    "#### 3 - Applying the Local Binaryt Pattern (LPB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2e6c2ff8-4f97-4f49-8f91-05e752eb2621",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aa23147\\AppData\\Roaming\\Python\\Python310\\site-packages\\skimage\\feature\\texture.py:385: UserWarning: Applying `local_binary_pattern` to floating-point images may give unexpected results when small numerical differences between adjacent pixels are present. It is recommended to use this function with images of integer dtype.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324\n",
      "Computing the image and histogram for pooling and classification...\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "normalaized_img = [] # holding the LBP maps\n",
    "    \n",
    "for img in all_images:\n",
    "    # Normalazing the image \n",
    "    if img.max() > img.min():\n",
    "        n_img = ((img - img.min()) / (img.max() - img.min()) * 255) \n",
    "    else:\n",
    "        n_img = img\n",
    "    # normalaized_img.append(n_img)\n",
    "    P = 8\n",
    "    R = 3\n",
    "    method = 'uniform'\n",
    "    LBP = feature.local_binary_pattern(n_img, P, R, method)\n",
    "#   bins_num = int(n_img.max()) + 1\n",
    "    normalaized_img.append(LBP)\n",
    "print(len(normalaized_img))\n",
    "# print(normalaized_img.shape)\n",
    "\n",
    "print(\"Computing the image and histogram for pooling and classification...\")\n",
    "\n",
    "def compute_histograms_for_each_region(normalaized_img, G=6, n_bins=59):\n",
    "    #compute th histogram from 255 in image size to 59 =>  reduce the number of bins\n",
    "    histogram = []\n",
    "\n",
    "    \"\"\"\n",
    "    # Pooling the image in to 6 x 6\n",
    "    H = 1020 # height\n",
    "    W = 1020 # width\n",
    "    #G = 6 # Number of Grid 6 * 6 \n",
    "    hor = int(H / G) # height of each region\n",
    "    wor = int(W / G) # width of each region\n",
    "    \"\"\"\n",
    "    H, W = normalaized_img.shape\n",
    "    hor, wor = H // G, W // G\n",
    "# Pooling the data into 6 * 6 regions   \n",
    "    for i in range(G):\n",
    "        for j in range(G):\n",
    "            row_start = i * hor\n",
    "            row_end = (i + 1) * hor\n",
    "            col_start = j * wor\n",
    "            col_end = (i + 1) * wor\n",
    "            region = normalaized_img[row_start:row_end, col_start:col_end]\n",
    "\n",
    "            hist, _ = np.histogram(region.ravel(), bins=n_bins, range=(0, n_bins))\n",
    "            hist = hist.astype(float)\n",
    "            if hist.sum() > 0:    \n",
    "                hist /= hist.sum()\n",
    "        \n",
    "            histogram.append(hist)\n",
    "\n",
    "    print(len(histogram))\n",
    "    print(\"Histogram Done!. . . \")\n",
    "    return histogram\n",
    "\n",
    "\n",
    "# histogram = compute_histograms_for_each_region(normalaized_img)\n",
    "print(len(histogram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4ef34e54-5d7e-4f29-b516-162f14f7d519",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLCM feature matrix: (324, 14)\n",
      "   contrast_mean   contrast_var  dissimilarity_mean  dissimilarity_var  \\\n",
      "0     117.391427    7297.511236            7.270573           9.409434   \n",
      "1      19.812110     186.927860            3.125081           1.573940   \n",
      "2     365.555063   78600.626153            6.565108           9.672931   \n",
      "3     460.872543  129591.976105            7.249875          12.577701   \n",
      "4      39.197109     858.594241            4.168859           3.119797   \n",
      "\n",
      "   homogeneity_mean  homogeneity_var  ASM_mean       ASM_var  energy_mean  \\\n",
      "0          0.184442         0.005042  0.000339  1.429746e-08     0.018130   \n",
      "1          0.322144         0.014375  0.001044  2.321923e-07     0.031542   \n",
      "2          0.569111         0.001664  0.176609  1.137524e-04     0.420054   \n",
      "3          0.540402         0.001760  0.156318  8.633963e-05     0.395193   \n",
      "4          0.279597         0.014106  0.000733  1.493392e-07     0.026271   \n",
      "\n",
      "   energy_var  correlation_mean  correlation_var  label  group  \n",
      "0    0.000010          0.985407         0.000114      1  mdb00  \n",
      "1    0.000049          0.993535         0.000020      1  mdb00  \n",
      "2    0.000164          0.968609         0.000575      0  mdb00  \n",
      "3    0.000140          0.963844         0.000792      0  mdb00  \n",
      "4    0.000043          0.982408         0.000174      1  mdb00  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[78], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m y_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lbp_img, label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(histogram, all_labels): \u001b[38;5;66;03m# ??//??????????????\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m     histogram \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_histograms_for_each_region\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlbp_img\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m     f_vector \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(histogram)\n\u001b[0;32m     33\u001b[0m     f_vector \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(f_vector) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-10\u001b[39m\n",
      "Cell \u001b[1;32mIn[77], line 33\u001b[0m, in \u001b[0;36mcompute_histograms_for_each_region\u001b[1;34m(normalaized_img, G, n_bins)\u001b[0m\n\u001b[0;32m     23\u001b[0m     histogram \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     25\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124;03m    # Pooling the image in to 6 x 6\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03m    H = 1020 # height\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m    wor = int(W / G) # width of each region\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m     H, W \u001b[38;5;241m=\u001b[39m normalaized_img\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m     34\u001b[0m     hor, wor \u001b[38;5;241m=\u001b[39m H \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m G, W \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m G\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Pooling the data into 6 * 6 regions   \u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "# Loop over your ROIs, build a DataFrame of features + labels + group IDs base on GLCM function\n",
    "records = [] # records the data\n",
    "for roi, label, grp in zip(all_images, all_labels, all_groups):\n",
    "    glcm_feats = extract_glcm_features(roi)\n",
    "    # lbp_feats  = compute_histograms_for_each_region(roi) # ?????????????\n",
    "    glcm_feats['label'] = label\n",
    "    glcm_feats['group'] = grp       \n",
    "    records.append(glcm_feats)\n",
    "\n",
    "    \n",
    "df = pd.DataFrame.from_records(records) # sort the recorded data into the dataframe\n",
    "print(\"GLCM feature matrix:\", df.shape)\n",
    "print(df.head())\n",
    "\n",
    "# 3) Prepare for data training \n",
    "X = df.drop(columns=['label','group']).values\n",
    "y = df['label'].values  \n",
    "\n",
    "X_glcm = X\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "##############################\n",
    "##############################\n",
    "\n",
    "x_list = []\n",
    "y_list = []\n",
    "for lbp_img, label in zip(histogram, all_labels): # ??//??????????????\n",
    "    histogram = compute_histograms_for_each_region(lbp_img)\n",
    "\n",
    "    f_vector = np.concatenate(histogram)\n",
    "    f_vector /= np.linalg.norm(f_vector) + 1e-10\n",
    "\n",
    "    x_list.append(f_vector)\n",
    "    y_list.append(label)\n",
    "\n",
    "X = np.array(x_list)\n",
    "y = np.array(y_list)\n",
    "X_lbp = X\n",
    "print(\"Function has been done successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bb9b6256-cef5-4f08-b9fc-822d817edef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLCM samples: 324\n",
      "LBP samples : 36\n",
      "Label count: 324\n"
     ]
    }
   ],
   "source": [
    "print(\"GLCM samples:\", X_glcm.shape[0])\n",
    "print(\"LBP samples :\", X_lbp.shape[0])\n",
    "print(\"Label count:\", y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8ed4251a-d2d3-4aa1-8a06-f308bf2d2f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLCM labels: [1 1 0 0 1]\n",
      "LBP labels: [1, 1, 0, 0, 1]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Mismatch in sample counts!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGLCM labels:\u001b[39m\u001b[38;5;124m\"\u001b[39m, df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[:\u001b[38;5;241m5\u001b[39m])\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLBP labels:\u001b[39m\u001b[38;5;124m\"\u001b[39m, y_list[:\u001b[38;5;241m5\u001b[39m])\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m X_glcm\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m X_lbp\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMismatch in sample counts!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m X_combined \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack([X_glcm, X_lbp])\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFused feature shape : \u001b[39m\u001b[38;5;124m\"\u001b[39m, X_combined\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Mismatch in sample counts!"
     ]
    }
   ],
   "source": [
    "print(\"GLCM labels:\", df['label'].values[:5])\n",
    "print(\"LBP labels:\", y_list[:5])\n",
    "\n",
    "assert X_glcm.shape[0] == X_lbp.shape[0] == y.shape[0], \"Mismatch in sample counts!\"\n",
    "X_combined = np.hstack([X_glcm, X_lbp])\n",
    "print(\"Fused feature shape : \", X_combined.shape)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_ready = scaler.fit_transform(X_combined)\n",
    "clf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(clf, X_ready, y, cv=cv, scoring='roc_auc')\n",
    "print(\"ROC‑AUC:\", scores.mean(), \"±\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8799b3fc-78ae-4b32-b59e-edcec747384f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group‑CV ROC‑AUC: 0.984 ± 0.010\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The 'groups' parameter should not be None.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 17\u001b[0m\n\u001b[0;32m      7\u001b[0m scores \u001b[38;5;241m=\u001b[39m cross_val_score(\n\u001b[0;32m      8\u001b[0m     clf,\n\u001b[0;32m      9\u001b[0m     X_ready,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m     scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m'\u001b[39m        \u001b[38;5;66;03m# ← here’s the “…” replacement\u001b[39;00m\n\u001b[0;32m     13\u001b[0m )\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGroup‑CV ROC‑AUC: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscores\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ± \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscores\u001b[38;5;241m.\u001b[39mstd()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_ready\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscoring\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m     22\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m scoring:\n\u001b[0;32m     25\u001b[0m     scores \u001b[38;5;241m=\u001b[39m cv_results[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mC:\\Python3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mC:\\Python3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:423\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    422\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 423\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    443\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    445\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python3\\lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python3\\lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mC:\\Python3\\lib\\site-packages\\joblib\\parallel.py:1844\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1841\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1843\u001b[0m \u001b[38;5;66;03m# Sequentially call the tasks and yield the results.\u001b[39;00m\n\u001b[1;32m-> 1844\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1845\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mC:\\Python3\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Capture the thread-local scikit-learn configuration at the time\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# Parallel.__call__ is issued since the tasks can be dispatched\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# in a different thread depending on the backend and on the value of\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# pre_dispatch and n_jobs.\u001b[39;00m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m---> 63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mC:\\Python3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:423\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    422\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 423\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    424\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    425\u001b[0m         clone(estimator),\n\u001b[0;32m    426\u001b[0m         X,\n\u001b[0;32m    427\u001b[0m         y,\n\u001b[0;32m    428\u001b[0m         scorer\u001b[38;5;241m=\u001b[39mscorers,\n\u001b[0;32m    429\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    430\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    431\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    432\u001b[0m         parameters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    433\u001b[0m         fit_params\u001b[38;5;241m=\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit,\n\u001b[0;32m    434\u001b[0m         score_params\u001b[38;5;241m=\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mscorer\u001b[38;5;241m.\u001b[39mscore,\n\u001b[0;32m    435\u001b[0m         return_train_score\u001b[38;5;241m=\u001b[39mreturn_train_score,\n\u001b[0;32m    436\u001b[0m         return_times\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    437\u001b[0m         return_estimator\u001b[38;5;241m=\u001b[39mreturn_estimator,\n\u001b[0;32m    438\u001b[0m         error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[0;32m    439\u001b[0m     )\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[0;32m    441\u001b[0m )\n\u001b[0;32m    443\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    445\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:416\u001b[0m, in \u001b[0;36m_BaseKFold.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits \u001b[38;5;241m>\u001b[39m n_samples:\n\u001b[0;32m    409\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    410\u001b[0m         (\n\u001b[0;32m    411\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot have number of splits n_splits=\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m greater\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    412\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m than the number of samples: n_samples=\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    413\u001b[0m         )\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits, n_samples)\n\u001b[0;32m    414\u001b[0m     )\n\u001b[1;32m--> 416\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msplit(X, y, groups):\n\u001b[0;32m    417\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m train, test\n",
      "File \u001b[1;32mC:\\Python3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:147\u001b[0m, in \u001b[0;36mBaseCrossValidator.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    145\u001b[0m X, y, groups \u001b[38;5;241m=\u001b[39m indexable(X, y, groups)\n\u001b[0;32m    146\u001b[0m indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(_num_samples(X))\n\u001b[1;32m--> 147\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_test_masks(X, y, groups):\n\u001b[0;32m    148\u001b[0m     train_index \u001b[38;5;241m=\u001b[39m indices[np\u001b[38;5;241m.\u001b[39mlogical_not(test_index)]\n\u001b[0;32m    149\u001b[0m     test_index \u001b[38;5;241m=\u001b[39m indices[test_index]\n",
      "File \u001b[1;32mC:\\Python3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:159\u001b[0m, in \u001b[0;36mBaseCrossValidator._iter_test_masks\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_iter_test_masks\u001b[39m(\u001b[38;5;28mself\u001b[39m, X\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    155\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generates boolean masks corresponding to test sets.\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03m    By default, delegates to _iter_test_indices(X, y, groups)\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 159\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m test_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_test_indices(X, y, groups):\n\u001b[0;32m    160\u001b[0m         test_mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(_num_samples(X), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[0;32m    161\u001b[0m         test_mask[test_index] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:602\u001b[0m, in \u001b[0;36mGroupKFold._iter_test_indices\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_iter_test_indices\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, groups):\n\u001b[0;32m    601\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m groups \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 602\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgroups\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m parameter should not be None.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    603\u001b[0m     groups \u001b[38;5;241m=\u001b[39m check_array(groups, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroups\u001b[39m\u001b[38;5;124m\"\u001b[39m, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    605\u001b[0m     unique_groups, groups \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(groups, return_inverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mValueError\u001b[0m: The 'groups' parameter should not be None."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "# cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv = GroupKFold(n_splits=5)\n",
    "scores = cross_val_score(\n",
    "    clf,\n",
    "    X_ready,\n",
    "    y,\n",
    "    cv=cv.split(X_ready, y, all_groups),\n",
    "    scoring='roc_auc'        # ← here’s the “…” replacement\n",
    ")\n",
    "\n",
    "print(f\"Group‑CV ROC‑AUC: {scores.mean():.3f} ± {scores.std():.3f}\")\n",
    "\n",
    "cv_results = cross_validate(\n",
    "    clf, X_ready, y,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    return_train_score=False\n",
    ")\n",
    "\n",
    "for metric in scoring:\n",
    "    scores = cv_results[f'test_{metric}']\n",
    "    print(f\"{metric.capitalize():<8} : {scores.mean():.3f} ± {scores.std():.3f}\")\n",
    "unique_codes = np.unique(LBP)\n",
    "print(\" \")\n",
    "print(\"Unique LBP codes in this image:\", unique_codes)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,    # for reproducibility\n",
    "    stratify=y          # preserves class ratios\n",
    ")\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=250,\n",
    "    class_weight = 'balanced',\n",
    "    max_depth=None,\n",
    "    min_samples_split=10,\n",
    "    random_state=65,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# 5. Predict\n",
    "y_pred = rf_model.predict(X_test)\n",
    "y_prob = rf_model.predict_proba(X_test)  # if you need probabilities\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f742beb8-81d5-4eaa-98fa-90c191bf59bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e442b384-c597-467d-9b6d-b09affb93b60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b338189-f459-4a37-84f8-64da2ff961e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
