{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9aa598cf-8b56-4dfc-8baf-d716e45659ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "from skimage import feature\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "# from skimage.feature import greycomatrix, greycoprops\n",
    "from glob import glob # Used to easily find file paths\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import recall_score, roc_auc_score, roc_curve, auc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5861b47-4095-43ea-96bf-5c6bdcb5efad",
   "metadata": {},
   "source": [
    "# LBP + GLCM\n",
    "\n",
    "### First step is to loud the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56ba33b1-a4d1-4071-9ac8-42c8090127ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been louded successfully\n",
      "Image list 324\n",
      "Labels list 324\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REFNUM</th>\n",
       "      <th>BG</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>SEVERITY</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>RADIUS</th>\n",
       "      <th>CANCER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>REFNUM</td>\n",
       "      <td>BG</td>\n",
       "      <td>CLASS</td>\n",
       "      <td>SEVERITY</td>\n",
       "      <td>X</td>\n",
       "      <td>Y</td>\n",
       "      <td>RADIUS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mdb001</td>\n",
       "      <td>G</td>\n",
       "      <td>CIRC</td>\n",
       "      <td>B</td>\n",
       "      <td>535</td>\n",
       "      <td>425</td>\n",
       "      <td>197</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mdb002</td>\n",
       "      <td>G</td>\n",
       "      <td>CIRC</td>\n",
       "      <td>B</td>\n",
       "      <td>522</td>\n",
       "      <td>280</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mdb003</td>\n",
       "      <td>D</td>\n",
       "      <td>NORM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mdb004</td>\n",
       "      <td>D</td>\n",
       "      <td>NORM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   REFNUM  BG  CLASS  SEVERITY    X    Y  RADIUS  CANCER\n",
       "0  REFNUM  BG  CLASS  SEVERITY    X    Y  RADIUS       0\n",
       "1  mdb001   G   CIRC         B  535  425     197       1\n",
       "2  mdb002   G   CIRC         B  522  280      69       1\n",
       "3  mdb003   D   NORM       NaN  NaN  NaN     NaN       0\n",
       "4  mdb004   D   NORM       NaN  NaN  NaN     NaN       0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loud the data folder and the images\n",
    "col_names = ['REFNUM', 'BG', 'CLASS', 'SEVERITY', 'X', 'Y', 'RADIUS']\n",
    "df = pd.read_csv('data2.txt', sep=\"\\s+\", names=col_names, header=None)\n",
    "df['CANCER'] = df['SEVERITY'].apply(lambda x: 1 if x in ['B', 'M'] else 0)\n",
    "\n",
    "images_path = \"all-mias\"\n",
    "\n",
    "all_images = []\n",
    "all_labels = []\n",
    "all_groups = []\n",
    "\n",
    "for filename in sorted(os.listdir(images_path)):\n",
    "    if filename.lower().endswith('.pgm'):\n",
    "        ref_num = os.path.splitext(filename)[0]\n",
    "        record = df[df['REFNUM'] == ref_num]\n",
    "\n",
    "        if not record.empty:\n",
    "            full_path = os.path.join(images_path, filename)\n",
    "            img_array = cv2.imread(full_path, cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "            img_eq = clahe.apply(img_array)\n",
    "\n",
    "            labels = record['CANCER'].iloc[0]\n",
    "            x, y, radius = record[['X', 'Y', 'RADIUS']].iloc[0]\n",
    "            \n",
    "            # Handle ROI extraction\n",
    "            if labels == 1 and pd.notna(x) and pd.notna(y) and pd.notna(radius):\n",
    "                # Adjust for bottom-left origin: flip Y coordinate\n",
    "                x, y, radius = int(x), int(1024 - float(y)), int(radius)  # Y = 1024 - y for top-left origin\n",
    "                # Crop a square ROI around (x, y) with size 2*radius\n",
    "                roi = img_eq[max(0, y-radius):min(1024, y+radius), max(0, x-radius):min(1024, x+radius)]\n",
    "                # Ensure ROI is not empty; resize to a fixed size (e.g., 128x128) for consistency\n",
    "                if roi.size > 0:\n",
    "                    roi = cv2.resize(roi, (256, 256), interpolation=cv2.INTER_AREA)\n",
    "                else:\n",
    "                    roi = img_eq  # Fallback to full image if ROI is invalid\n",
    "            else:\n",
    "                # For normal images or missing coordinates, use the entire image resized\n",
    "                roi = cv2.resize(img_eq, (256, 256), interpolation=cv2.INTER_AREA)\n",
    "            \n",
    "            all_images.append(roi)\n",
    "            all_labels.append(labels)\n",
    "            all_groups.append(ref_num[:-1])\n",
    "\n",
    "print(\"Data has been louded successfully\")\n",
    "# plt.imshow(img_eq, cmap='gray')\n",
    "## Print out the table from dataset\n",
    "print(f\"Image list {len(all_images)}\")\n",
    "print(f\"Labels list {len(all_labels)}\")\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf41739-bef3-4258-af4f-2a110b4781f6",
   "metadata": {},
   "source": [
    "# GLCM\n",
    "\n",
    "#### 2 - applyed the Gray-Level Co-occurrence Matrix (GLCM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef4f71f7-ab89-4c38-88f1-d18b3a783a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_glcm_features(patch, \n",
    "                          distances=[1, 3, 5], \n",
    "                          angles=[0, np.pi/4, np.pi/2, 3*np.pi/4], \n",
    "                          levels=256):\n",
    "    \"\"\"\n",
    "    Compute GLCM and summary stats for a single gray‑scale patch (2D ndarray).\n",
    "    Returns a dict: e.g. {'contrast_mean':…, 'contrast_var':…, 'homogeneity_mean':…, …}\n",
    "    \"\"\"\n",
    "    patch = (patch * (levels - 1)).astype(np.uint8) if patch.max() <= 1 else patch.astype(np.uint8)\n",
    "    \n",
    "    glcm = graycomatrix(patch,\n",
    "                        distances=distances,\n",
    "                        angles=angles,\n",
    "                        levels=levels,\n",
    "                        symmetric=True,\n",
    "                        normed=True)\n",
    "\n",
    "    props = ['contrast', 'dissimilarity', 'homogeneity', 'ASM', 'energy', 'correlation']\n",
    "    feats = {}\n",
    "    for prop in props:\n",
    "        mat = graycoprops(glcm, prop)  # shape = (len(distances), len(angles))\n",
    "        feats[f'{prop}_mean'] = mat.mean()\n",
    "        feats[f'{prop}_var']  = mat.var()\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34864d5e-b9d8-474d-aabb-86019b95d617",
   "metadata": {},
   "source": [
    "# LBP\n",
    "#### 3 - Applying the Local Binaryt Pattern (LPB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e6c2ff8-4f97-4f49-8f91-05e752eb2621",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aa23147\\AppData\\Roaming\\Python\\Python310\\site-packages\\skimage\\feature\\texture.py:385: UserWarning: Applying `local_binary_pattern` to floating-point images may give unexpected results when small numerical differences between adjacent pixels are present. It is recommended to use this function with images of integer dtype.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324\n",
      "Computing the image and histogram for pooling and classification...\n"
     ]
    }
   ],
   "source": [
    "normalaized_img = [] # holding the LBP maps\n",
    "    \n",
    "for img in all_images:\n",
    "    # Normalazing the image \n",
    "    if img.max() > img.min():\n",
    "        n_img = ((img - img.min()) / (img.max() - img.min()) * 255) \n",
    "    else:\n",
    "        n_img = img\n",
    "    # normalaized_img.append(n_img)\n",
    "    P = 8\n",
    "    R = 3\n",
    "    method = 'uniform'\n",
    "    LBP = feature.local_binary_pattern(n_img, P, R, method)\n",
    "#   bins_num = int(n_img.max()) + 1\n",
    "    normalaized_img.append(LBP)\n",
    "print(len(normalaized_img))\n",
    "# print(normalaized_img.shape)\n",
    "\n",
    "print(\"Computing the image and histogram for pooling and classification...\")\n",
    "\n",
    "def compute_histograms_for_each_region(normalaized_img, G=6, n_bins=59):\n",
    "    #compute th histogram from 255 in image size to 59 =>  reduce the number of bins\n",
    "    histogram = []\n",
    "\n",
    "    \"\"\"\n",
    "    # Pooling the image in to 6 x 6\n",
    "    H = 1020 # height\n",
    "    W = 1020 # width\n",
    "    #G = 6 # Number of Grid 6 * 6 \n",
    "    hor = int(H / G) # height of each region\n",
    "    wor = int(W / G) # width of each region\n",
    "    \"\"\"\n",
    "    H, W = normalaized_img.shape\n",
    "    hor, wor = H // G, W // G\n",
    "# Pooling the data into 6 * 6 regions   \n",
    "    for i in range(G):\n",
    "        for j in range(G):\n",
    "            row_start = i * hor\n",
    "            row_end = (i + 1) * hor\n",
    "            col_start = j * wor\n",
    "            col_end = (i + 1) * wor\n",
    "            region = normalaized_img[row_start:row_end, col_start:col_end]\n",
    "\n",
    "            hist, _ = np.histogram(region.ravel(), bins=n_bins, range=(0, n_bins))\n",
    "            hist = hist.astype(float)\n",
    "            if hist.sum() > 0:    \n",
    "                hist /= hist.sum()\n",
    "        \n",
    "            histogram.append(hist)\n",
    "\n",
    "    # print(len(histogram))\n",
    "    # count = 0\n",
    "    # for i in range(count):\n",
    "    #     count + 1\n",
    "    #     print(f\"Histogram Done!. . . {i}\")\n",
    "    return histogram\n",
    "\n",
    "\n",
    "# histogram = compute_histograms_for_each_region(normalaized_img)\n",
    "# print(len(histogram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ef34e54-5d7e-4f29-b516-162f14f7d519",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLCM feature matrix: (324, 14)\n",
      "   contrast_mean   contrast_var  dissimilarity_mean  dissimilarity_var  \\\n",
      "0     117.391427    7297.511236            7.270573           9.409434   \n",
      "1      19.812110     186.927860            3.125081           1.573940   \n",
      "2     365.555063   78600.626153            6.565108           9.672931   \n",
      "3     460.872543  129591.976105            7.249875          12.577701   \n",
      "4      39.197109     858.594241            4.168859           3.119797   \n",
      "\n",
      "   homogeneity_mean  homogeneity_var  ASM_mean       ASM_var  energy_mean  \\\n",
      "0          0.184442         0.005042  0.000339  1.429746e-08     0.018130   \n",
      "1          0.322144         0.014375  0.001044  2.321923e-07     0.031542   \n",
      "2          0.569111         0.001664  0.176609  1.137524e-04     0.420054   \n",
      "3          0.540402         0.001760  0.156318  8.633963e-05     0.395193   \n",
      "4          0.279597         0.014106  0.000733  1.493392e-07     0.026271   \n",
      "\n",
      "   energy_var  correlation_mean  correlation_var  label  group  \n",
      "0    0.000010          0.985407         0.000114      1  mdb00  \n",
      "1    0.000049          0.993535         0.000020      1  mdb00  \n",
      "2    0.000164          0.968609         0.000575      0  mdb00  \n",
      "3    0.000140          0.963844         0.000792      0  mdb00  \n",
      "4    0.000043          0.982408         0.000174      1  mdb00  \n",
      "Function has been done successfully\n"
     ]
    }
   ],
   "source": [
    "# Loop over your ROIs, build a DataFrame of features + labels + group IDs base on GLCM function\n",
    "records = [] # records the data\n",
    "for roi, label, grp in zip(all_images, all_labels, all_groups):\n",
    "    glcm_feats = extract_glcm_features(roi)\n",
    "    # lbp_feats  = compute_histograms_for_each_region(roi) # ?????????????\n",
    "    glcm_feats['label'] = label\n",
    "    glcm_feats['group'] = grp       \n",
    "    records.append(glcm_feats)\n",
    "\n",
    "    \n",
    "df = pd.DataFrame.from_records(records) # sort the recorded data into the dataframe\n",
    "print(\"GLCM feature matrix:\", df.shape)\n",
    "print(df.head())\n",
    "\n",
    "# 3) Prepare for data training \n",
    "X = df.drop(columns=['label','group']).values\n",
    "y = df['label'].values  \n",
    "\n",
    "X_glcm = X\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "##############################\n",
    "##############################\n",
    "\n",
    "x_list = []\n",
    "y_list = []\n",
    "for lbp_img, label in zip(normalaized_img, all_labels): # ??//??????????????\n",
    "    histogram = compute_histograms_for_each_region(lbp_img)\n",
    "\n",
    "    f_vector = np.concatenate(histogram)\n",
    "    f_vector /= np.linalg.norm(f_vector) + 1e-10\n",
    "\n",
    "    x_list.append(f_vector)\n",
    "    y_list.append(label)\n",
    "\n",
    "X = np.array(x_list)\n",
    "y = np.array(y_list)\n",
    "X_lbp = X\n",
    "print(\"Function has been done successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb9b6256-cef5-4f08-b9fc-822d817edef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLCM samples: 324\n",
      "LBP samples : 324\n",
      "Label count: 324\n"
     ]
    }
   ],
   "source": [
    "print(\"GLCM samples:\", X_glcm.shape[0])\n",
    "print(\"LBP samples :\", X_lbp.shape[0])\n",
    "print(\"Label count:\", y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ed4251a-d2d3-4aa1-8a06-f308bf2d2f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLCM labels: [1 1 0 0 1]\n",
      "LBP labels: [1, 1, 0, 0, 1]\n",
      "Fused feature shape :  (324, 2136)\n",
      "ROC‑AUC: 0.9854984093319195 ± 0.019039728533377997\n"
     ]
    }
   ],
   "source": [
    "print(\"GLCM labels:\", df['label'].values[:5])\n",
    "print(\"LBP labels:\", y_list[:5])\n",
    "\n",
    "assert X_glcm.shape[0] == X_lbp.shape[0] == y.shape[0], \"Mismatch in sample counts!\"\n",
    "X_combined = np.hstack([X_glcm, X_lbp])\n",
    "print(\"Fused feature shape : \", X_combined.shape)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_ready = scaler.fit_transform(X_combined)\n",
    "clf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(clf, X_ready, y, cv=cv, scoring='roc_auc')\n",
    "print(\"ROC‑AUC:\", scores.mean(), \"±\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8799b3fc-78ae-4b32-b59e-edcec747384f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group‑CV ROC‑AUC: 0.984 ± 0.010\n",
      "Accuracy : 0.985 ± 0.009\n",
      "Precision : 1.000 ± 0.000\n",
      "Recall   : 0.956 ± 0.024\n",
      "F1       : 0.977 ± 0.012\n",
      "Roc_auc  : 0.984 ± 0.010\n",
      " \n",
      "Unique LBP codes in this image: [0. 1. 2. 3. 4. 5. 6. 7. 8. 9.]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        42\n",
      "           1       1.00      0.96      0.98        23\n",
      "\n",
      "    accuracy                           0.98        65\n",
      "   macro avg       0.99      0.98      0.98        65\n",
      "weighted avg       0.98      0.98      0.98        65\n",
      "\n",
      "Confusion Matrix:\n",
      "[[42  0]\n",
      " [ 1 22]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "\n",
    "# cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv = GroupKFold(n_splits=5)\n",
    "scores = cross_val_score(\n",
    "    clf,\n",
    "    X_ready,\n",
    "    y,\n",
    "    cv=cv.split(X_ready, y, all_groups),\n",
    "    scoring='roc_auc'\n",
    ")\n",
    "print(f\"Group‑CV ROC‑AUC: {scores.mean():.3f} ± {scores.std():.3f}\")\n",
    "\n",
    "cv_results = cross_validate(\n",
    "    clf, X_ready, y,\n",
    "    cv=cv,\n",
    "     groups = all_groups,\n",
    "    scoring=scoring,\n",
    "    return_train_score=False\n",
    ")\n",
    "\n",
    "for metric in scoring:\n",
    "    scores = cv_results[f'test_{metric}']\n",
    "    print(f\"{metric.capitalize():<8} : {scores.mean():.3f} ± {scores.std():.3f}\")\n",
    "unique_codes = np.unique(LBP)\n",
    "print(\" \")\n",
    "print(\"Unique LBP codes in this image:\", unique_codes)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,    # for reproducibility\n",
    "    stratify=y          # preserves class ratios\n",
    ")\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=250,\n",
    "    class_weight = 'balanced',\n",
    "    max_depth=None,\n",
    "    min_samples_split=10,\n",
    "    random_state=65,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# 5. Predict\n",
    "y_pred = rf_model.predict(X_test)\n",
    "y_prob = rf_model.predict_proba(X_test)  # if you need probabilities\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f742beb8-81d5-4eaa-98fa-90c191bf59bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e442b384-c597-467d-9b6d-b09affb93b60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b338189-f459-4a37-84f8-64da2ff961e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
