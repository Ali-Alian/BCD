{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "38b589cd-8767-40bf-9ac0-0f7c30d042cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "from skimage import feature, data, color\n",
    "from glob import glob # Used to easily find file paths\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7463190b-23b2-49a6-a9e5-2f7e03db2ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Besham ta alan ke chedesh ...\n"
     ]
    }
   ],
   "source": [
    "# Loud the data folder and the images\n",
    "col_names = ['REFNUM', 'BG', 'CLASS', 'SEVERITY', 'X', 'Y', 'RADIUS']\n",
    "df = pd.read_csv('data2.txt', sep=\"\\s+\", names=col_names, header=None)\n",
    "df['CANCER'] = df['SEVERITY'].apply(lambda x: 1 if x in ['B', 'M'] else 0)\n",
    "\n",
    "images_path = \"all-mias\"\n",
    "\n",
    "all_images = []\n",
    "all_labels = []\n",
    "\n",
    "for filename in sorted(os.listdir(images_path)):\n",
    "    if filename.lower().endswith('.pgm'):\n",
    "        ref_num = os.path.splitext(filename)[0]\n",
    "        record = df[df['REFNUM'] == ref_num]\n",
    "\n",
    "        if not record.empty:\n",
    "            full_path = os.path.join(images_path, filename)\n",
    "            img_array = cv2.imread(full_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            labels = record['CANCER'].iloc[0]\n",
    "\n",
    "            all_images.append(img_array)\n",
    "            all_labels.append(labels)\n",
    "\n",
    "print(\"Besham ta alan ke chedesh ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2407da49-eb76-46ad-9156-8a5e756f1e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image list 324\n",
      "Labels list 324\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REFNUM</th>\n",
       "      <th>BG</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>SEVERITY</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>RADIUS</th>\n",
       "      <th>CANCER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>REFNUM</td>\n",
       "      <td>BG</td>\n",
       "      <td>CLASS</td>\n",
       "      <td>SEVERITY</td>\n",
       "      <td>X</td>\n",
       "      <td>Y</td>\n",
       "      <td>RADIUS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mdb001</td>\n",
       "      <td>G</td>\n",
       "      <td>CIRC</td>\n",
       "      <td>B</td>\n",
       "      <td>535</td>\n",
       "      <td>425</td>\n",
       "      <td>197</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mdb002</td>\n",
       "      <td>G</td>\n",
       "      <td>CIRC</td>\n",
       "      <td>B</td>\n",
       "      <td>522</td>\n",
       "      <td>280</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mdb003</td>\n",
       "      <td>D</td>\n",
       "      <td>NORM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mdb004</td>\n",
       "      <td>D</td>\n",
       "      <td>NORM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   REFNUM  BG  CLASS  SEVERITY    X    Y  RADIUS  CANCER\n",
       "0  REFNUM  BG  CLASS  SEVERITY    X    Y  RADIUS       0\n",
       "1  mdb001   G   CIRC         B  535  425     197       1\n",
       "2  mdb002   G   CIRC         B  522  280      69       1\n",
       "3  mdb003   D   NORM       NaN  NaN  NaN     NaN       0\n",
       "4  mdb004   D   NORM       NaN  NaN  NaN     NaN       0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Image list {len(all_images)}\")\n",
    "print(f\"Labels list {len(all_labels)}\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2a491c94-6d76-49be-b996-b16845b55681",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "andaki sabr sahar nazdik ast...\n",
      "Normalazation process has been Done!.\n",
      "Start of the histogram processing...\n"
     ]
    }
   ],
   "source": [
    "# img = cv2.imread('all-mias/mdb005.pgm', cv2.IMREAD_GRAYSCALE)\n",
    "# print(img.shape, img.dtype)\n",
    "# img.max()\n",
    "# plt.imshow(img, cmap='gray')\n",
    "normalaized_img = []\n",
    "print(\"Computing the image and histogram for pooling and classification...\")\n",
    "\n",
    "for img in all_images:\n",
    "    # Normalazing the image \n",
    "    if img.max() > img.min():\n",
    "        n_img = ((img - img.min()) / (img.max() - img.min()) * 255) \n",
    "    else:\n",
    "        n_img = img\n",
    "    # normalaized_img.append(n_img)\n",
    "    P = 8\n",
    "    R = 1\n",
    "    method = 'uniform'\n",
    "    LBP = feature.local_binary_pattern(n_img, P, R, method)\n",
    "\n",
    "    bins_num = int(n_img.max()) + 1\n",
    "    normalaized_img.append(bins_num)\n",
    "# print(LBP.min())\n",
    "\n",
    "print(\"Normalazation process has been Done!.\")\n",
    "\n",
    "print(\"Start of the histogram processing...\")\n",
    "def compute_histograms_for_each_region(normalaized_img, G=6):\n",
    "    #compute th histogram from 255 in image size to 59 =>  reduce the number of bins\n",
    "    histogram = []\n",
    "    # Pooling the image in to 6 x 6\n",
    "    H = 1020 # height\n",
    "    W = 1020 # width\n",
    "    #G = 6 # Number of Grid 6 * 6 \n",
    "    hor = int(H / G) # height of each region\n",
    "    wor = int(W / G) # width of each region\n",
    "\n",
    "# Pooling the data into 6 * 6 regions\n",
    "    for i in range(G):\n",
    "        for j in range(G):\n",
    "            row_start = i * hor\n",
    "            row_end = (i + 1) * hor\n",
    "            col_start = j * wor\n",
    "            col_end = (i + 1) * wor\n",
    "            region = img[row_start:row_end, col_start:col_end]\n",
    "\n",
    "        hist, _ = np.histogram(n_img.ravel(), bins=bins_num, range=(0, bins_num))\n",
    "        histogram.append(hist)\n",
    "\n",
    "    return histogram\n",
    "x_list = []\n",
    "y_list = []\n",
    "for img, label in zip(all_images, all_labels):\n",
    "    histogram = compute_histograms_for_each_region(img)\n",
    "\n",
    "    f_vector = np.concatenate(histogram)\n",
    "\n",
    "    x_list.append(f_vector)\n",
    "    y_list.append(label)\n",
    "\n",
    "X = np.array(x_list)\n",
    "y = np.array(y_list)\n",
    "\n",
    "# print(hor)\n",
    "\n",
    "print(\"Function has been done successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c24b2e4c-c905-4203-8d25-4cf156e05fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[383114     38   7288 ...    100      0      8]\n",
      " [383114     38   7288 ...    100      0      8]\n",
      " [383114     38   7288 ...    100      0      8]\n",
      " ...\n",
      " [383114     38   7288 ...    100      0      8]\n",
      " [383114     38   7288 ...    100      0      8]\n",
      " [383114     38   7288 ...    100      0      8]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "16fe903d-84d0-47a5-881e-9ba33d5cdeba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique LBP codes in this image: [0. 1. 2. 3. 4. 5. 6. 7. 8. 9.]\n"
     ]
    }
   ],
   "source": [
    "unique_codes = np.unique(LBP)\n",
    "print(\"Unique LBP codes in this image:\", unique_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ebcf253d-6b18-468b-a6d6-3bf140f3a79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,    # for reproducibility\n",
    "    stratify=y          # preserves class ratios\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8827f4dd-c486-45e1-bccc-2a8479b5f66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=1500,\n",
    "    max_depth=None,\n",
    "    min_samples_split=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# 5. Predict\n",
    "y_pred = rf_model.predict(X_test)\n",
    "y_prob = rf_model.predict_proba(X_test)  # if you need probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7daffadf-6e53-4e49-8f76-c98c3039f6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      1.00      0.79        42\n",
      "           1       0.00      0.00      0.00        23\n",
      "\n",
      "    accuracy                           0.65        65\n",
      "   macro avg       0.32      0.50      0.39        65\n",
      "weighted avg       0.42      0.65      0.51        65\n",
      "\n",
      "Confusion Matrix:\n",
      "[[42  0]\n",
      " [23  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Python3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Python3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9bffb2eb-6d23-4f51-ab39-d1a8109a0742",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Python3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Python3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      1.00      0.79        42\n",
      "           1       0.00      0.00      0.00        23\n",
      "\n",
      "    accuracy                           0.65        65\n",
      "   macro avg       0.32      0.50      0.39        65\n",
      "weighted avg       0.42      0.65      0.51        65\n",
      "\n",
      "Confusion Matrix:\n",
      " [[42  0]\n",
      " [23  0]]\n",
      "ROC AUC: 0.5\n",
      "Best SVM params: {'C': 0.1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Best CV score: 0.49588881706528765\n",
      "Tuned SVM report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      1.00      0.79        42\n",
      "           1       0.00      0.00      0.00        23\n",
      "\n",
      "    accuracy                           0.65        65\n",
      "   macro avg       0.32      0.50      0.39        65\n",
      "weighted avg       0.42      0.65      0.51        65\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Python3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Python3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing  import StandardScaler\n",
    "from sklearn.svm            import SVC\n",
    "from sklearn.metrics        import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# 1. Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# 2. Scale features (fit on train, apply to both)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "# 3. Instantiate SVM\n",
    "svm = SVC(\n",
    "    kernel='rbf',    # radial basis function\n",
    "    C=1.0,           # regularization parameter\n",
    "    gamma='scale',   # 1 / (n_features * X.var())\n",
    "    probability=True,# if you need predict_proba()\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 4. Train\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 5. Predict\n",
    "y_pred = svm.predict(X_test_scaled)\n",
    "y_prob = svm.predict_proba(X_test_scaled)[:, 1]  # for binary or one‑vs‑rest\n",
    "\n",
    "# 6. Evaluate\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "try:\n",
    "    print(\"ROC AUC:\", roc_auc_score(y_test, y_prob, multi_class='ovr'))\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# 7. (Optional) Hyperparameter tuning\n",
    "param_grid = {\n",
    "    'C':     [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 0.01, 0.001],\n",
    "    'kernel': ['rbf', 'linear']\n",
    "}\n",
    "grid = GridSearchCV(\n",
    "    svm, param_grid,\n",
    "    cv=5,\n",
    "    scoring='f1_weighted',\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "print(\"Best SVM params:\", grid.best_params_)\n",
    "print(\"Best CV score:\", grid.best_score_)\n",
    "\n",
    "# After tuning, you can re‑evaluate the best model:\n",
    "best_svm = grid.best_estimator_\n",
    "y_pred_best = best_svm.predict(X_test_scaled)\n",
    "print(\"Tuned SVM report:\\n\", classification_report(y_test, y_pred_best))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "031103e6-a31f-4f14-b794-121b217bd601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12,4))\n",
    "# plt.plot(n_img)\n",
    "# plt.title(\"LBP Histogram\")\n",
    "# plt.xlabel(\"LBP code\")\n",
    "# plt.ylabel(\"Frequency\")\n",
    "# plt.grid()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "05ce245c-19c8-4e0a-8d65-d76a2f30bc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "# axes[0].imshow(n_img, cmap='gray')\n",
    "# axes[0].set_title(\"Original\")\n",
    "# axes[0].axis('off')\n",
    "\n",
    "# axes[1].imshow(LBP, cmap='gray')\n",
    "# axes[1].set_title(f\"LBP (P={P}, R={R})\")\n",
    "# axes[1].axis('off')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "956078d8-16c9-4909-a947-533ac60301a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing data...\n",
      "Data loading complete.\n",
      "Starting feature extraction with LBP...\n",
      "Feature extraction complete.\n",
      "Shape of our feature matrix X: (324, 360)\n",
      "Shape of our label vector y: (324,)\n",
      "\n",
      "Splitting data and training Random Forest model...\n",
      "\n",
      "--- Model Evaluation Results ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Normal (0)       0.60      0.79      0.68        42\n",
      "  Cancer (1)       0.10      0.04      0.06        23\n",
      "\n",
      "    accuracy                           0.52        65\n",
      "   macro avg       0.35      0.41      0.37        65\n",
      "weighted avg       0.42      0.52      0.46        65\n",
      "\n",
      "Confusion Matrix:\n",
      "[[33  9]\n",
      " [22  1]]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import feature\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# --- 1. Load Data (Your existing code, which is correct) ---\n",
    "print(\"Loading and preparing data...\")\n",
    "col_names = ['REFNUM', 'BG', 'CLASS', 'SEVERITY', 'X', 'Y', 'RADIUS']\n",
    "df = pd.read_csv('data2.txt', sep=\"\\s+\", names=col_names, header=None)\n",
    "df['CANCER'] = df['SEVERITY'].apply(lambda x: 1 if x in ['B', 'M'] else 0)\n",
    "\n",
    "images_path = \"all-mias\"\n",
    "all_images = []\n",
    "all_labels = []\n",
    "\n",
    "for filename in sorted(os.listdir(images_path)):\n",
    "    if filename.lower().endswith('.pgm'):\n",
    "        ref_num = os.path.splitext(filename)[0]\n",
    "        record = df[df['REFNUM'] == ref_num]\n",
    "        if not record.empty:\n",
    "            full_path = os.path.join(images_path, filename)\n",
    "            img_array = cv2.imread(full_path, cv2.IMREAD_GRAYSCALE)\n",
    "            labels = record['CANCER'].iloc[0]\n",
    "            all_images.append(img_array)\n",
    "            all_labels.append(labels)\n",
    "print(\"Data loading complete.\")\n",
    "\n",
    "# --- 2. Corrected LBP Feature Extraction ---\n",
    "print(\"Starting feature extraction with LBP...\")\n",
    "\n",
    "def create_lbp_feature_vector(image, P=8, R=3, grid_cells=6):\n",
    "    \"\"\"\n",
    "    Computes the Local Binary Pattern for an image, divides it into a grid,\n",
    "    and returns a concatenated histogram of all grid cells.\n",
    "    \n",
    "    Args:\n",
    "        image (np.array): The input grayscale image.\n",
    "        P (int): Number of circularly symmetric neighbor set points.\n",
    "        R (int): Radius of circle.\n",
    "        grid_cells (int): The number of cells in one dimension (e.g., 6 for a 6x6 grid).\n",
    "\n",
    "    Returns:\n",
    "        np.array: A single, flattened feature vector for the image.\n",
    "    \"\"\"\n",
    "    # 1. Compute the LBP image\n",
    "    # The 'uniform' method is robust and creates 10 bins (P+2)\n",
    "    lbp_image = feature.local_binary_pattern(image, P, R, method='uniform')\n",
    "    \n",
    "    # 2. Calculate histogram properties\n",
    "    # For 'uniform' LBP, the number of bins is P + 2.\n",
    "    num_bins = int(lbp_image.max() + 1)\n",
    "    \n",
    "    # 3. Divide the LBP image into a grid and compute histograms\n",
    "    h, w = lbp_image.shape\n",
    "    cell_h, cell_w = h // grid_cells, w // grid_cells\n",
    "    \n",
    "    full_histogram = []\n",
    "    for i in range(grid_cells):\n",
    "        for j in range(grid_cells):\n",
    "            # Extract the region from the LBP image\n",
    "            region = lbp_image[i*cell_h:(i+1)*cell_h, j*cell_w:(j+1)*cell_w]\n",
    "            \n",
    "            # Compute the histogram for this region\n",
    "            # The range is from 0 to num_bins.\n",
    "            hist, _ = np.histogram(region, bins=num_bins, range=(0, num_bins))\n",
    "            \n",
    "            # Add the region's histogram to our list\n",
    "            full_histogram.append(hist)\n",
    "            \n",
    "    # 4. Concatenate all regional histograms into a single feature vector\n",
    "    return np.concatenate(full_histogram)\n",
    "\n",
    "# Now, create the feature matrix (X) and label vector (y)\n",
    "X_features = []\n",
    "y_labels = []\n",
    "\n",
    "for img, label in zip(all_images, all_labels):\n",
    "    # For each image, compute its LBP feature vector\n",
    "    lbp_features = create_lbp_feature_vector(img)\n",
    "    X_features.append(lbp_features)\n",
    "    y_labels.append(label)\n",
    "\n",
    "# Convert lists to NumPy arrays for scikit-learn\n",
    "X = np.array(X_features)\n",
    "y = np.array(y_labels)\n",
    "\n",
    "print(\"Feature extraction complete.\")\n",
    "print(f\"Shape of our feature matrix X: {X.shape}\")\n",
    "print(f\"Shape of our label vector y: {y.shape}\")\n",
    "\n",
    "\n",
    "# --- 3. Train and Evaluate the Random Forest (Your existing code, now with good features) ---\n",
    "print(\"\\nSplitting data and training Random Forest model...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=150,\n",
    "    max_depth=None,\n",
    "    min_samples_split=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "print(\"\\n--- Model Evaluation Results ---\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Normal (0)', 'Cancer (1)']))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94369062-f150-44c6-952b-a7719d04f3d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
