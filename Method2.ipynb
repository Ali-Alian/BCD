{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0fe6a8b-ba26-4603-be32-4c58aa3219c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] imbalanced-learn not available. Script will use class_weight='balanced' instead of SMOTE.\n",
      "[INFO] Reading metadata...\n",
      "[INFO] Found 324 image files in all-mias\n",
      "[INFO] median radius: 43\n",
      "[INFO] Extracted 324 ROIs (CLAHE applied per-ROI).\n",
      "[INFO] Computing LBP maps for radii: [1, 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python3\\Lib\\site-packages\\skimage\\feature\\texture.py:385: UserWarning: Applying `local_binary_pattern` to floating-point images may give unexpected results when small numerical differences between adjacent pixels are present. It is recommended to use this function with images of integer dtype.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Determined LBP n_bins = 10\n",
      "[INFO] Building pooled LBP histograms and GLCM features for each ROI...\n",
      "[INFO] Feature shapes: X_glcm (324, 12) X_lbp (324, 180) combined X (324, 192)\n",
      "Label counts: Counter({np.int64(0): 207, np.int64(1): 117})\n",
      "[INFO] Train samples: 258 Test samples: 66\n",
      "[INFO] Running inner grid-search for RandomForest...\n",
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n",
      "[INFO] Best RandomForest params: {'clf__max_depth': 12, 'clf__min_samples_leaf': 6, 'clf__n_estimators': 300}\n",
      "[INFO] Running inner grid-search for SVM...\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "[INFO] Best SVM params: {'clf__C': 1, 'clf__gamma': 0.01}\n",
      "\n",
      "=== Held-out evaluation: RandomForest (best) ===\n",
      "Accuracy: 0.8333333333333334\n",
      "Recall: 0.75\n",
      "AUC: 0.8978174603174602\n",
      "Confusion Matrix:\n",
      " [[37  5]\n",
      " [ 6 18]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87        42\n",
      "           1       0.78      0.75      0.77        24\n",
      "\n",
      "    accuracy                           0.83        66\n",
      "   macro avg       0.82      0.82      0.82        66\n",
      "weighted avg       0.83      0.83      0.83        66\n",
      "\n",
      "\n",
      "=== Held-out evaluation: SVM (best) ===\n",
      "Accuracy: 0.8484848484848485\n",
      "Recall: 0.75\n",
      "AUC: 0.8978174603174603\n",
      "Confusion Matrix:\n",
      " [[38  4]\n",
      " [ 6 18]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88        42\n",
      "           1       0.82      0.75      0.78        24\n",
      "\n",
      "    accuracy                           0.85        66\n",
      "   macro avg       0.84      0.83      0.83        66\n",
      "weighted avg       0.85      0.85      0.85        66\n",
      "\n",
      "\n",
      "Top 30 feature importances (index, name, importance):\n",
      "40 LBP_R1_r02_c008 0.0372\n",
      "0 contrast_mean 0.0369\n",
      "1 contrast_var 0.0361\n",
      "48 LBP_R1_r03_c006 0.0311\n",
      "3 dissimilarity_var 0.0307\n",
      "11 correlation_var 0.0305\n",
      "5 homogeneity_var 0.0282\n",
      "39 LBP_R1_r02_c007 0.0278\n",
      "28 LBP_R1_r01_c006 0.0269\n",
      "69 LBP_R1_r05_c007 0.0263\n",
      "65 LBP_R1_r05_c003 0.0245\n",
      "47 LBP_R1_r03_c005 0.0233\n",
      "44 LBP_R1_r03_c002 0.0223\n",
      "63 LBP_R1_r05_c001 0.0223\n",
      "32 LBP_R1_r02_c000 0.0219\n",
      "64 LBP_R1_r05_c002 0.0218\n",
      "34 LBP_R1_r02_c002 0.0215\n",
      "24 LBP_R1_r01_c002 0.0214\n",
      "18 LBP_R1_r00_c006 0.0213\n",
      "2 dissimilarity_mean 0.0206\n",
      "59 LBP_R1_r04_c007 0.0205\n",
      "23 LBP_R1_r01_c001 0.0187\n",
      "20 LBP_R1_r00_c008 0.0176\n",
      "55 LBP_R1_r04_c003 0.0168\n",
      "57 LBP_R1_r04_c005 0.0161\n",
      "62 LBP_R1_r05_c000 0.0147\n",
      "72 LBP_R1_r06_c000 0.0134\n",
      "35 LBP_R1_r02_c003 0.0134\n",
      "61 LBP_R1_r04_c009 0.0127\n",
      "14 LBP_R1_r00_c002 0.0124\n",
      "[INFO] RF held-out best threshold for recall (example): 0.10, recall=1.000\n",
      "Confusion at chosen threshold:\n",
      " [[10 32]\n",
      " [ 0 24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.24      0.38        42\n",
      "           1       0.43      1.00      0.60        24\n",
      "\n",
      "    accuracy                           0.52        66\n",
      "   macro avg       0.71      0.62      0.49        66\n",
      "weighted avg       0.79      0.52      0.46        66\n",
      "\n",
      "\n",
      "[INFO] Done. Results and models saved to ./results/\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "improved_lbp_glcm_pipeline.py\n",
    "\n",
    "- ROI extraction (consistent normal/abnormal)\n",
    "- per-ROI CLAHE\n",
    "- LBP pooled features (adaptive bins)\n",
    "- quantized GLCM features\n",
    "- SelectKBest feature selection inside pipeline\n",
    "- SMOTE inside CV if available, else class_weight fallback\n",
    "- nested GroupKFold (inner) GridSearchCV and held-out GroupShuffleSplit\n",
    "- prints and saves results to ./results/\n",
    "\"\"\"\n",
    "import os\n",
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.feature import local_binary_pattern, graycomatrix, graycoprops\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GroupKFold, GroupShuffleSplit, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, recall_score, roc_auc_score, classification_report, confusion_matrix\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# try to import imblearn (SMOTE & pipeline). If missing fallback will be used.\n",
    "USE_SMOTE = True\n",
    "try:\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "except Exception:\n",
    "    USE_SMOTE = False\n",
    "    ImbPipeline = None\n",
    "    print(\"[WARN] imbalanced-learn not available. Script will use class_weight='balanced' instead of SMOTE.\")\n",
    "\n",
    "# ----------------- USER CONFIG -----------------\n",
    "IMAGES_DIR = \"all-mias\"\n",
    "META_PATH = \"data2.txt\"\n",
    "IMAGE_SIZE = 1024               # MIAS image size reference\n",
    "TARGET_SIZE = 128               # None to keep native crop size, or int to resize (128 recommended)\n",
    "MIN_SIDE = 32                   # pad if ROI smaller\n",
    "CLAHE_CLIP = 2.0\n",
    "CLAHE_TILE = (8, 8)\n",
    "\n",
    "# LBP params\n",
    "P = 8\n",
    "# You can enable multi-scale LBP; set RB list to include desired radii:\n",
    "LBP_RADII = [1, 3]             # set to [3] or [1,3] for multiscale\n",
    "LBP_METHOD = 'uniform'\n",
    "\n",
    "# pooling grid for LBP\n",
    "POOL_G = 3                      # 3x3 pooling (try 3,4,6). smaller reduces dims\n",
    "\n",
    "# GLCM params (quantized)\n",
    "GLCM_LEVELS = 32\n",
    "GLCM_DISTANCES = [1, 3]\n",
    "GLCM_ANGLES = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
    "\n",
    "# CV params\n",
    "OUTER_SPLITS = 5\n",
    "INNER_SPLITS = 4\n",
    "RANDOM_STATE = 42\n",
    "HOLDOUT_TEST_SIZE = 0.2\n",
    "\n",
    "# Grid search params\n",
    "RF_PARAM_GRID = {\n",
    "    'clf__n_estimators': [100, 300],\n",
    "    'clf__max_depth': [6, 12, None],\n",
    "    'clf__min_samples_leaf': [2, 6],\n",
    "}\n",
    "SVM_PARAM_GRID = {\n",
    "    'clf__C': [0.1, 1, 10],\n",
    "    'clf__gamma': ['scale', 0.01],\n",
    "}\n",
    "\n",
    "SELECT_K = 80  # number of features to keep with SelectKBest (set based on experiments)\n",
    "\n",
    "# ------------------------------------------------\n",
    "\n",
    "# ---------- helper functions ----------\n",
    "def read_metadata(meta_path):\n",
    "    col_names = ['REFNUM', 'BG', 'CLASS', 'SEVERITY', 'X', 'Y', 'RADIUS']\n",
    "    df = pd.read_csv(meta_path, sep=r\"\\s+\", names=col_names, header=None)\n",
    "    df['CANCER'] = df['SEVERITY'].apply(lambda x: 1 if x in ['B', 'M'] else 0)\n",
    "    return df\n",
    "\n",
    "def ref_to_patient_id(ref):\n",
    "    try:\n",
    "        n = int(''.join(ch for ch in ref if ch.isdigit()))\n",
    "        return (n - 1) // 2\n",
    "    except:\n",
    "        return ref\n",
    "\n",
    "def clamp(a, lo, hi):\n",
    "    return max(lo, min(hi, a))\n",
    "\n",
    "def crop_square(img, cx, cy, r):\n",
    "    H, W = img.shape\n",
    "    x0 = clamp(cx - r, 0, W)\n",
    "    x1 = clamp(cx + r, 0, W)\n",
    "    y0 = clamp(cy - r, 0, H)\n",
    "    y1 = clamp(cy + r, 0, H)\n",
    "    if x1 <= x0 or y1 <= y0:\n",
    "        return img.copy()\n",
    "    return img[y0:y1, x0:x1]\n",
    "\n",
    "def pad_to_min_side(img, min_side):\n",
    "    h, w = img.shape\n",
    "    top = bottom = left = right = 0\n",
    "    if h < min_side:\n",
    "        extra = min_side - h\n",
    "        top = extra // 2\n",
    "        bottom = extra - top\n",
    "    if w < min_side:\n",
    "        extra = min_side - w\n",
    "        left = extra // 2\n",
    "        right = extra - left\n",
    "    if any([top, bottom, left, right]):\n",
    "        img = cv2.copyMakeBorder(img, top, bottom, left, right, borderType=cv2.BORDER_REFLECT)\n",
    "    return img\n",
    "\n",
    "def apply_clahe_to_roi(roi, clip=2.0, tile=(8,8)):\n",
    "    if roi.dtype != np.uint8:\n",
    "        if roi.max() <= 1.0:\n",
    "            roi_u8 = (roi * 255).astype(np.uint8)\n",
    "        else:\n",
    "            roi_u8 = roi.astype(np.uint8)\n",
    "    else:\n",
    "        roi_u8 = roi\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip, tileGridSize=tile)\n",
    "    return clahe.apply(roi_u8)\n",
    "\n",
    "def pooled_lbp_matrix(lbp_map, G=3, n_bins=None):\n",
    "    H, W = lbp_map.shape\n",
    "    row_edges = np.linspace(0, H, G+1, dtype=int)\n",
    "    col_edges = np.linspace(0, W, G+1, dtype=int)\n",
    "    rows = []\n",
    "    # use dynamic n_bins from caller\n",
    "    for i in range(G):\n",
    "        for j in range(G):\n",
    "            r0, r1 = row_edges[i], row_edges[i+1]\n",
    "            c0, c1 = col_edges[j], col_edges[j+1]\n",
    "            region = lbp_map[r0:r1, c0:c1]\n",
    "            # ensure integer codes\n",
    "            region_int = region.ravel().astype(int)\n",
    "            if n_bins is None:\n",
    "                n_bins_reg = int(region_int.max()) + 1 if region_int.size>0 else 1\n",
    "                hist = np.bincount(region_int, minlength=n_bins_reg).astype(float)\n",
    "            else:\n",
    "                hist = np.bincount(region_int, minlength=n_bins).astype(float)\n",
    "            if hist.sum() > 0:\n",
    "                hist /= hist.sum()\n",
    "            # if n_bins is provided, hist length is fixed\n",
    "            if n_bins is not None and len(hist) < n_bins:\n",
    "                # pad\n",
    "                hist = np.pad(hist, (0, n_bins - len(hist)), mode='constant')\n",
    "            rows.append(hist)\n",
    "    M = np.vstack(rows)\n",
    "    return M\n",
    "\n",
    "def quantize_img_levels(img, levels=32):\n",
    "    a = img.astype(np.float32)\n",
    "    if a.max() > 1.1:\n",
    "        a = a / 255.0\n",
    "    q = np.floor(a * (levels - 1) + 0.5).astype(np.uint8)\n",
    "    return q\n",
    "\n",
    "def extract_glcm_features(patch, distances, angles, levels):\n",
    "    q = quantize_img_levels(patch, levels=levels)\n",
    "    glcm = graycomatrix(q, distances=distances, angles=angles, levels=levels, symmetric=True, normed=True)\n",
    "    props = ['contrast', 'dissimilarity', 'homogeneity', 'ASM', 'energy', 'correlation']\n",
    "    feats = []\n",
    "    for p in props:\n",
    "        mat = graycoprops(glcm, p)\n",
    "        feats.append(float(np.nanmean(mat)))\n",
    "        feats.append(float(np.nanvar(mat)))\n",
    "    return np.array(feats, dtype=float)  # length = 2 * len(props)\n",
    "\n",
    "# ---------- main ----------\n",
    "def main():\n",
    "    print(\"[INFO] Reading metadata...\")\n",
    "    df = read_metadata(META_PATH)\n",
    "    refs = sorted([f for f in os.listdir(IMAGES_DIR) if f.lower().endswith('.pgm')])\n",
    "    print(f\"[INFO] Found {len(refs)} image files in {IMAGES_DIR}\")\n",
    "    radii = pd.to_numeric(df['RADIUS'], errors='coerce').dropna()\n",
    "    median_radius = int(radii.median()) if radii.size > 0 else 48\n",
    "    print(\"[INFO] median radius:\", median_radius)\n",
    "\n",
    "    # ROI extraction\n",
    "    rois = []\n",
    "    rois_raw = []   # keep a raw copy (pre-CLAHE) for comparisons\n",
    "    labels = []\n",
    "    groups = []\n",
    "    ref_list = []\n",
    "\n",
    "    for fname in refs:\n",
    "        ref = os.path.splitext(fname)[0]\n",
    "        row = df[df['REFNUM'] == ref]\n",
    "        if row.empty:\n",
    "            continue\n",
    "        row = row.iloc[0]\n",
    "        img_path = os.path.join(IMAGES_DIR, fname)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            print(\"[WARN] cannot read\", img_path); continue\n",
    "\n",
    "        label = int(row['CANCER'])\n",
    "        x, y, r = row['X'], row['Y'], row['RADIUS']\n",
    "\n",
    "        if label == 1 and pd.notna(x) and pd.notna(y) and pd.notna(r):\n",
    "            cx = int(float(x))\n",
    "            cy = int(IMAGE_SIZE - float(y))  # convert bottom-left MIAS to top-left indexing\n",
    "            rr = int(max(int(r), 8))\n",
    "            roi = crop_square(img, cx, cy, rr)\n",
    "        else:\n",
    "            cx = img.shape[1] // 2\n",
    "            cy = img.shape[0] // 2\n",
    "            rr = median_radius\n",
    "            roi = crop_square(img, cx, cy, rr)\n",
    "\n",
    "        roi = pad_to_min_side(roi, MIN_SIDE)\n",
    "        rois_raw.append(roi.copy())\n",
    "        roi_clahe = apply_clahe_to_roi(roi, clip=CLAHE_CLIP, tile=CLAHE_TILE)\n",
    "        if TARGET_SIZE is not None:\n",
    "            if roi_clahe.shape[0] > TARGET_SIZE or roi_clahe.shape[1] > TARGET_SIZE:\n",
    "                interp = cv2.INTER_AREA\n",
    "            else:\n",
    "                interp = cv2.INTER_LINEAR\n",
    "            roi_clahe = cv2.resize(roi_clahe, (TARGET_SIZE, TARGET_SIZE), interpolation=interp)\n",
    "\n",
    "        rois.append(roi_clahe)\n",
    "        labels.append(label)\n",
    "        groups.append(ref_to_patient_id(ref))\n",
    "        ref_list.append(ref)\n",
    "\n",
    "    print(f\"[INFO] Extracted {len(rois)} ROIs (CLAHE applied per-ROI).\")\n",
    "    if len(rois) == 0:\n",
    "        raise RuntimeError(\"No ROIs extracted - check dataset paths and metadata.\")\n",
    "\n",
    "    # Compute LBP maps for each radius and collect global max code to set fixed bins\n",
    "    print(\"[INFO] Computing LBP maps for radii:\", LBP_RADII)\n",
    "    lbp_maps_per_radius = {r: [] for r in LBP_RADII}\n",
    "    max_code = 0\n",
    "    for roi in rois:\n",
    "        # ensure float input\n",
    "        img_float = roi.astype(np.float32)\n",
    "        for r in LBP_RADII:\n",
    "            lbp_map = local_binary_pattern(img_float, P, r, method=LBP_METHOD)\n",
    "            # LBP returns floats; convert to ints safely\n",
    "            lbp_int = np.round(lbp_map).astype(int)\n",
    "            lbp_maps_per_radius[r].append(lbp_int)\n",
    "            max_code = max(max_code, int(lbp_int.max()))\n",
    "\n",
    "    n_lbp_bins = max_code + 1\n",
    "    print(f\"[INFO] Determined LBP n_bins = {n_lbp_bins}\")\n",
    "\n",
    "    # Build feature matrices\n",
    "    X_lbp_parts = []  # will contain per-radius pooled LBP flattened\n",
    "    X_glcm = []\n",
    "    print(\"[INFO] Building pooled LBP histograms and GLCM features for each ROI...\")\n",
    "    for idx, roi in enumerate(rois):\n",
    "        roi_uint8 = roi.astype(np.uint8)\n",
    "        # LBP pooled for each radius, concatenate\n",
    "        lbp_concat = []\n",
    "        for r in LBP_RADII:\n",
    "            lbp_map = lbp_maps_per_radius[r][idx]\n",
    "            M = pooled_lbp_matrix(lbp_map, G=POOL_G, n_bins=n_lbp_bins)  # shape (G*G, n_bins)\n",
    "            lbp_concat.append(M.ravel())\n",
    "        lbp_vec = np.hstack(lbp_concat)\n",
    "        X_lbp_parts.append(lbp_vec)\n",
    "\n",
    "        # GLCM features (quantized)\n",
    "        glcm_feats = extract_glcm_features(roi_uint8, distances=GLCM_DISTANCES, angles=GLCM_ANGLES, levels=GLCM_LEVELS)\n",
    "        X_glcm.append(glcm_feats)\n",
    "\n",
    "    X_lbp = np.vstack(X_lbp_parts)\n",
    "    X_glcm = np.vstack(X_glcm)\n",
    "    X = np.hstack([X_glcm, X_lbp])\n",
    "    y = np.array(labels)\n",
    "    groups_arr = np.array(groups)\n",
    "\n",
    "    print(\"[INFO] Feature shapes: X_glcm\", X_glcm.shape, \"X_lbp\", X_lbp.shape, \"combined X\", X.shape)\n",
    "    print(\"Label counts:\", Counter(y))\n",
    "    # safety check\n",
    "    if np.isnan(X).any():\n",
    "        raise RuntimeError(\"NaN found in features!\")\n",
    "\n",
    "    # Create feature names for mapping importances\n",
    "    glcm_props = ['contrast', 'dissimilarity', 'homogeneity', 'ASM', 'energy', 'correlation']\n",
    "    glcm_names = []\n",
    "    for p in glcm_props:\n",
    "        glcm_names += [f\"{p}_mean\", f\"{p}_var\"]\n",
    "    lbp_names = []\n",
    "    region_count = POOL_G * POOL_G\n",
    "    for r in LBP_RADII:\n",
    "        for region_ix in range(region_count):\n",
    "            for code in range(n_lbp_bins):\n",
    "                lbp_names.append(f\"LBP_R{r}_r{region_ix:02d}_c{code:03d}\")\n",
    "    feature_names = glcm_names + lbp_names\n",
    "    assert X.shape[1] == len(feature_names)\n",
    "\n",
    "    # ---------------- train/test split (group-aware held-out) ----------------\n",
    "    gss = GroupShuffleSplit(n_splits=1, test_size=HOLDOUT_TEST_SIZE, random_state=RANDOM_STATE)\n",
    "    train_idx, test_idx = next(gss.split(X, y, groups_arr))\n",
    "    X_tr, X_te = X[train_idx], X[test_idx]\n",
    "    y_tr, y_te = y[train_idx], y[test_idx]\n",
    "    groups_tr, groups_te = groups_arr[train_idx], groups_arr[test_idx]\n",
    "    print(\"[INFO] Train samples:\", X_tr.shape[0], \"Test samples:\", X_te.shape[0])\n",
    "\n",
    "    # Build pipelines: keep feature selection inside pipeline (SelectKBest)\n",
    "    selector = SelectKBest(mutual_info_classif, k=min(SELECT_K, X_tr.shape[1]))\n",
    "\n",
    "    # If SMOTE available, put inside ImbPipeline, else use sklearn Pipeline and class_weight\n",
    "    if USE_SMOTE:\n",
    "        rf_pipeline = ImbPipeline([\n",
    "            ('smote', SMOTE(random_state=RANDOM_STATE)),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('select', selector),\n",
    "            ('clf', RandomForestClassifier(random_state=RANDOM_STATE, class_weight='balanced', n_jobs=-1))\n",
    "        ])\n",
    "        svm_pipeline = ImbPipeline([\n",
    "            ('smote', SMOTE(random_state=RANDOM_STATE)),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('select', selector),\n",
    "            ('clf', SVC(probability=True, class_weight='balanced', random_state=RANDOM_STATE))\n",
    "        ])\n",
    "    else:\n",
    "        rf_pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('select', selector),\n",
    "            ('clf', RandomForestClassifier(random_state=RANDOM_STATE, class_weight='balanced', n_jobs=-1))\n",
    "        ])\n",
    "        svm_pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('select', selector),\n",
    "            ('clf', SVC(probability=True, class_weight='balanced', random_state=RANDOM_STATE))\n",
    "        ])\n",
    "\n",
    "    # inner CV uses GroupKFold on training set\n",
    "    def run_gridsearch(pipeline, param_grid, X_train, y_train, groups_train, name=\"model\"):\n",
    "        inner_cv = GroupKFold(n_splits=INNER_SPLITS)\n",
    "        gs = GridSearchCV(pipeline, param_grid, cv=inner_cv.split(X_train, y_train, groups_train),\n",
    "                          scoring='roc_auc', n_jobs=-1, verbose=1)\n",
    "        gs.fit(X_train, y_train)\n",
    "        print(f\"[INFO] Best {name} params:\", gs.best_params_)\n",
    "        return gs.best_estimator_, gs\n",
    "\n",
    "    print(\"[INFO] Running inner grid-search for RandomForest...\")\n",
    "    best_rf, rf_gs = run_gridsearch(rf_pipeline, RF_PARAM_GRID, X_tr, y_tr, groups_tr, name=\"RandomForest\")\n",
    "\n",
    "    print(\"[INFO] Running inner grid-search for SVM...\")\n",
    "    best_svm, svm_gs = run_gridsearch(svm_pipeline, SVM_PARAM_GRID, X_tr, y_tr, groups_tr, name=\"SVM\")\n",
    "\n",
    "    # Evaluate on held-out test set\n",
    "    def evaluate_model(est, X_test, y_test, name=\"model\"):\n",
    "        y_pred = est.predict(X_test)\n",
    "        if hasattr(est, \"predict_proba\"):\n",
    "            try:\n",
    "                y_prob = est.predict_proba(X_test)[:, 1]\n",
    "            except Exception:\n",
    "                y_prob = None\n",
    "        else:\n",
    "            y_prob = None\n",
    "        print(f\"\\n=== Held-out evaluation: {name} ===\")\n",
    "        print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "        print(\"Recall:\", recall_score(y_test, y_pred, zero_division=0))\n",
    "        if y_prob is not None and len(np.unique(y_test)) > 1:\n",
    "            print(\"AUC:\", roc_auc_score(y_test, y_prob))\n",
    "        print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        return y_pred, y_prob\n",
    "\n",
    "    ypred_rf, yprob_rf = evaluate_model(best_rf, X_te, y_te, name=\"RandomForest (best)\")\n",
    "    ypred_svm, yprob_svm = evaluate_model(best_svm, X_te, y_te, name=\"SVM (best)\")\n",
    "\n",
    "    # Feature importances mapping (RF)\n",
    "    try:\n",
    "        rf_clf = best_rf.named_steps['clf'] if USE_SMOTE else best_rf.named_steps['clf']\n",
    "        importances = rf_clf.feature_importances_\n",
    "        # map to names\n",
    "        idxs = np.argsort(importances)[::-1][:30]\n",
    "        print(\"\\nTop 30 feature importances (index, name, importance):\")\n",
    "        for idx in idxs:\n",
    "            print(idx, feature_names[idx], f\"{importances[idx]:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(\"[WARN] Could not extract feature importances:\", e)\n",
    "\n",
    "    # Threshold tuning on held-out set to prioritize recall if desired (example)\n",
    "    if yprob_rf is not None:\n",
    "        best_thresh = 0.5\n",
    "        best_recall = recall_score(y_te, (yprob_rf >= 0.5).astype(int))\n",
    "        # choose threshold that maximizes recall while keeping precision >= 0.5 (example)\n",
    "        for t in np.linspace(0.1, 0.9, 81):\n",
    "            preds_t = (yprob_rf >= t).astype(int)\n",
    "            r = recall_score(y_te, preds_t, zero_division=0)\n",
    "            # for illustration choose threshold maximizing recall\n",
    "            if r > best_recall:\n",
    "                best_recall = r; best_thresh = t\n",
    "        print(f\"[INFO] RF held-out best threshold for recall (example): {best_thresh:.2f}, recall={best_recall:.3f}\")\n",
    "        # show confusion at best threshold\n",
    "        preds_best = (yprob_rf >= best_thresh).astype(int)\n",
    "        print(\"Confusion at chosen threshold:\\n\", confusion_matrix(y_te, preds_best))\n",
    "        print(classification_report(y_te, preds_best))\n",
    "\n",
    "    # Save outputs\n",
    "    os.makedirs(\"results\", exist_ok=True)\n",
    "    with open(os.path.join(\"results\", \"features_X_y_groups.pkl\"), \"wb\") as f:\n",
    "        pickle.dump({\"X\": X, \"y\": y, \"groups\": groups_arr, \"ref_list\": ref_list, \"feature_names\": feature_names}, f)\n",
    "    with open(os.path.join(\"results\", \"best_rf.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(best_rf, f)\n",
    "    with open(os.path.join(\"results\", \"best_svm.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(best_svm, f)\n",
    "\n",
    "    print(\"\\n[INFO] Done. Results and models saved to ./results/\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3423a7e4-ee66-41cc-8a71-c4120181c86f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35f7ff84-6354-488b-8dc1-88ba268e9905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded and processed 324 images.\n",
      "Label distribution: Counter({np.int64(0): 207, np.int64(1): 117})\n",
      "\n",
      "--- Model Evaluation on Held-Out Test Set ---\n",
      "Accuracy: 0.9268\n",
      "ROC AUC Score: 0.9630\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94        51\n",
      "           1       0.96      0.84      0.90        31\n",
      "\n",
      "    accuracy                           0.93        82\n",
      "   macro avg       0.94      0.91      0.92        82\n",
      "weighted avg       0.93      0.93      0.93        82\n",
      "\n",
      "Confusion Matrix:\n",
      " [[50  1]\n",
      " [ 5 26]]\n",
      "\n",
      "--- Running Permutation Test (100 permutations) ---\n",
      "Permutation 1/100, Score: 0.4970\\rPermutation 2/100, Score: 0.4428\\rPermutation 3/100, Score: 0.5666\\rPermutation 4/100, Score: 0.4841\\rPermutation 5/100, Score: 0.5062\\rPermutation 6/100, Score: 0.4456\\rPermutation 7/100, Score: 0.4689\\rPermutation 8/100, Score: 0.4358\\rPermutation 9/100, Score: 0.4901\\rPermutation 10/100, Score: 0.5459\\rPermutation 11/100, Score: 0.4777\\rPermutation 12/100, Score: 0.5673\\rPermutation 13/100, Score: 0.4659\\rPermutation 14/100, Score: 0.4583\\rPermutation 15/100, Score: 0.5552\\rPermutation 16/100, Score: 0.5414\\rPermutation 17/100, Score: 0.5131\\rPermutation 18/100, Score: 0.6016\\rPermutation 19/100, Score: 0.5131\\rPermutation 20/100, Score: 0.5388\\rPermutation 21/100, Score: 0.4356\\rPermutation 22/100, Score: 0.5074\\rPermutation 23/100, Score: 0.5229\\rPermutation 24/100, Score: 0.5302\\rPermutation 25/100, Score: 0.5275\\rPermutation 26/100, Score: 0.4368\\rPermutation 27/100, Score: 0.4323\\rPermutation 28/100, Score: 0.5608\\rPermutation 29/100, Score: 0.5204\\rPermutation 30/100, Score: 0.5234\\rPermutation 31/100, Score: 0.5464\\rPermutation 32/100, Score: 0.5809\\rPermutation 33/100, Score: 0.5036\\rPermutation 34/100, Score: 0.4937\\rPermutation 35/100, Score: 0.4843\\rPermutation 36/100, Score: 0.5584\\rPermutation 37/100, Score: 0.5562\\rPermutation 38/100, Score: 0.5127\\rPermutation 39/100, Score: 0.4302\\rPermutation 40/100, Score: 0.4756\\rPermutation 41/100, Score: 0.4583\\rPermutation 42/100, Score: 0.5147\\rPermutation 43/100, Score: 0.4943\\rPermutation 44/100, Score: 0.5230\\rPermutation 45/100, Score: 0.4712\\rPermutation 46/100, Score: 0.4591\\rPermutation 47/100, Score: 0.5324\\rPermutation 48/100, Score: 0.5197\\rPermutation 49/100, Score: 0.4930\\rPermutation 50/100, Score: 0.5801\\rPermutation 51/100, Score: 0.5046\\rPermutation 52/100, Score: 0.5795\\rPermutation 53/100, Score: 0.5950\\rPermutation 54/100, Score: 0.5007\\rPermutation 55/100, Score: 0.4816\\rPermutation 56/100, Score: 0.4942\\rPermutation 57/100, Score: 0.5035\\rPermutation 58/100, Score: 0.4256\\rPermutation 59/100, Score: 0.6022\\rPermutation 60/100, Score: 0.4247\\rPermutation 61/100, Score: 0.5202\\rPermutation 62/100, Score: 0.6000\\rPermutation 63/100, Score: 0.5401\\rPermutation 64/100, Score: 0.5136\\rPermutation 65/100, Score: 0.5947\\rPermutation 66/100, Score: 0.5343\\rPermutation 67/100, Score: 0.5256\\rPermutation 68/100, Score: 0.4665\\rPermutation 69/100, Score: 0.5686\\rPermutation 70/100, Score: 0.4378\\rPermutation 71/100, Score: 0.5224\\rPermutation 72/100, Score: 0.4923\\rPermutation 73/100, Score: 0.5350\\rPermutation 74/100, Score: 0.5006\\rPermutation 75/100, Score: 0.5080\\rPermutation 76/100, Score: 0.5152\\rPermutation 77/100, Score: 0.5058\\rPermutation 78/100, Score: 0.4885\\rPermutation 79/100, Score: 0.4922\\rPermutation 80/100, Score: 0.4606\\rPermutation 81/100, Score: 0.5386\\rPermutation 82/100, Score: 0.4718\\rPermutation 83/100, Score: 0.4623\\rPermutation 84/100, Score: 0.5842\\rPermutation 85/100, Score: 0.4675\\rPermutation 86/100, Score: 0.5031\\rPermutation 87/100, Score: 0.5173\\rPermutation 88/100, Score: 0.5946\\rPermutation 89/100, Score: 0.4889\\rPermutation 90/100, Score: 0.4968\\rPermutation 91/100, Score: 0.4815\\rPermutation 92/100, Score: 0.4776\\rPermutation 93/100, Score: 0.4661\\rPermutation 94/100, Score: 0.5516\\rPermutation 95/100, Score: 0.4445\\rPermutation 96/100, Score: 0.4783\\rPermutation 97/100, Score: 0.4753\\rPermutation 98/100, Score: 0.4900\\rPermutation 99/100, Score: 0.4231\\rPermutation 100/100, Score: 0.4928\\r\\nReal Model ROC AUC: 0.9630\n",
      "Permutation Scores Mean: 0.5064\n",
      "P-value: 0.0000\n",
      "Result is statistically significant.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Corrected_Analysis.ipynb\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "from skimage import feature\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit, cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, confusion_matrix\n",
    "from sklearn.base import clone\n",
    "\n",
    "# --- Configuration ---\n",
    "IMAGES_DIR = \"all-mias\"\n",
    "META_PATH = \"data2.txt\"\n",
    "IMAGE_SIZE = 1024\n",
    "TARGET_ROI_SIZE = 256\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# --- 1. Data Loading and Preprocessing ---\n",
    "\n",
    "def load_and_prepare_data(images_dir, meta_path):\n",
    "    \"\"\"Loads metadata, finds images, and extracts consistent ROIs for all samples.\"\"\"\n",
    "    col_names = ['REFNUM', 'BG', 'CLASS', 'SEVERITY', 'X', 'Y', 'RADIUS']\n",
    "    df = pd.read_csv(meta_path, sep=\"\\\\s+\", names=col_names, header=None)\n",
    "    df['CANCER'] = df['SEVERITY'].apply(lambda x: 1 if x in ['B', 'M'] else 0)\n",
    "\n",
    "    # Calculate median radius from abnormal cases to use for normal cases\n",
    "    radii = pd.to_numeric(df[df['CANCER'] == 1]['RADIUS'], errors='coerce').dropna()\n",
    "    median_radius = int(radii.median())\n",
    "\n",
    "    all_rois = []\n",
    "    all_labels = []\n",
    "    all_groups = []\n",
    "\n",
    "    for filename in sorted(os.listdir(images_dir)):\n",
    "        if not filename.lower().endswith('.pgm'):\n",
    "            continue\n",
    "        \n",
    "        ref_num = os.path.splitext(filename)[0]\n",
    "        record = df[df['REFNUM'] == ref_num]\n",
    "        if record.empty:\n",
    "            continue\n",
    "\n",
    "        record = record.iloc[0]\n",
    "        full_path = os.path.join(images_dir, filename)\n",
    "        img_array = cv2.imread(full_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        label = record['CANCER']\n",
    "        patient_id = int(''.join(c for c in ref_num if c.isdigit())) // 2\n",
    "        \n",
    "        # Consistent ROI Extraction\n",
    "        x, y, r = record[['X', 'Y', 'RADIUS']]\n",
    "        \n",
    "        if label == 1 and all(pd.notna([x, y, r])):\n",
    "            cx, cy, cr = int(x), int(IMAGE_SIZE - float(y)), int(r)\n",
    "        else:\n",
    "            # For normal cases, take a crop from the center\n",
    "            cx, cy, cr = IMAGE_SIZE // 2, IMAGE_SIZE // 2, median_radius\n",
    "            \n",
    "        # Crop a square ROI and apply CLAHE\n",
    "        x0, y0 = max(0, cx - cr), max(0, cy - cr)\n",
    "        x1, y1 = min(IMAGE_SIZE, cx + cr), min(IMAGE_SIZE, cy + cr)\n",
    "        roi = img_array[y0:y1, x0:x1]\n",
    "\n",
    "        if roi.size == 0:\n",
    "            continue\n",
    "        \n",
    "        # Apply CLAHE to the ROI\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        roi_enhanced = clahe.apply(roi)\n",
    "        \n",
    "        # Resize to a fixed size for consistency\n",
    "        roi_resized = cv2.resize(roi_enhanced, (TARGET_ROI_SIZE, TARGET_ROI_SIZE), interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        all_rois.append(roi_resized)\n",
    "        all_labels.append(label)\n",
    "        all_groups.append(patient_id)\n",
    "        \n",
    "    print(f\"Successfully loaded and processed {len(all_rois)} images.\")\n",
    "    print(f\"Label distribution: {Counter(all_labels)}\")\n",
    "    return np.array(all_rois), np.array(all_labels), np.array(all_groups)\n",
    "\n",
    "# --- 2. Feature Extraction ---\n",
    "\n",
    "def extract_glcm_features(patch, distances=[1, 3, 5], angles=[0, np.pi/4, np.pi/2, 3*np.pi/4]):\n",
    "    \"\"\"Computes GLCM features for a single patch.\"\"\"\n",
    "    glcm = graycomatrix(patch, distances=distances, angles=angles, levels=256, symmetric=True, normed=True)\n",
    "    props = ['contrast', 'dissimilarity', 'homogeneity', 'ASM', 'energy', 'correlation']\n",
    "    feats = {}\n",
    "    for prop in props:\n",
    "        mat = graycoprops(glcm, prop)\n",
    "        feats[f'{prop}_mean'] = mat.mean()\n",
    "        feats[f'{prop}_var'] = mat.var()\n",
    "    return feats\n",
    "\n",
    "def extract_lbp_features(patch, P=8, R=3, G=6):\n",
    "    \"\"\"Computes pooled LBP histogram features.\"\"\"\n",
    "    lbp = feature.local_binary_pattern(patch, P, R, method='uniform')\n",
    "    n_bins = int(lbp.max() + 1)\n",
    "    hist, _ = np.histogram(lbp, density=True, bins=n_bins, range=(0, n_bins))\n",
    "    return hist\n",
    "\n",
    "def create_feature_matrix(rois, labels, groups):\n",
    "    \"\"\"Loops over all ROIs to build the final feature matrix.\"\"\"\n",
    "    records = []\n",
    "    for roi, label, grp in zip(rois, labels, groups):\n",
    "        # GLCM\n",
    "        glcm_feats = extract_glcm_features(roi)\n",
    "        # LBP\n",
    "        lbp_feats_hist = extract_lbp_features(roi)\n",
    "        lbp_feats = {f'lbp_{i}': val for i, val in enumerate(lbp_feats_hist)}\n",
    "        \n",
    "        # Combine features and metadata\n",
    "        all_feats = {**glcm_feats, **lbp_feats}\n",
    "        all_feats['label'] = label\n",
    "        all_feats['group'] = grp\n",
    "        records.append(all_feats)\n",
    "        \n",
    "    df = pd.DataFrame.from_records(records)\n",
    "    return df\n",
    "\n",
    "# --- 3. Model Training and Evaluation ---\n",
    "\n",
    "# Run the pipeline\n",
    "rois, labels, groups = load_and_prepare_data(IMAGES_DIR, META_PATH)\n",
    "feature_df = create_feature_matrix(rois, labels, groups)\n",
    "\n",
    "X = feature_df.drop(columns=['label', 'group']).values\n",
    "y = feature_df['label'].values\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Group-aware train/test split to prevent data leakage\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.25, random_state=RANDOM_STATE)\n",
    "train_idx, test_idx = next(gss.split(X_scaled, y, groups))\n",
    "\n",
    "X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
    "y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "# --- Model Training ---\n",
    "clf = RandomForestClassifier(n_estimators=300, random_state=RANDOM_STATE, class_weight='balanced')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# --- Evaluation ---\n",
    "y_pred = clf.predict(X_test)\n",
    "y_prob = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\n--- Model Evaluation on Held-Out Test Set ---\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC AUC Score: {roc_auc_score(y_test, y_prob):.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# --- 4. Permutation Test ---\n",
    "print(\"\\n--- Running Permutation Test (100 permutations) ---\")\n",
    "cv = GroupShuffleSplit(n_splits=5, test_size=0.25, random_state=RANDOM_STATE)\n",
    "score_real, _, _ = roc_auc_score(y_test, y_prob), None, None # Using held-out score as the real score\n",
    "\n",
    "n_permutations = 100\n",
    "perm_scores = []\n",
    "for i in range(n_permutations):\n",
    "    y_permuted = np.random.permutation(y)\n",
    "    # Using a simple CV for the permutation test for speed\n",
    "    perm_clf = clone(clf)\n",
    "    score = cross_val_score(perm_clf, X_scaled, y_permuted, cv=cv, groups=groups, scoring='roc_auc').mean()\n",
    "    perm_scores.append(score)\n",
    "    print(f\"Permutation {i+1}/{n_permutations}, Score: {score:.4f}\", end='\\\\r')\n",
    "\n",
    "p_value = (np.sum(np.array(perm_scores) >= score_real)) / n_permutations\n",
    "print(f\"\\\\nReal Model ROC AUC: {score_real:.4f}\")\n",
    "print(f\"Permutation Scores Mean: {np.mean(perm_scores):.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "if p_value < 0.05:\n",
    "    print(\"Result is statistically significant.\")\n",
    "else:\n",
    "    print(\"Result is not statistically significant.\")\n",
    "\n",
    "# Plot permutation scores\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(perm_scores, bins=20, label='Permutation Scores', edgecolor='k')\n",
    "plt.axvline(score_real, color='red', linestyle='--', linewidth=2, label=f'Real Score (p={p_value:.4f})')\n",
    "plt.title(\"Permutation Test Results\")\n",
    "plt.xlabel(\"ROC AUC Score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e455d90-1c32-4ff0-a1d2-fc81f0ddff4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting xgboost\n",
      "  Downloading xgboost-3.0.5-py3-none-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in c:\\python3\\lib\\site-packages (from xgboost) (2.2.6)\n",
      "Requirement already satisfied: scipy in c:\\python3\\lib\\site-packages (from xgboost) (1.16.1)\n",
      "Downloading xgboost-3.0.5-py3-none-win_amd64.whl (56.8 MB)\n",
      "   ---------------------------------------- 0.0/56.8 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 10.5/56.8 MB 54.7 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 31.2/56.8 MB 82.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 49.3/56.8 MB 84.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 56.8/56.8 MB 78.7 MB/s  0:00:00\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-3.0.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e71556b-6e65-4118-8da6-865bfd14b9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing images...\n",
      "Loaded 648 images (including augmented).\n",
      "Training set size: 516 (after augmentation)\n",
      "Test set size: 66 (original images only)\n",
      "\n",
      "Extracting features for training and test sets...\n",
      "\n",
      "--- Starting Hyperparameter Tuning ---\n",
      "\n",
      "Tuning RandomForest...\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Best Score (AUC) for RandomForest: 0.9199\n",
      "Best Params for RandomForest: {'clf__max_depth': 10, 'clf__min_samples_leaf': 1, 'clf__n_estimators': 500, 'select__k': 40}\n",
      "\n",
      "Tuning SVM...\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Best Score (AUC) for SVM: 0.9140\n",
      "Best Params for SVM: {'clf__C': 100, 'clf__gamma': 0.001, 'select__k': 40}\n",
      "\n",
      "Tuning XGBoost...\n",
      "Fitting 4 folds for each of 81 candidates, totalling 324 fits\n",
      "Best Score (AUC) for XGBoost: 0.9312\n",
      "Best Params for XGBoost: {'clf__learning_rate': 0.1, 'clf__max_depth': 7, 'clf__n_estimators': 100, 'select__k': 40}\n",
      "\n",
      "--- Final Model Evaluation on Held-Out Test Set ---\n",
      "\n",
      "--- Results for Best RandomForest ---\n",
      "Accuracy: 0.8333\n",
      "ROC AUC Score: 0.8604\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.79      0.97      0.87        39\n",
      "      Cancer       0.94      0.63      0.76        27\n",
      "\n",
      "    accuracy                           0.83        66\n",
      "   macro avg       0.87      0.80      0.81        66\n",
      "weighted avg       0.85      0.83      0.83        66\n",
      "\n",
      "Confusion Matrix:\n",
      " [[38  1]\n",
      " [10 17]]\n",
      "\n",
      "--- Results for Best SVM ---\n",
      "Accuracy: 0.7576\n",
      "ROC AUC Score: 0.8367\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.76      0.87      0.81        39\n",
      "      Cancer       0.76      0.59      0.67        27\n",
      "\n",
      "    accuracy                           0.76        66\n",
      "   macro avg       0.76      0.73      0.74        66\n",
      "weighted avg       0.76      0.76      0.75        66\n",
      "\n",
      "Confusion Matrix:\n",
      " [[34  5]\n",
      " [11 16]]\n",
      "\n",
      "--- Results for Best XGBoost ---\n",
      "Accuracy: 0.8030\n",
      "ROC AUC Score: 0.8765\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.77      0.95      0.85        39\n",
      "      Cancer       0.89      0.59      0.71        27\n",
      "\n",
      "    accuracy                           0.80        66\n",
      "   macro avg       0.83      0.77      0.78        66\n",
      "weighted avg       0.82      0.80      0.79        66\n",
      "\n",
      "Confusion Matrix:\n",
      " [[37  2]\n",
      " [11 16]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aa23147\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [20:56:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Improved_LBP_GLCM_Pipeline.ipynb\n",
    "#\n",
    "# This script improves upon the robust structure of Method2 by adding\n",
    "# data augmentation, a more powerful XGBoost classifier, and a more\n",
    "# comprehensive hyperparameter search to maximize performance with LBP/GLCM features.\n",
    "#\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Scikit-learn and XGBoost imports\n",
    "from skimage import feature\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GroupKFold, GroupShuffleSplit, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "\n",
    "# --- Configuration ---\n",
    "IMAGES_DIR = \"all-mias\"\n",
    "META_PATH = \"data2.txt\"\n",
    "IMAGE_SIZE = 1024\n",
    "TARGET_ROI_SIZE = 128\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# CV and Split Configuration\n",
    "HOLDOUT_TEST_SIZE = 0.2\n",
    "INNER_CV_SPLITS = 4 # K-fold for grid search\n",
    "\n",
    "# --- 1. Data Loading and Preprocessing with Augmentation ---\n",
    "\n",
    "def load_and_prepare_data(images_dir, meta_path, augment_train=True):\n",
    "    \"\"\"Loads metadata and extracts ROIs. Includes an option for horizontal flip augmentation.\"\"\"\n",
    "    col_names = ['REFNUM', 'BG', 'CLASS', 'SEVERITY', 'X', 'Y', 'RADIUS']\n",
    "    df = pd.read_csv(meta_path, sep=\"\\\\s+\", names=col_names, header=None)\n",
    "    df['CANCER'] = df['SEVERITY'].apply(lambda x: 1 if x in ['B', 'M'] else 0)\n",
    "    radii = pd.to_numeric(df[df['CANCER'] == 1]['RADIUS'], errors='coerce').dropna()\n",
    "    median_radius = int(radii.median())\n",
    "\n",
    "    data = [] # Store tuples of (roi, label, group, is_augmented)\n",
    "\n",
    "    print(\"Loading and preprocessing images...\")\n",
    "    for filename in sorted(os.listdir(images_dir)):\n",
    "        if not filename.lower().endswith('.pgm'):\n",
    "            continue\n",
    "        \n",
    "        ref_num = os.path.splitext(filename)[0]\n",
    "        record = df[df['REFNUM'] == ref_num]\n",
    "        if record.empty: continue\n",
    "\n",
    "        record = record.iloc[0]\n",
    "        full_path = os.path.join(images_dir, filename)\n",
    "        img_array = cv2.imread(full_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        label = record['CANCER']\n",
    "        patient_id = int(''.join(c for c in ref_num if c.isdigit())) // 2 if ref_num[3:].isdigit() else ref_num\n",
    "\n",
    "        x, y, r = record[['X', 'Y', 'RADIUS']]\n",
    "        if label == 1 and all(pd.notna([x, y, r])):\n",
    "            cx, cy, cr = int(x), int(IMAGE_SIZE - float(y)), int(r)\n",
    "        else:\n",
    "            cx, cy, cr = IMAGE_SIZE // 2, IMAGE_SIZE // 2, median_radius\n",
    "            \n",
    "        x0, y0 = max(0, cx - cr), max(0, cy - cr)\n",
    "        x1, y1 = min(IMAGE_SIZE, cx + cr), min(IMAGE_SIZE, cy + cr)\n",
    "        roi = img_array[y0:y1, x0:x1]\n",
    "\n",
    "        if roi.size == 0: continue\n",
    "        \n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        roi_enhanced = clahe.apply(roi)\n",
    "        roi_resized = cv2.resize(roi_enhanced, (TARGET_ROI_SIZE, TARGET_ROI_SIZE), interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        data.append({'roi': roi_resized, 'label': label, 'group': patient_id, 'is_augmented': False})\n",
    "\n",
    "        # *** IMPROVEMENT: DATA AUGMENTATION ***\n",
    "        # Add a horizontally flipped version of the ROI\n",
    "        if augment_train:\n",
    "            roi_flipped = cv2.flip(roi_resized, 1)\n",
    "            data.append({'roi': roi_flipped, 'label': label, 'group': patient_id, 'is_augmented': True})\n",
    "\n",
    "    print(f\"Loaded {len(data)} images (including augmented).\")\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# --- 2. Feature Extraction (LBP + GLCM) ---\n",
    "\n",
    "# CORRECTED FUNCTION\n",
    "\n",
    "def extract_features(roi):\n",
    "    \"\"\"Extracts a combined feature vector of LBP and GLCM for a single ROI.\"\"\"\n",
    "    # LBP Features\n",
    "    P, R, G = 8, 3, 3 # Points, Radius, Grid size\n",
    "    lbp = feature.local_binary_pattern(roi, P, R, method='uniform')\n",
    "    \n",
    "    # --- FIX ---\n",
    "    # Use a fixed number of bins for uniform LBP (P + 2)\n",
    "    n_bins = P + 2 \n",
    "    # --- END FIX ---\n",
    "    \n",
    "    # Pooled histogram\n",
    "    H, W = lbp.shape\n",
    "    h_step, w_step = H // G, W // G\n",
    "    lbp_hist = []\n",
    "    for i in range(G):\n",
    "        for j in range(G):\n",
    "            region = lbp[i*h_step:(i+1)*h_step, j*w_step:(j+1)*w_step]\n",
    "            # Use fixed n_bins and range\n",
    "            hist, _ = np.histogram(region.ravel(), bins=n_bins, range=(0, n_bins))\n",
    "            lbp_hist.extend(hist)\n",
    "    lbp_features = np.array(lbp_hist, dtype=float)\n",
    "\n",
    "    # GLCM Features\n",
    "    glcm = graycomatrix(roi, distances=[1, 3], angles=[0, np.pi/4, np.pi/2], levels=256, symmetric=True, normed=True)\n",
    "    props = ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation', 'ASM']\n",
    "    glcm_features = []\n",
    "    for prop in props:\n",
    "        glcm_features.extend(graycoprops(glcm, prop).ravel())\n",
    "        \n",
    "    # Combine and return\n",
    "    return np.concatenate([lbp_features, glcm_features])\n",
    "# --- 3. Model Training and Evaluation Pipeline ---\n",
    "\n",
    "# Step 1: Load data\n",
    "full_dataset = load_and_prepare_data(IMAGES_DIR, META_PATH, augment_train=True)\n",
    "\n",
    "# Step 2: Group-aware train/test split (BEFORE feature extraction and augmentation handling)\n",
    "# We split based on original images to ensure augmented versions stay with their originals.\n",
    "original_indices = full_dataset[full_dataset['is_augmented'] == False].index\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=HOLDOUT_TEST_SIZE, random_state=RANDOM_STATE)\n",
    "train_idx_orig, test_idx_orig = next(gss.split(original_indices, groups=full_dataset.loc[original_indices, 'group']))\n",
    "\n",
    "# Get the full training set (originals + their augmented pairs)\n",
    "train_groups = full_dataset.loc[original_indices[train_idx_orig], 'group'].unique()\n",
    "train_df = full_dataset[full_dataset['group'].isin(train_groups)]\n",
    "\n",
    "# The test set contains ONLY original, non-augmented images\n",
    "test_df = full_dataset.loc[original_indices[test_idx_orig]]\n",
    "\n",
    "print(f\"Training set size: {len(train_df)} (after augmentation)\")\n",
    "print(f\"Test set size: {len(test_df)} (original images only)\")\n",
    "\n",
    "# Step 3: Extract features for train and test sets\n",
    "print(\"\\nExtracting features for training and test sets...\")\n",
    "X_train = np.array([extract_features(roi) for roi in train_df['roi']])\n",
    "y_train = train_df['label'].values\n",
    "groups_train = train_df['group'].values\n",
    "\n",
    "X_test = np.array([extract_features(roi) for roi in test_df['roi']])\n",
    "y_test = test_df['label'].values\n",
    "\n",
    "# Step 4: Define pipelines and hyperparameter grids\n",
    "scaler = StandardScaler()\n",
    "selector = SelectKBest(mutual_info_classif)\n",
    "\n",
    "# Pipeline definitions\n",
    "rf_pipeline = Pipeline([('scaler', scaler), ('select', selector), ('clf', RandomForestClassifier(random_state=RANDOM_STATE, class_weight='balanced'))])\n",
    "svm_pipeline = Pipeline([('scaler', scaler), ('select', selector), ('clf', SVC(probability=True, random_state=RANDOM_STATE, class_weight='balanced'))])\n",
    "xgb_pipeline = Pipeline([('scaler', scaler), ('select', selector), ('clf', XGBClassifier(random_state=RANDOM_STATE, use_label_encoder=False, eval_metric='logloss'))])\n",
    "\n",
    "\n",
    "# *** IMPROVEMENT: Expanded Hyperparameter Grids ***\n",
    "rf_params = {\n",
    "    'select__k': [40, 80, 120],\n",
    "    'clf__n_estimators': [100, 250, 500],\n",
    "    'clf__max_depth': [5, 10, 20, None],\n",
    "    'clf__min_samples_leaf': [1, 3, 5]\n",
    "}\n",
    "\n",
    "svm_params = {\n",
    "    'select__k': [40, 80, 120],\n",
    "    'clf__C': [0.1, 1, 10, 100],\n",
    "    'clf__gamma': ['scale', 0.01, 0.001]\n",
    "}\n",
    "\n",
    "xgb_params = {\n",
    "    'select__k': [40, 80, 120],\n",
    "    'clf__n_estimators': [100, 250, 500],\n",
    "    'clf__max_depth': [3, 5, 7],\n",
    "    'clf__learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "pipelines = {\n",
    "    'RandomForest': (rf_pipeline, rf_params),\n",
    "    'SVM': (svm_pipeline, svm_params),\n",
    "    'XGBoost': (xgb_pipeline, xgb_params) # *** IMPROVEMENT: Added XGBoost ***\n",
    "}\n",
    "\n",
    "# Step 5: Run GridSearchCV for each model\n",
    "print(\"\\n--- Starting Hyperparameter Tuning ---\")\n",
    "best_estimators = {}\n",
    "inner_cv = GroupKFold(n_splits=INNER_CV_SPLITS)\n",
    "\n",
    "for name, (pipeline, params) in pipelines.items():\n",
    "    print(f\"\\nTuning {name}...\")\n",
    "    gs = GridSearchCV(pipeline, params, cv=inner_cv.split(X_train, y_train, groups_train), scoring='roc_auc', n_jobs=-1, verbose=1)\n",
    "    gs.fit(X_train, y_train)\n",
    "    best_estimators[name] = gs.best_estimator_\n",
    "    print(f\"Best Score (AUC) for {name}: {gs.best_score_:.4f}\")\n",
    "    print(f\"Best Params for {name}: {gs.best_params_}\")\n",
    "\n",
    "# Step 6: Evaluate the best models on the held-out test set\n",
    "print(\"\\n--- Final Model Evaluation on Held-Out Test Set ---\")\n",
    "for name, model in best_estimators.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    print(f\"\\n--- Results for Best {name} ---\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"ROC AUC Score: {roc_auc_score(y_test, y_prob):.4f}\")\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=[\"Normal\", \"Cancer\"]))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
