{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0fe6a8b-ba26-4603-be32-4c58aa3219c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] imbalanced-learn not available. Script will use class_weight='balanced' instead of SMOTE.\n",
      "[INFO] Reading metadata...\n",
      "[INFO] Found 324 image files in all-mias\n",
      "[INFO] median radius: 43\n",
      "[INFO] Extracted 324 ROIs (CLAHE applied per-ROI).\n",
      "[INFO] Computing LBP maps for radii: [1, 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python3\\Lib\\site-packages\\skimage\\feature\\texture.py:385: UserWarning: Applying `local_binary_pattern` to floating-point images may give unexpected results when small numerical differences between adjacent pixels are present. It is recommended to use this function with images of integer dtype.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Determined LBP n_bins = 10\n",
      "[INFO] Building pooled LBP histograms and GLCM features for each ROI...\n",
      "[INFO] Feature shapes: X_glcm (324, 12) X_lbp (324, 180) combined X (324, 192)\n",
      "Label counts: Counter({np.int64(0): 207, np.int64(1): 117})\n",
      "[INFO] Train samples: 258 Test samples: 66\n",
      "[INFO] Running inner grid-search for RandomForest...\n",
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n",
      "[INFO] Best RandomForest params: {'clf__max_depth': 12, 'clf__min_samples_leaf': 6, 'clf__n_estimators': 300}\n",
      "[INFO] Running inner grid-search for SVM...\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "[INFO] Best SVM params: {'clf__C': 1, 'clf__gamma': 'scale'}\n",
      "\n",
      "=== Held-out evaluation: RandomForest (best) ===\n",
      "Accuracy: 0.8333333333333334\n",
      "Recall: 0.75\n",
      "AUC: 0.8938492063492064\n",
      "Confusion Matrix:\n",
      " [[37  5]\n",
      " [ 6 18]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87        42\n",
      "           1       0.78      0.75      0.77        24\n",
      "\n",
      "    accuracy                           0.83        66\n",
      "   macro avg       0.82      0.82      0.82        66\n",
      "weighted avg       0.83      0.83      0.83        66\n",
      "\n",
      "\n",
      "=== Held-out evaluation: SVM (best) ===\n",
      "Accuracy: 0.8333333333333334\n",
      "Recall: 0.75\n",
      "AUC: 0.9047619047619047\n",
      "Confusion Matrix:\n",
      " [[37  5]\n",
      " [ 6 18]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87        42\n",
      "           1       0.78      0.75      0.77        24\n",
      "\n",
      "    accuracy                           0.83        66\n",
      "   macro avg       0.82      0.82      0.82        66\n",
      "weighted avg       0.83      0.83      0.83        66\n",
      "\n",
      "\n",
      "Top 30 feature importances (index, name, importance):\n",
      "1 contrast_var 0.0418\n",
      "39 LBP_R1_r02_c007 0.0364\n",
      "0 contrast_mean 0.0333\n",
      "5 homogeneity_var 0.0321\n",
      "28 LBP_R1_r01_c006 0.0309\n",
      "24 LBP_R1_r01_c002 0.0287\n",
      "10 correlation_mean 0.0275\n",
      "3 dissimilarity_var 0.0272\n",
      "66 LBP_R1_r05_c004 0.0270\n",
      "38 LBP_R1_r02_c006 0.0268\n",
      "19 LBP_R1_r00_c007 0.0251\n",
      "33 LBP_R1_r02_c001 0.0245\n",
      "47 LBP_R1_r03_c005 0.0233\n",
      "64 LBP_R1_r05_c002 0.0223\n",
      "32 LBP_R1_r02_c000 0.0222\n",
      "71 LBP_R1_r05_c009 0.0221\n",
      "59 LBP_R1_r04_c007 0.0207\n",
      "62 LBP_R1_r05_c000 0.0205\n",
      "41 LBP_R1_r02_c009 0.0182\n",
      "55 LBP_R1_r04_c003 0.0173\n",
      "2 dissimilarity_mean 0.0166\n",
      "63 LBP_R1_r05_c001 0.0164\n",
      "46 LBP_R1_r03_c004 0.0162\n",
      "57 LBP_R1_r04_c005 0.0156\n",
      "43 LBP_R1_r03_c001 0.0154\n",
      "56 LBP_R1_r04_c004 0.0152\n",
      "75 LBP_R1_r06_c003 0.0144\n",
      "21 LBP_R1_r00_c009 0.0131\n",
      "34 LBP_R1_r02_c002 0.0130\n",
      "17 LBP_R1_r00_c005 0.0127\n",
      "[INFO] RF held-out best threshold for recall (example): 0.10, recall=1.000\n",
      "Confusion at chosen threshold:\n",
      " [[12 30]\n",
      " [ 0 24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.29      0.44        42\n",
      "           1       0.44      1.00      0.62        24\n",
      "\n",
      "    accuracy                           0.55        66\n",
      "   macro avg       0.72      0.64      0.53        66\n",
      "weighted avg       0.80      0.55      0.51        66\n",
      "\n",
      "\n",
      "[INFO] Done. Results and models saved to ./results/\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "improved_lbp_glcm_pipeline.py\n",
    "\n",
    "- ROI extraction (consistent normal/abnormal)\n",
    "- per-ROI CLAHE\n",
    "- LBP pooled features (adaptive bins)\n",
    "- quantized GLCM features\n",
    "- SelectKBest feature selection inside pipeline\n",
    "- SMOTE inside CV if available, else class_weight fallback\n",
    "- nested GroupKFold (inner) GridSearchCV and held-out GroupShuffleSplit\n",
    "- prints and saves results to ./results/\n",
    "\"\"\"\n",
    "import os\n",
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.feature import local_binary_pattern, graycomatrix, graycoprops\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GroupKFold, GroupShuffleSplit, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, recall_score, roc_auc_score, classification_report, confusion_matrix\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# try to import imblearn (SMOTE & pipeline). If missing fallback will be used.\n",
    "USE_SMOTE = True\n",
    "try:\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "except Exception:\n",
    "    USE_SMOTE = False\n",
    "    ImbPipeline = None\n",
    "    print(\"[WARN] imbalanced-learn not available. Script will use class_weight='balanced' instead of SMOTE.\")\n",
    "\n",
    "# ----------------- USER CONFIG -----------------\n",
    "IMAGES_DIR = \"all-mias\"\n",
    "META_PATH = \"data2.txt\"\n",
    "IMAGE_SIZE = 1024               # MIAS image size reference\n",
    "TARGET_SIZE = 128               # None to keep native crop size, or int to resize (128 recommended)\n",
    "MIN_SIDE = 32                   # pad if ROI smaller\n",
    "CLAHE_CLIP = 2.0\n",
    "CLAHE_TILE = (8, 8)\n",
    "\n",
    "# LBP params\n",
    "P = 8\n",
    "# You can enable multi-scale LBP; set RB list to include desired radii:\n",
    "LBP_RADII = [1, 3]             # set to [3] or [1,3] for multiscale\n",
    "LBP_METHOD = 'uniform'\n",
    "\n",
    "# pooling grid for LBP\n",
    "POOL_G = 3                      # 3x3 pooling (try 3,4,6). smaller reduces dims\n",
    "\n",
    "# GLCM params (quantized)\n",
    "GLCM_LEVELS = 32\n",
    "GLCM_DISTANCES = [1, 3]\n",
    "GLCM_ANGLES = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
    "\n",
    "# CV params\n",
    "OUTER_SPLITS = 5\n",
    "INNER_SPLITS = 4\n",
    "RANDOM_STATE = 42\n",
    "HOLDOUT_TEST_SIZE = 0.2\n",
    "\n",
    "# Grid search params\n",
    "RF_PARAM_GRID = {\n",
    "    'clf__n_estimators': [100, 300],\n",
    "    'clf__max_depth': [6, 12, None],\n",
    "    'clf__min_samples_leaf': [2, 6],\n",
    "}\n",
    "SVM_PARAM_GRID = {\n",
    "    'clf__C': [0.1, 1, 10],\n",
    "    'clf__gamma': ['scale', 0.01],\n",
    "}\n",
    "\n",
    "SELECT_K = 80  # number of features to keep with SelectKBest (set based on experiments)\n",
    "\n",
    "# ------------------------------------------------\n",
    "\n",
    "# ---------- helper functions ----------\n",
    "def read_metadata(meta_path):\n",
    "    col_names = ['REFNUM', 'BG', 'CLASS', 'SEVERITY', 'X', 'Y', 'RADIUS']\n",
    "    df = pd.read_csv(meta_path, sep=r\"\\s+\", names=col_names, header=None)\n",
    "    df['CANCER'] = df['SEVERITY'].apply(lambda x: 1 if x in ['B', 'M'] else 0)\n",
    "    return df\n",
    "\n",
    "def ref_to_patient_id(ref):\n",
    "    try:\n",
    "        n = int(''.join(ch for ch in ref if ch.isdigit()))\n",
    "        return (n - 1) // 2\n",
    "    except:\n",
    "        return ref\n",
    "\n",
    "def clamp(a, lo, hi):\n",
    "    return max(lo, min(hi, a))\n",
    "\n",
    "def crop_square(img, cx, cy, r):\n",
    "    H, W = img.shape\n",
    "    x0 = clamp(cx - r, 0, W)\n",
    "    x1 = clamp(cx + r, 0, W)\n",
    "    y0 = clamp(cy - r, 0, H)\n",
    "    y1 = clamp(cy + r, 0, H)\n",
    "    if x1 <= x0 or y1 <= y0:\n",
    "        return img.copy()\n",
    "    return img[y0:y1, x0:x1]\n",
    "\n",
    "def pad_to_min_side(img, min_side):\n",
    "    h, w = img.shape\n",
    "    top = bottom = left = right = 0\n",
    "    if h < min_side:\n",
    "        extra = min_side - h\n",
    "        top = extra // 2\n",
    "        bottom = extra - top\n",
    "    if w < min_side:\n",
    "        extra = min_side - w\n",
    "        left = extra // 2\n",
    "        right = extra - left\n",
    "    if any([top, bottom, left, right]):\n",
    "        img = cv2.copyMakeBorder(img, top, bottom, left, right, borderType=cv2.BORDER_REFLECT)\n",
    "    return img\n",
    "\n",
    "def apply_clahe_to_roi(roi, clip=2.0, tile=(8,8)):\n",
    "    if roi.dtype != np.uint8:\n",
    "        if roi.max() <= 1.0:\n",
    "            roi_u8 = (roi * 255).astype(np.uint8)\n",
    "        else:\n",
    "            roi_u8 = roi.astype(np.uint8)\n",
    "    else:\n",
    "        roi_u8 = roi\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip, tileGridSize=tile)\n",
    "    return clahe.apply(roi_u8)\n",
    "\n",
    "def pooled_lbp_matrix(lbp_map, G=3, n_bins=None):\n",
    "    H, W = lbp_map.shape\n",
    "    row_edges = np.linspace(0, H, G+1, dtype=int)\n",
    "    col_edges = np.linspace(0, W, G+1, dtype=int)\n",
    "    rows = []\n",
    "    # use dynamic n_bins from caller\n",
    "    for i in range(G):\n",
    "        for j in range(G):\n",
    "            r0, r1 = row_edges[i], row_edges[i+1]\n",
    "            c0, c1 = col_edges[j], col_edges[j+1]\n",
    "            region = lbp_map[r0:r1, c0:c1]\n",
    "            # ensure integer codes\n",
    "            region_int = region.ravel().astype(int)\n",
    "            if n_bins is None:\n",
    "                n_bins_reg = int(region_int.max()) + 1 if region_int.size>0 else 1\n",
    "                hist = np.bincount(region_int, minlength=n_bins_reg).astype(float)\n",
    "            else:\n",
    "                hist = np.bincount(region_int, minlength=n_bins).astype(float)\n",
    "            if hist.sum() > 0:\n",
    "                hist /= hist.sum()\n",
    "            # if n_bins is provided, hist length is fixed\n",
    "            if n_bins is not None and len(hist) < n_bins:\n",
    "                # pad\n",
    "                hist = np.pad(hist, (0, n_bins - len(hist)), mode='constant')\n",
    "            rows.append(hist)\n",
    "    M = np.vstack(rows)\n",
    "    return M\n",
    "\n",
    "def quantize_img_levels(img, levels=32):\n",
    "    a = img.astype(np.float32)\n",
    "    if a.max() > 1.1:\n",
    "        a = a / 255.0\n",
    "    q = np.floor(a * (levels - 1) + 0.5).astype(np.uint8)\n",
    "    return q\n",
    "\n",
    "def extract_glcm_features(patch, distances, angles, levels):\n",
    "    q = quantize_img_levels(patch, levels=levels)\n",
    "    glcm = graycomatrix(q, distances=distances, angles=angles, levels=levels, symmetric=True, normed=True)\n",
    "    props = ['contrast', 'dissimilarity', 'homogeneity', 'ASM', 'energy', 'correlation']\n",
    "    feats = []\n",
    "    for p in props:\n",
    "        mat = graycoprops(glcm, p)\n",
    "        feats.append(float(np.nanmean(mat)))\n",
    "        feats.append(float(np.nanvar(mat)))\n",
    "    return np.array(feats, dtype=float)  # length = 2 * len(props)\n",
    "\n",
    "# ---------- main ----------\n",
    "def main():\n",
    "    print(\"[INFO] Reading metadata...\")\n",
    "    df = read_metadata(META_PATH)\n",
    "    refs = sorted([f for f in os.listdir(IMAGES_DIR) if f.lower().endswith('.pgm')])\n",
    "    print(f\"[INFO] Found {len(refs)} image files in {IMAGES_DIR}\")\n",
    "    radii = pd.to_numeric(df['RADIUS'], errors='coerce').dropna()\n",
    "    median_radius = int(radii.median()) if radii.size > 0 else 48\n",
    "    print(\"[INFO] median radius:\", median_radius)\n",
    "\n",
    "    # ROI extraction\n",
    "    rois = []\n",
    "    rois_raw = []   # keep a raw copy (pre-CLAHE) for comparisons\n",
    "    labels = []\n",
    "    groups = []\n",
    "    ref_list = []\n",
    "\n",
    "    for fname in refs:\n",
    "        ref = os.path.splitext(fname)[0]\n",
    "        row = df[df['REFNUM'] == ref]\n",
    "        if row.empty:\n",
    "            continue\n",
    "        row = row.iloc[0]\n",
    "        img_path = os.path.join(IMAGES_DIR, fname)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            print(\"[WARN] cannot read\", img_path); continue\n",
    "\n",
    "        label = int(row['CANCER'])\n",
    "        x, y, r = row['X'], row['Y'], row['RADIUS']\n",
    "\n",
    "        if label == 1 and pd.notna(x) and pd.notna(y) and pd.notna(r):\n",
    "            cx = int(float(x))\n",
    "            cy = int(IMAGE_SIZE - float(y))  # convert bottom-left MIAS to top-left indexing\n",
    "            rr = int(max(int(r), 8))\n",
    "            roi = crop_square(img, cx, cy, rr)\n",
    "        else:\n",
    "            cx = img.shape[1] // 2\n",
    "            cy = img.shape[0] // 2\n",
    "            rr = median_radius\n",
    "            roi = crop_square(img, cx, cy, rr)\n",
    "\n",
    "        roi = pad_to_min_side(roi, MIN_SIDE)\n",
    "        rois_raw.append(roi.copy())\n",
    "        roi_clahe = apply_clahe_to_roi(roi, clip=CLAHE_CLIP, tile=CLAHE_TILE)\n",
    "        if TARGET_SIZE is not None:\n",
    "            if roi_clahe.shape[0] > TARGET_SIZE or roi_clahe.shape[1] > TARGET_SIZE:\n",
    "                interp = cv2.INTER_AREA\n",
    "            else:\n",
    "                interp = cv2.INTER_LINEAR\n",
    "            roi_clahe = cv2.resize(roi_clahe, (TARGET_SIZE, TARGET_SIZE), interpolation=interp)\n",
    "\n",
    "        rois.append(roi_clahe)\n",
    "        labels.append(label)\n",
    "        groups.append(ref_to_patient_id(ref))\n",
    "        ref_list.append(ref)\n",
    "\n",
    "    print(f\"[INFO] Extracted {len(rois)} ROIs (CLAHE applied per-ROI).\")\n",
    "    if len(rois) == 0:\n",
    "        raise RuntimeError(\"No ROIs extracted - check dataset paths and metadata.\")\n",
    "\n",
    "    # Compute LBP maps for each radius and collect global max code to set fixed bins\n",
    "    print(\"[INFO] Computing LBP maps for radii:\", LBP_RADII)\n",
    "    lbp_maps_per_radius = {r: [] for r in LBP_RADII}\n",
    "    max_code = 0\n",
    "    for roi in rois:\n",
    "        # ensure float input\n",
    "        img_float = roi.astype(np.float32)\n",
    "        for r in LBP_RADII:\n",
    "            lbp_map = local_binary_pattern(img_float, P, r, method=LBP_METHOD)\n",
    "            # LBP returns floats; convert to ints safely\n",
    "            lbp_int = np.round(lbp_map).astype(int)\n",
    "            lbp_maps_per_radius[r].append(lbp_int)\n",
    "            max_code = max(max_code, int(lbp_int.max()))\n",
    "\n",
    "    n_lbp_bins = max_code + 1\n",
    "    print(f\"[INFO] Determined LBP n_bins = {n_lbp_bins}\")\n",
    "\n",
    "    # Build feature matrices\n",
    "    X_lbp_parts = []  # will contain per-radius pooled LBP flattened\n",
    "    X_glcm = []\n",
    "    print(\"[INFO] Building pooled LBP histograms and GLCM features for each ROI...\")\n",
    "    for idx, roi in enumerate(rois):\n",
    "        roi_uint8 = roi.astype(np.uint8)\n",
    "        # LBP pooled for each radius, concatenate\n",
    "        lbp_concat = []\n",
    "        for r in LBP_RADII:\n",
    "            lbp_map = lbp_maps_per_radius[r][idx]\n",
    "            M = pooled_lbp_matrix(lbp_map, G=POOL_G, n_bins=n_lbp_bins)  # shape (G*G, n_bins)\n",
    "            lbp_concat.append(M.ravel())\n",
    "        lbp_vec = np.hstack(lbp_concat)\n",
    "        X_lbp_parts.append(lbp_vec)\n",
    "\n",
    "        # GLCM features (quantized)\n",
    "        glcm_feats = extract_glcm_features(roi_uint8, distances=GLCM_DISTANCES, angles=GLCM_ANGLES, levels=GLCM_LEVELS)\n",
    "        X_glcm.append(glcm_feats)\n",
    "\n",
    "    X_lbp = np.vstack(X_lbp_parts)\n",
    "    X_glcm = np.vstack(X_glcm)\n",
    "    X = np.hstack([X_glcm, X_lbp])\n",
    "    y = np.array(labels)\n",
    "    groups_arr = np.array(groups)\n",
    "\n",
    "    print(\"[INFO] Feature shapes: X_glcm\", X_glcm.shape, \"X_lbp\", X_lbp.shape, \"combined X\", X.shape)\n",
    "    print(\"Label counts:\", Counter(y))\n",
    "    # safety check\n",
    "    if np.isnan(X).any():\n",
    "        raise RuntimeError(\"NaN found in features!\")\n",
    "\n",
    "    # Create feature names for mapping importances\n",
    "    glcm_props = ['contrast', 'dissimilarity', 'homogeneity', 'ASM', 'energy', 'correlation']\n",
    "    glcm_names = []\n",
    "    for p in glcm_props:\n",
    "        glcm_names += [f\"{p}_mean\", f\"{p}_var\"]\n",
    "    lbp_names = []\n",
    "    region_count = POOL_G * POOL_G\n",
    "    for r in LBP_RADII:\n",
    "        for region_ix in range(region_count):\n",
    "            for code in range(n_lbp_bins):\n",
    "                lbp_names.append(f\"LBP_R{r}_r{region_ix:02d}_c{code:03d}\")\n",
    "    feature_names = glcm_names + lbp_names\n",
    "    assert X.shape[1] == len(feature_names)\n",
    "\n",
    "    # ---------------- train/test split (group-aware held-out) ----------------\n",
    "    gss = GroupShuffleSplit(n_splits=1, test_size=HOLDOUT_TEST_SIZE, random_state=RANDOM_STATE)\n",
    "    train_idx, test_idx = next(gss.split(X, y, groups_arr))\n",
    "    X_tr, X_te = X[train_idx], X[test_idx]\n",
    "    y_tr, y_te = y[train_idx], y[test_idx]\n",
    "    groups_tr, groups_te = groups_arr[train_idx], groups_arr[test_idx]\n",
    "    print(\"[INFO] Train samples:\", X_tr.shape[0], \"Test samples:\", X_te.shape[0])\n",
    "\n",
    "    # Build pipelines: keep feature selection inside pipeline (SelectKBest)\n",
    "    selector = SelectKBest(mutual_info_classif, k=min(SELECT_K, X_tr.shape[1]))\n",
    "\n",
    "    # If SMOTE available, put inside ImbPipeline, else use sklearn Pipeline and class_weight\n",
    "    if USE_SMOTE:\n",
    "        rf_pipeline = ImbPipeline([\n",
    "            ('smote', SMOTE(random_state=RANDOM_STATE)),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('select', selector),\n",
    "            ('clf', RandomForestClassifier(random_state=RANDOM_STATE, class_weight='balanced', n_jobs=-1))\n",
    "        ])\n",
    "        svm_pipeline = ImbPipeline([\n",
    "            ('smote', SMOTE(random_state=RANDOM_STATE)),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('select', selector),\n",
    "            ('clf', SVC(probability=True, class_weight='balanced', random_state=RANDOM_STATE))\n",
    "        ])\n",
    "    else:\n",
    "        rf_pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('select', selector),\n",
    "            ('clf', RandomForestClassifier(random_state=RANDOM_STATE, class_weight='balanced', n_jobs=-1))\n",
    "        ])\n",
    "        svm_pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('select', selector),\n",
    "            ('clf', SVC(probability=True, class_weight='balanced', random_state=RANDOM_STATE))\n",
    "        ])\n",
    "\n",
    "    # inner CV uses GroupKFold on training set\n",
    "    def run_gridsearch(pipeline, param_grid, X_train, y_train, groups_train, name=\"model\"):\n",
    "        inner_cv = GroupKFold(n_splits=INNER_SPLITS)\n",
    "        gs = GridSearchCV(pipeline, param_grid, cv=inner_cv.split(X_train, y_train, groups_train),\n",
    "                          scoring='roc_auc', n_jobs=-1, verbose=1)\n",
    "        gs.fit(X_train, y_train)\n",
    "        print(f\"[INFO] Best {name} params:\", gs.best_params_)\n",
    "        return gs.best_estimator_, gs\n",
    "\n",
    "    print(\"[INFO] Running inner grid-search for RandomForest...\")\n",
    "    best_rf, rf_gs = run_gridsearch(rf_pipeline, RF_PARAM_GRID, X_tr, y_tr, groups_tr, name=\"RandomForest\")\n",
    "\n",
    "    print(\"[INFO] Running inner grid-search for SVM...\")\n",
    "    best_svm, svm_gs = run_gridsearch(svm_pipeline, SVM_PARAM_GRID, X_tr, y_tr, groups_tr, name=\"SVM\")\n",
    "\n",
    "    # Evaluate on held-out test set\n",
    "    def evaluate_model(est, X_test, y_test, name=\"model\"):\n",
    "        y_pred = est.predict(X_test)\n",
    "        if hasattr(est, \"predict_proba\"):\n",
    "            try:\n",
    "                y_prob = est.predict_proba(X_test)[:, 1]\n",
    "            except Exception:\n",
    "                y_prob = None\n",
    "        else:\n",
    "            y_prob = None\n",
    "        print(f\"\\n=== Held-out evaluation: {name} ===\")\n",
    "        print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "        print(\"Recall:\", recall_score(y_test, y_pred, zero_division=0))\n",
    "        if y_prob is not None and len(np.unique(y_test)) > 1:\n",
    "            print(\"AUC:\", roc_auc_score(y_test, y_prob))\n",
    "        print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        return y_pred, y_prob\n",
    "\n",
    "    ypred_rf, yprob_rf = evaluate_model(best_rf, X_te, y_te, name=\"RandomForest (best)\")\n",
    "    ypred_svm, yprob_svm = evaluate_model(best_svm, X_te, y_te, name=\"SVM (best)\")\n",
    "\n",
    "    # Feature importances mapping (RF)\n",
    "    try:\n",
    "        rf_clf = best_rf.named_steps['clf'] if USE_SMOTE else best_rf.named_steps['clf']\n",
    "        importances = rf_clf.feature_importances_\n",
    "        # map to names\n",
    "        idxs = np.argsort(importances)[::-1][:30]\n",
    "        print(\"\\nTop 30 feature importances (index, name, importance):\")\n",
    "        for idx in idxs:\n",
    "            print(idx, feature_names[idx], f\"{importances[idx]:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(\"[WARN] Could not extract feature importances:\", e)\n",
    "\n",
    "    # Threshold tuning on held-out set to prioritize recall if desired (example)\n",
    "    if yprob_rf is not None:\n",
    "        best_thresh = 0.5\n",
    "        best_recall = recall_score(y_te, (yprob_rf >= 0.5).astype(int))\n",
    "        # choose threshold that maximizes recall while keeping precision >= 0.5 (example)\n",
    "        for t in np.linspace(0.1, 0.9, 81):\n",
    "            preds_t = (yprob_rf >= t).astype(int)\n",
    "            r = recall_score(y_te, preds_t, zero_division=0)\n",
    "            # for illustration choose threshold maximizing recall\n",
    "            if r > best_recall:\n",
    "                best_recall = r; best_thresh = t\n",
    "        print(f\"[INFO] RF held-out best threshold for recall (example): {best_thresh:.2f}, recall={best_recall:.3f}\")\n",
    "        # show confusion at best threshold\n",
    "        preds_best = (yprob_rf >= best_thresh).astype(int)\n",
    "        print(\"Confusion at chosen threshold:\\n\", confusion_matrix(y_te, preds_best))\n",
    "        print(classification_report(y_te, preds_best))\n",
    "\n",
    "    # Save outputs\n",
    "    os.makedirs(\"results\", exist_ok=True)\n",
    "    with open(os.path.join(\"results\", \"features_X_y_groups.pkl\"), \"wb\") as f:\n",
    "        pickle.dump({\"X\": X, \"y\": y, \"groups\": groups_arr, \"ref_list\": ref_list, \"feature_names\": feature_names}, f)\n",
    "    with open(os.path.join(\"results\", \"best_rf.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(best_rf, f)\n",
    "    with open(os.path.join(\"results\", \"best_svm.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(best_svm, f)\n",
    "\n",
    "    print(\"\\n[INFO] Done. Results and models saved to ./results/\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3423a7e4-ee66-41cc-8a71-c4120181c86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] imblearn not available. SMOTE disabled.\n",
      "[WARN] shap not available. SHAP plots will be skipped.\n",
      "[INFO] Built features: X.shape=(324, 134), positives=117, unique_groups=162\n",
      "[INFO] Outer fold 1: train=258 test=66 groups_train=129\n",
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n",
      " Fold 1 -> acc=0.939 auc=0.986 recall=0.870\n",
      "[INFO] Outer fold 2: train=258 test=66 groups_train=129\n",
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n",
      " Fold 2 -> acc=0.879 auc=0.919 recall=0.786\n",
      "[INFO] Outer fold 3: train=260 test=64 groups_train=130\n",
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n",
      " Fold 3 -> acc=0.859 auc=0.924 recall=0.708\n",
      "[INFO] Outer fold 4: train=260 test=64 groups_train=130\n",
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n",
      " Fold 4 -> acc=0.938 auc=0.988 recall=0.895\n",
      "[INFO] Outer fold 5: train=260 test=64 groups_train=130\n",
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n",
      " Fold 5 -> acc=0.891 auc=0.882 recall=0.696\n",
      "=== Outer CV summary ===\n",
      "Accuracy: 0.901 ± 0.032\n",
      "AUC:      0.940 ± 0.041\n",
      "Recall:   0.791 ± 0.081\n",
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n",
      "[INFO] Saved final model to final_rf_model_fixed.pkl\n"
     ]
    }
   ],
   "source": [
    "# Improved_Method2_fixed.py\n",
    "import os\n",
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from collections import Counter\n",
    "\n",
    "from skimage.feature import local_binary_pattern, graycomatrix, graycoprops\n",
    "from sklearn.model_selection import GroupKFold, GroupShuffleSplit, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, recall_score, roc_auc_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Optional: imblearn SMOTE\n",
    "USE_SMOTE = True\n",
    "try:\n",
    "    from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "except Exception:\n",
    "    USE_SMOTE = False\n",
    "    ImbPipeline = None\n",
    "    SMOTE = None\n",
    "    print(\"[WARN] imblearn not available. SMOTE disabled.\")\n",
    "\n",
    "# Optional: SHAP\n",
    "USE_SHAP = True\n",
    "try:\n",
    "    import shap\n",
    "except Exception:\n",
    "    USE_SHAP = False\n",
    "    print(\"[WARN] shap not available. SHAP plots will be skipped.\")\n",
    "\n",
    "# -------------------------\n",
    "# Config\n",
    "# -------------------------\n",
    "IMAGES_DIR = \"all-mias\"     # adjust path if needed\n",
    "META_PATH = \"data2.txt\"\n",
    "IMAGE_SIZE = 1024\n",
    "TARGET_SIZE = 128\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# LBP settings\n",
    "P = 8\n",
    "LBP_RADII = [1, 3]          # radii to compute and concatenate\n",
    "LBP_UNIFORM_BINS = 59      # uniform LBP with P=8 -> 59 bins per radius\n",
    "\n",
    "# GLCM settings\n",
    "GLCM_LEVELS = 32\n",
    "GLCM_DISTANCES = [1, 3]\n",
    "GLCM_ANGLES = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
    "\n",
    "# Feature selection\n",
    "SELECT_K = 100   # will be clipped to number of features\n",
    "\n",
    "# Grid for RF (example)\n",
    "RF_GRID = {\n",
    "    'clf__n_estimators': [100, 200],\n",
    "    'clf__max_depth': [6, 12, None],\n",
    "    'clf__min_samples_leaf': [1, 3]\n",
    "}\n",
    "\n",
    "# -------------------------\n",
    "# Helpers\n",
    "# -------------------------\n",
    "def read_metadata(meta_path):\n",
    "    col_names = ['REFNUM', 'BG', 'CLASS', 'SEVERITY', 'X', 'Y', 'RADIUS']\n",
    "    df = pd.read_csv(meta_path, sep=r\"\\s+\", names=col_names, header=None)\n",
    "    # convert RADIUS to numeric safely\n",
    "    df['RADIUS'] = pd.to_numeric(df['RADIUS'], errors='coerce')\n",
    "    df['CANCER'] = df['SEVERITY'].apply(lambda x: 1 if x in ['B','M'] else 0)\n",
    "    return df\n",
    "\n",
    "def ref_to_patient_id(ref):\n",
    "    # extracts digits and map pairs to patient id as (n-1)//2 + 1\n",
    "    import re\n",
    "    m = re.search(r\"\\d+\", str(ref))\n",
    "    if not m:\n",
    "        return 0\n",
    "    n = int(m.group(0))\n",
    "    return ((n - 1) // 2) + 1\n",
    "\n",
    "def extract_roi(img, rec, median_radius):\n",
    "    # rec expected to be a pandas Series row\n",
    "    label = rec['CANCER']\n",
    "    x, y, r = rec['X'], rec['Y'], rec['RADIUS']\n",
    "    if label==1 and not pd.isna(x) and not pd.isna(y) and not pd.isna(r):\n",
    "        cx = int(x)\n",
    "        cy = int(IMAGE_SIZE - float(y))  # MIAS coordinate conversion\n",
    "        cr = int(r)\n",
    "    else:\n",
    "        cx = IMAGE_SIZE // 2\n",
    "        cy = IMAGE_SIZE // 2\n",
    "        cr = int(median_radius)\n",
    "    x0, y0 = max(0, cx - cr), max(0, cy - cr)\n",
    "    x1, y1 = min(IMAGE_SIZE, cx + cr), min(IMAGE_SIZE, cy + cr)\n",
    "    roi = img[y0:y1, x0:x1]\n",
    "    if roi.size == 0:\n",
    "        return None\n",
    "    # CLAHE\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    roi = clahe.apply(roi)\n",
    "    roi = cv2.resize(roi, (TARGET_SIZE, TARGET_SIZE), interpolation=cv2.INTER_AREA)\n",
    "    return roi\n",
    "\n",
    "def extract_lbp_features(patch, P=P, radii=LBP_RADII, n_bins=LBP_UNIFORM_BINS):\n",
    "    feats = []\n",
    "    for R in radii:\n",
    "        lbp = local_binary_pattern(patch, P, R, method='uniform')\n",
    "        # fixed bins to n_bins (59) to keep stable feature length\n",
    "        hist, _ = np.histogram(lbp.ravel(), bins=n_bins, range=(0, n_bins), density=True)\n",
    "        feats.extend(hist.astype(float).tolist())\n",
    "    return feats\n",
    "\n",
    "def extract_glcm_features(patch, levels=GLCM_LEVELS, distances=GLCM_DISTANCES, angles=GLCM_ANGLES):\n",
    "    # quantize patch to 'levels'\n",
    "    patch_q = (patch / (256 / levels)).astype(np.uint8)\n",
    "    glcm = graycomatrix(patch_q, distances=distances, angles=angles, levels=levels, symmetric=True, normed=True)\n",
    "    props = ['contrast','dissimilarity','homogeneity','ASM','energy','correlation']\n",
    "    feats = []\n",
    "    for p in props:\n",
    "        vals = graycoprops(glcm, p)\n",
    "        feats.extend(vals.mean(axis=1).tolist())  # mean across angles/distances\n",
    "    return feats\n",
    "\n",
    "def extract_intensity_stats(patch):\n",
    "    return [float(patch.mean()), float(patch.std()), float(patch.min()), float(patch.max())]\n",
    "\n",
    "# -------------------------\n",
    "# Build feature matrix\n",
    "# -------------------------\n",
    "meta = read_metadata(META_PATH)\n",
    "median_radius = int(meta.loc[meta['CANCER']==1, 'RADIUS'].dropna().median()) if meta['RADIUS'].notna().any() else 48\n",
    "\n",
    "features_list = []\n",
    "labels = []\n",
    "groups = []\n",
    "filenames = []\n",
    "\n",
    "for fname in sorted(os.listdir(IMAGES_DIR)):\n",
    "    if not fname.lower().endswith('.pgm'):\n",
    "        continue\n",
    "    ref = os.path.splitext(fname)[0]\n",
    "    rec = meta[meta['REFNUM'] == ref]\n",
    "    if rec.empty:\n",
    "        continue\n",
    "    rec = rec.iloc[0]\n",
    "    img_path = os.path.join(IMAGES_DIR, fname)\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        continue\n",
    "    roi = extract_roi(img, rec, median_radius)\n",
    "    if roi is None:\n",
    "        continue\n",
    "    lbp_feat = extract_lbp_features(roi)\n",
    "    glcm_feat = extract_glcm_features(roi)\n",
    "    int_feat = extract_intensity_stats(roi)\n",
    "    feat = lbp_feat + glcm_feat + int_feat\n",
    "    features_list.append(feat)\n",
    "    labels.append(int(rec['CANCER']))\n",
    "    gid = ref_to_patient_id(ref)\n",
    "    groups.append(gid)\n",
    "    filenames.append(ref)\n",
    "\n",
    "X = np.array(features_list, dtype=float)\n",
    "y = np.array(labels, dtype=int)\n",
    "groups = np.array(groups, dtype=int)\n",
    "\n",
    "print(f\"[INFO] Built features: X.shape={X.shape}, positives={y.sum()}, unique_groups={np.unique(groups).shape[0]}\")\n",
    "\n",
    "# -------------------------\n",
    "# Pipeline + nested CV\n",
    "# -------------------------\n",
    "# make sure SELECT_K not larger than number of features\n",
    "n_features = X.shape[1]\n",
    "SELECT_K_SAFE = min(SELECT_K if 'SELECT_K' in globals() else 100, n_features)\n",
    "\n",
    "selector = SelectKBest(mutual_info_classif, k=SELECT_K_SAFE)\n",
    "scaler = StandardScaler()\n",
    "rf = RandomForestClassifier(class_weight='balanced', random_state=RANDOM_STATE)\n",
    "\n",
    "steps = [('scaler', scaler), ('select', selector), ('clf', rf)]\n",
    "if USE_SMOTE and ImbPipeline:\n",
    "    pipeline = ImbPipeline([('smote', SMOTE(random_state=RANDOM_STATE))] + steps)\n",
    "else:\n",
    "    from sklearn.pipeline import Pipeline as SKPipeline\n",
    "    pipeline = SKPipeline(steps)\n",
    "\n",
    "cv_outer = GroupKFold(n_splits=5)\n",
    "cv_inner = GroupKFold(n_splits=4)\n",
    "\n",
    "search = GridSearchCV(pipeline, RF_GRID, cv=cv_inner, scoring='roc_auc', n_jobs=-1, refit=True, verbose=1)\n",
    "\n",
    "outer_scores = []\n",
    "fold_idx = 0\n",
    "for train_idx, test_idx in cv_outer.split(X, y, groups):\n",
    "    fold_idx += 1\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    groups_train, groups_test = groups[train_idx], groups[test_idx]\n",
    "\n",
    "    # Note: pass groups to fit so inner GroupKFold can use them\n",
    "    print(f\"[INFO] Outer fold {fold_idx}: train={X_train.shape[0]} test={X_test.shape[0]} groups_train={np.unique(groups_train).size}\")\n",
    "    search.fit(X_train, y_train, groups=groups_train)\n",
    "\n",
    "    best = search.best_estimator_\n",
    "    y_pred = best.predict(X_test)\n",
    "    y_prob = best.predict_proba(X_test)[:,1] if hasattr(best, \"predict_proba\") else best.decision_function(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_prob) if len(np.unique(y_test))>1 else float('nan')\n",
    "    rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "    outer_scores.append({'acc': acc, 'auc': auc, 'recall': rec})\n",
    "    print(f\" Fold {fold_idx} -> acc={acc:.3f} auc={auc:.3f} recall={rec:.3f}\")\n",
    "\n",
    "# Summary\n",
    "import statistics\n",
    "accs = [s['acc'] for s in outer_scores]\n",
    "aucs = [s['auc'] for s in outer_scores if not math.isnan(s['auc'])]\n",
    "recs = [s['recall'] for s in outer_scores]\n",
    "print(\"=== Outer CV summary ===\")\n",
    "print(f\"Accuracy: {np.mean(accs):.3f} ± {np.std(accs):.3f}\")\n",
    "print(f\"AUC:      {np.mean(aucs):.3f} ± {np.std(aucs):.3f}\")\n",
    "print(f\"Recall:   {np.mean(recs):.3f} ± {np.std(recs):.3f}\")\n",
    "\n",
    "# Fit final model on full data (pass groups)\n",
    "search.fit(X, y, groups=groups)\n",
    "best_final = search.best_estimator_\n",
    "\n",
    "# Save model\n",
    "with open(\"final_rf_model_fixed.pkl\", \"wb\") as f:\n",
    "    pickle.dump(best_final, f)\n",
    "print(\"[INFO] Saved final model to final_rf_model_fixed.pkl\")\n",
    "\n",
    "# Optional SHAP explanations (if available)\n",
    "if USE_SHAP:\n",
    "    try:\n",
    "        # Get feature names\n",
    "        feat_names = []\n",
    "        # LBP feature names\n",
    "        for r in LBP_RADII:\n",
    "            for i in range(LBP_UNIFORM_BINS):\n",
    "                feat_names.append(f\"lbp_r{r}_{i}\")\n",
    "        # GLCM names\n",
    "        props = ['contrast','dissimilarity','homogeneity','ASM','energy','correlation']\n",
    "        for p in props:\n",
    "            for d in GLCM_DISTANCES:\n",
    "                feat_names.append(f\"glcm_{p}_d{d}\")\n",
    "        feat_names += ['mean_int','std_int','min_int','max_int']\n",
    "        # prepare transformed data (through scaler+selector pipeline)\n",
    "        transformed = best_final.named_steps['select'].transform(best_final.named_steps['scaler'].transform(X))\n",
    "        explainer = shap.KernelExplainer(best_final.named_steps['clf'].predict_proba, transformed[:50])\n",
    "        shap_vals = explainer.shap_values(transformed[:200])  # small subset\n",
    "        # Save a simple summary\n",
    "        shap.summary_plot(shap_vals[1], features=transformed, feature_names=feat_names, show=False)\n",
    "    except Exception as e:\n",
    "        print(\"[WARN] SHAP failed:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03ccf363-15f0-4395-9e29-b1e8d012edfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Features built: (324, 128) Positives: 117 Unique groups: 162\n",
      "[INFO] Train/test sizes: 258 66\n",
      "[INFO] Train label counts: Counter({np.int64(0): 165, np.int64(1): 93}) Test label counts: Counter({np.int64(0): 42, np.int64(1): 24})\n",
      "[INFO] Running GridSearchCV on training partition (inner GroupKFold)...\n",
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n",
      "[INFO] Best params: {'clf__max_depth': None, 'clf__min_samples_leaf': 1, 'clf__n_estimators': 300}\n",
      "\\n=== Held-out evaluation: RandomForest (best) ===\n",
      "Accuracy: 0.8333333333333334\n",
      "Recall: 0.7916666666666666\n",
      "AUC: 0.9221230158730158\n",
      "Confusion Matrix:\\n [[36  6]\n",
      " [ 5 19]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8780    0.8571    0.8675        42\n",
      "           1     0.7600    0.7917    0.7755        24\n",
      "\n",
      "    accuracy                         0.8333        66\n",
      "   macro avg     0.8190    0.8244    0.8215        66\n",
      "weighted avg     0.8351    0.8333    0.8340        66\n",
      "\n",
      "[INFO] Saving best pipeline to final_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# run_method2_heldout_summary.py\n",
    "import os\n",
    "import math\n",
    "import pickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from skimage.feature import local_binary_pattern, graycomatrix, graycoprops\n",
    "from sklearn.model_selection import GroupShuffleSplit, GroupKFold, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.metrics import accuracy_score, recall_score, roc_auc_score, classification_report, confusion_matrix, precision_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Optional: imblearn SMOTE\n",
    "USE_SMOTE = False\n",
    "try:\n",
    "    from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    USE_SMOTE = True\n",
    "except Exception:\n",
    "    USE_SMOTE = False\n",
    "\n",
    "# Optional: SHAP\n",
    "USE_SHAP = False\n",
    "try:\n",
    "    import shap\n",
    "    USE_SHAP = True\n",
    "except Exception:\n",
    "    USE_SHAP = False\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "IMAGES_DIR = \"all-mias\"   # folder with .pgm files\n",
    "META_PATH = \"data2.txt\"\n",
    "IMAGE_SIZE = 1024\n",
    "TARGET_SIZE = 128        # change to 64/256 to trade speed vs detail\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# LBP (uniform)\n",
    "P = 8\n",
    "LBP_RADII = [1, 3]      # radii to use\n",
    "LBP_BINS = 59           # fixed for uniform P=8\n",
    "\n",
    "# GLCM (simple)\n",
    "GLCM_LEVELS = 32\n",
    "GLCM_DISTANCES = [1]    # use [1] or [1,3]\n",
    "GLCM_ANGLES = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
    "\n",
    "# feature selection and grid\n",
    "SELECT_K = 100\n",
    "RF_GRID = {\n",
    "    'clf__n_estimators': [100, 300],\n",
    "    'clf__max_depth': [6, 12, None],\n",
    "    'clf__min_samples_leaf': [1, 3]\n",
    "}\n",
    "\n",
    "# ---------- HELPERS ----------\n",
    "def read_meta(path):\n",
    "    col_names = ['REFNUM', 'BG', 'CLASS', 'SEVERITY', 'X', 'Y', 'RADIUS']\n",
    "    df = pd.read_csv(path, sep=r\"\\s+\", names=col_names, header=None)\n",
    "    df['RADIUS'] = pd.to_numeric(df['RADIUS'], errors='coerce')\n",
    "    df['CANCER'] = df['SEVERITY'].apply(lambda x: 1 if x in ['B','M'] else 0)\n",
    "    return df\n",
    "\n",
    "def ref_to_patient(ref):\n",
    "    import re\n",
    "    m = re.search(r\"\\d+\", str(ref))\n",
    "    if not m: return 0\n",
    "    n = int(m.group(0))\n",
    "    return ((n-1)//2) + 1\n",
    "\n",
    "def extract_roi(img, rec, median_radius):\n",
    "    label = rec['CANCER']; x = rec['X']; y = rec['Y']; r = rec['RADIUS']\n",
    "    if label==1 and pd.notna(x) and pd.notna(y) and pd.notna(r):\n",
    "        cx = int(x); cy = int(IMAGE_SIZE - float(y)); cr = int(r)\n",
    "    else:\n",
    "        cx = IMAGE_SIZE//2; cy = IMAGE_SIZE//2; cr = int(median_radius)\n",
    "    x0,y0 = max(0, cx-cr), max(0, cy-cr)\n",
    "    x1,y1 = min(IMAGE_SIZE, cx+cr), min(IMAGE_SIZE, cy+cr)\n",
    "    roi = img[y0:y1, x0:x1]\n",
    "    if roi.size == 0:\n",
    "        return None\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    roi = clahe.apply(roi)\n",
    "    roi = cv2.resize(roi, (TARGET_SIZE, TARGET_SIZE), interpolation=cv2.INTER_AREA)\n",
    "    return roi\n",
    "\n",
    "def lbp_features(patch, P=P, radii=LBP_RADII, bins=LBP_BINS):\n",
    "    feats = []\n",
    "    for R in radii:\n",
    "        lbp = local_binary_pattern(patch, P, R, method='uniform')\n",
    "        hist, _ = np.histogram(lbp.ravel(), bins=bins, range=(0, bins), density=True)\n",
    "        feats.extend(hist.astype(float).tolist())\n",
    "    return feats\n",
    "\n",
    "def glcm_features(patch, levels=GLCM_LEVELS, distances=GLCM_DISTANCES, angles=GLCM_ANGLES):\n",
    "    patch_q = (patch / (256/levels)).astype(np.uint8)\n",
    "    glcm = graycomatrix(patch_q, distances=distances, angles=angles, levels=levels, symmetric=True, normed=True)\n",
    "    props = ['contrast','dissimilarity','homogeneity','ASM','energy','correlation']\n",
    "    feats = []\n",
    "    for p in props:\n",
    "        vals = graycoprops(glcm, p)\n",
    "        feats.append(float(vals.mean()))\n",
    "    return feats\n",
    "\n",
    "def intensity_stats(patch):\n",
    "    return [float(patch.mean()), float(patch.std()), float(patch.min()), float(patch.max())]\n",
    "\n",
    "# ---------- BUILD FEATURES ----------\n",
    "meta = read_meta(META_PATH)\n",
    "median_radius = int(meta.loc[meta['CANCER']==1, 'RADIUS'].dropna().median()) if meta['RADIUS'].notna().any() else 48\n",
    "\n",
    "features = []\n",
    "labels = []\n",
    "groups = []\n",
    "filenames = []\n",
    "\n",
    "for fname in sorted(os.listdir(IMAGES_DIR)):\n",
    "    if not fname.lower().endswith('.pgm'): \n",
    "        continue\n",
    "    ref = os.path.splitext(fname)[0]\n",
    "    recs = meta[meta['REFNUM']==ref]\n",
    "    if recs.empty: \n",
    "        continue\n",
    "    rec = recs.iloc[0]\n",
    "    img = cv2.imread(os.path.join(IMAGES_DIR, fname), cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        continue\n",
    "    roi = extract_roi(img, rec, median_radius)\n",
    "    if roi is None:\n",
    "        continue\n",
    "    # compute features (comment/uncomment blocks to speed up)\n",
    "    lbp_f = lbp_features(roi)                # stable 59*len(radii)\n",
    "    glcm_f = glcm_features(roi)              # small number of features\n",
    "    int_f  = intensity_stats(roi)\n",
    "    feat = lbp_f + glcm_f + int_f\n",
    "    features.append(feat)\n",
    "    labels.append(int(rec['CANCER']))\n",
    "    groups.append(ref_to_patient(ref))\n",
    "    filenames.append(ref)\n",
    "\n",
    "X = np.array(features, dtype=float)\n",
    "y = np.array(labels, dtype=int)\n",
    "groups = np.array(groups, dtype=int)\n",
    "\n",
    "print(\"[INFO] Features built:\", X.shape, \"Positives:\", y.sum(), \"Unique groups:\", len(np.unique(groups)))\n",
    "\n",
    "# ---------- HELD-OUT SPLIT (patient-wise) ----------\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=RANDOM_STATE)\n",
    "train_idx, test_idx = next(gss.split(X, y, groups))\n",
    "X_train, X_test = X[train_idx], X[test_idx]; y_train, y_test = y[train_idx], y[test_idx]\n",
    "groups_train, groups_test = groups[train_idx], groups[test_idx]\n",
    "\n",
    "print(\"[INFO] Train/test sizes:\", X_train.shape[0], X_test.shape[0])\n",
    "print(\"[INFO] Train label counts:\", Counter(y_train), \"Test label counts:\", Counter(y_test))\n",
    "\n",
    "# ---------- PIPELINE and NESTED CV on training partition ----------\n",
    "from sklearn.pipeline import Pipeline as SKPipeline\n",
    "select_k = min(SELECT_K, X.shape[1]) if 'SELECT_K' in globals() else min(100, X.shape[1])\n",
    "pipeline_steps = [('scaler', StandardScaler()), ('select', SelectKBest(mutual_info_classif, k=select_k)), ('clf', RandomForestClassifier(class_weight='balanced', random_state=RANDOM_STATE))]\n",
    "pipeline = SKPipeline(pipeline_steps)\n",
    "\n",
    "inner_cv = GroupKFold(n_splits=4)\n",
    "search = GridSearchCV(pipeline, RF_GRID, cv=inner_cv, scoring='roc_auc', n_jobs=-1, refit=True, verbose=1)\n",
    "\n",
    "print(\"[INFO] Running GridSearchCV on training partition (inner GroupKFold)...\")\n",
    "# pass groups so GroupKFold inside GridSearchCV can split properly\n",
    "search.fit(X_train, y_train, groups=groups_train)\n",
    "\n",
    "best_model = search.best_estimator_\n",
    "print(\"[INFO] Best params:\", search.best_params_)\n",
    "\n",
    "# ---------- Evaluate on held-out ----------\n",
    "if hasattr(best_model, \"predict_proba\"):\n",
    "    y_prob = best_model.predict_proba(X_test)[:,1]\n",
    "else:\n",
    "    y_prob = best_model.decision_function(X_test)\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "auc = roc_auc_score(y_test, y_prob) if len(np.unique(y_test))>1 else float('nan')\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred, digits=4)\n",
    "\n",
    "print(\"\\\\n=== Held-out evaluation: RandomForest (best) ===\")\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"Recall:\", rec)\n",
    "print(\"AUC:\", auc)\n",
    "print(\"Confusion Matrix:\\\\n\", cm)\n",
    "print(report)\n",
    "\n",
    "# Save final model fit on full training+validation (optionally refit on all data)\n",
    "print(\"[INFO] Saving best pipeline to final_model.pkl\")\n",
    "with open(\"final_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "# Optional: SHAP (if installed) - expensive\n",
    "if USE_SHAP:\n",
    "    try:\n",
    "        print(\"[INFO] Computing SHAP explanations (this may be slow)...\")\n",
    "        # get transformed features for model input to classifier\n",
    "        transformed = best_model.named_steps['select'].transform(best_model.named_steps['scaler'].transform(X))\n",
    "        explainer = shap.KernelExplainer(best_model.named_steps['clf'].predict_proba, transformed[:50])\n",
    "        shap_vals = explainer.shap_values(transformed[:200])\n",
    "        shap.summary_plot(shap_vals[1], features=transformed, feature_names=None)\n",
    "    except Exception as e:\n",
    "        print(\"[WARN] SHAP failed:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "081707cf-5be2-42d0-b482-bc8461015340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import time\n",
    "import math\n",
    "import json\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.feature import local_binary_pattern, graycomatrix, graycoprops\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GroupKFold, GroupShuffleSplit, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, recall_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.base import clone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ae707a21-5785-4082-964f-71d1055eb3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_metadata(meta_path):\n",
    "    meta = pd.read_csv(meta_path, delim_whitespace=True, dtype=str)\n",
    "    meta.columns = [c.strip().upper() for c in meta.columns]\n",
    "    \n",
    "    # Now you should have proper columns like 'CLASS' or 'SEVERITY'\n",
    "    if 'SEVERITY' in meta.columns:\n",
    "        meta['CANCER'] = meta['SEVERITY'].map({'B': 1, 'M': 1}).fillna(0).astype(int)\n",
    "    elif 'CLASS' in meta.columns:\n",
    "        meta['CANCER'] = meta['CLASS'].map({'B': 1, 'M': 1}).fillna(0).astype(int)\n",
    "    else:\n",
    "        raise ValueError(\"Missing CLASS or SEVERITY column for cancer label.\")\n",
    "\n",
    "    meta['RADIUS'] = pd.to_numeric(meta['RADIUS'], errors='coerce')\n",
    "    return meta\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_img(img, target_size, min_side=32):\n",
    "    h, w = img.shape\n",
    "    if min(h, w) < min_side:\n",
    "        return None\n",
    "    scale = target_size / min(h, w)\n",
    "    new_h, new_w = int(h * scale), int(w * scale)\n",
    "    img_resized = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "    return img_resized\n",
    "\n",
    "\n",
    "def roi_from_row(img, row, fallback_radius=32, target_size=64):\n",
    "    x, y = row['X'], row['Y']\n",
    "    radius = row['RADIUS']\n",
    "    if pd.isna(radius):\n",
    "        radius = fallback_radius\n",
    "    r = int(radius)\n",
    "    x, y = int(x), int(y)\n",
    "    roi = img[max(0, y - r): y + r, max(0, x - r): x + r]\n",
    "    roi_resized = cv2.resize(roi, (target_size, target_size), interpolation=cv2.INTER_AREA)\n",
    "    return roi_resized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2f26764d-e99c-4c80-bb1a-ab1b8844503f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def compute_glcm_features(roi, levels=32, distances=[1]):\n",
    "    roi_scaled = (roi / (256 / levels)).astype(np.uint8)\n",
    "    glcm = graycomatrix(roi_scaled, distances=distances, angles=[0], levels=levels, symmetric=True, normed=True)\n",
    "    feats = {\n",
    "        'contrast': graycoprops(glcm, 'contrast')[0, 0],\n",
    "        'dissimilarity': graycoprops(glcm, 'dissimilarity')[0, 0],\n",
    "        'homogeneity': graycoprops(glcm, 'homogeneity')[0, 0],\n",
    "        'energy': graycoprops(glcm, 'energy')[0, 0],\n",
    "        'correlation': graycoprops(glcm, 'correlation')[0, 0],\n",
    "        'ASM': graycoprops(glcm, 'ASM')[0, 0],\n",
    "    }\n",
    "    return feats\n",
    "\n",
    "\n",
    "def compute_lbp_hist(roi, P=8, R=1, bins=59):\n",
    "    lbp = local_binary_pattern(roi, P, R, method='uniform')\n",
    "    hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, bins + 1), range=(0, bins))\n",
    "    hist = hist.astype(float)\n",
    "    hist /= (hist.sum() + 1e-6)\n",
    "    return {f'lbp_{i}': h for i, h in enumerate(hist)}\n",
    "\n",
    "\n",
    "def intensity_stats(roi):\n",
    "    stats = {\n",
    "        'mean': np.mean(roi),\n",
    "        'std': np.std(roi),\n",
    "        'skew': skew(roi.flatten())\n",
    "    }\n",
    "    return stats\n",
    "\n",
    "\n",
    "def convert(feat_dicts):\n",
    "    all_keys = sorted({k for d in feat_dicts for k in d})\n",
    "    X = np.array([[d.get(k, 0) for k in all_keys] for d in feat_dicts])\n",
    "    return X, all_keys\n",
    "\n",
    "\n",
    "def group_permutation_test(y_true, y_pred, groups, n_permutations=1000, random_state=42, scorer=accuracy_score):\n",
    "    np.random.seed(random_state)\n",
    "    true_score = scorer(y_true, y_pred)\n",
    "    count = 0\n",
    "    for _ in range(n_permutations):\n",
    "        permuted = y_true.copy()\n",
    "        group_ids = np.unique(groups)\n",
    "        np.random.shuffle(group_ids)\n",
    "        permuted_groups = dict(zip(group_ids, group_ids))\n",
    "        shuffled = [permuted_groups[g] for g in groups]\n",
    "        if scorer(permuted, y_pred) >= true_score:\n",
    "            count += 1\n",
    "    p_value = (count + 1) / (n_permutations + 1)\n",
    "    return p_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "93d8aaaa-d33e-44c9-b0d9-842690bfc88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['REFNUM BG CLASS SEVERITY X Y RADIUS'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "meta = pd.read_csv(\"data2.txt\", sep=';', dtype=str)\n",
    "meta.columns = [c.strip().upper() for c in meta.columns]\n",
    "print(meta.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "560335a2-08fa-486c-acce-3972815730c4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aa23147\\AppData\\Local\\Temp\\ipykernel_17120\\1787884179.py:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  meta = pd.read_csv(meta_path, delim_whitespace=True, dtype=str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] metadata rows: 324\n",
      "[INFO] median radius: 43\n",
      "[INFO] found 324 image files in all-mias\n",
      "[ERROR] processing mdb001: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb002: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb003: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb004: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb005: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb006: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb007: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb008: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb009: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb010: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb011: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb012: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb013: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb014: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb015: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb016: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb017: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb018: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb019: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb020: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb021: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb022: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb023: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb024: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb025: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb026: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb027: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb028: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb029: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb030: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb031: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb032: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb033: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb034: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb035: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb036: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb037: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb038: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb039: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb040: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb041: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb042: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb043: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb044: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb045: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb046: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb047: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb048: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb049: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb050: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb051: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb052: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb053: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb054: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb055: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb056: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb057: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb058: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb059: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb060: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb061: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb062: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb063: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb064: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb065: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb066: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb067: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb068: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb069: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb070: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb071: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb072: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb073: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb074: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb075: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb076: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb077: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb078: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb079: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb080: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb081: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb082: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb083: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb084: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb085: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb086: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb087: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb088: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb089: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb090: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb091: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb092: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb093: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb094: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb095: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb096: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb097: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb098: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb099: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb100: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb101: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb102: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb103: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb104: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb105: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb106: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb107: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb108: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb109: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb110: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb111: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb112: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb113: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb114: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb115: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb116: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb117: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb118: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb119: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb120: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb121: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb122: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb123: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb124: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb125: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb126: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb127: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb128: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb129: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb130: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb131: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb132: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb133: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb134: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb135: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb136: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb137: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb138: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb139: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb140: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb141: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb142: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb143: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb144: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb145: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb146: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb147: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb148: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb149: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb150: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb151: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb152: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb153: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb154: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb155: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb156: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb157: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb158: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb159: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb160: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb161: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb162: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb163: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb164: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb165: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb166: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb167: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb168: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb169: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb170: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb171: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb172: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb173: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb174: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb175: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb176: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb177: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb178: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb179: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb180: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb181: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb182: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb183: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb184: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb185: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb186: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb187: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb188: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb189: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb190: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb191: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb192: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb193: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb194: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb195: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb196: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb197: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb198: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb199: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb200: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb201: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb202: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb203: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb204: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb205: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb206: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb207: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb208: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb209: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb210: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb211: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb212: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb213: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb214: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb215: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb216: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb217: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb218: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb219: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb220: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb221: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb222: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb223: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb224: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb225: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb226: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb227: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb228: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb229: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb230: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb231: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb232: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb233: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb234: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb235: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb236: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb237: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb238: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb239: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb240: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb241: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb242: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb243: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb244: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb245: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb246: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb247: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb248: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb249: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb250: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb251: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb252: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb253: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb254: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb255: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb256: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb257: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb258: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb259: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb260: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb261: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb262: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb263: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb264: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb265: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb266: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb267: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb268: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb269: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb270: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb271: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb272: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb273: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb274: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb275: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb276: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb277: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb278: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb279: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb280: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb281: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb282: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb283: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb284: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb285: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb286: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb287: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb288: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb289: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb290: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb291: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb292: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb293: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb294: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb295: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb296: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb297: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb298: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb299: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb300: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb301: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb302: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb303: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb304: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb305: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb306: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb307: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb308: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb309: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb310: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb311: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb312: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb313: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb314: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb315: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb316: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb317: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb318: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb319: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb320: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb321: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb322: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb323: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[ERROR] processing mdb324: preprocess_img() missing 1 required positional argument: 'target_size'\n",
      "[INFO] extracted features shape: (0, 123)\n",
      " label distribution: Counter()\n",
      " unique groups: 0\n",
      "[INFO] saved features.pkl\n",
      "[INFO] saved sample_rois.png\n",
      "[INFO] using outer_splits=2, inner_splits=2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot have number of splits n_splits=2 greater than the number of samples: n_samples=0.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 216\u001b[0m\n\u001b[0;32m    213\u001b[0m     glcm_levels \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n\u001b[0;32m    215\u001b[0m args \u001b[38;5;241m=\u001b[39m Args()\n\u001b[1;32m--> 216\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[44], line 108\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m    105\u001b[0m best_models \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    107\u001b[0m fold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 108\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_idx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mouter_cv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups_arr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfold\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mXtr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXte\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest_idx\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\python3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:404\u001b[0m, in \u001b[0;36m_BaseKFold.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    402\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(X)\n\u001b[0;32m    403\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits \u001b[38;5;241m>\u001b[39m n_samples:\n\u001b[1;32m--> 404\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    405\u001b[0m         (\n\u001b[0;32m    406\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot have number of splits n_splits=\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m greater\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    407\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m than the number of samples: n_samples=\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    408\u001b[0m         )\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits, n_samples)\n\u001b[0;32m    409\u001b[0m     )\n\u001b[0;32m    411\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msplit(X, y, groups):\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m train, test\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot have number of splits n_splits=2 greater than the number of samples: n_samples=0."
     ]
    }
   ],
   "source": [
    "def main(args):\n",
    "    start_time = time.time()\n",
    "    cfg = {\n",
    "        'P': args.P,\n",
    "        'lbp_radii': tuple(args.lbp_radii),\n",
    "        'lbp_bins': args.lbp_bins,\n",
    "        'glcm_distances': tuple(args.glcm_distances),\n",
    "        'glcm_angles': (0, math.pi/4, math.pi/2, 3*math.pi/4),\n",
    "        'glcm_levels': args.glcm_levels,\n",
    "    }\n",
    "\n",
    "    # read metadata\n",
    "    df = read_metadata(args.meta)\n",
    "    print(f\"[INFO] metadata rows: {len(df)}\")\n",
    "    radii_num = pd.to_numeric(df['RADIUS'], errors='coerce').dropna()\n",
    "    median_radius = int(radii_num.median()) if radii_num.size > 0 else args.median_radius\n",
    "    print(f\"[INFO] median radius: {median_radius}\")\n",
    "\n",
    "    # list images\n",
    "    images = sorted([f for f in os.listdir(args.images) if f.lower().endswith('.pgm')])\n",
    "    print(f\"[INFO] found {len(images)} image files in {args.images}\")\n",
    "\n",
    "    features = []\n",
    "    labels = []\n",
    "    groups = []\n",
    "    sample_rois = []\n",
    "\n",
    "    for fname in images:\n",
    "        ref = os.path.splitext(fname)[0]\n",
    "        row = df[df['REFNUM'] == ref]\n",
    "        if row.empty:\n",
    "            continue\n",
    "        row = row.iloc[0]\n",
    "        img_path = os.path.join(args.images, fname)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            print(f\"[WARN] cannot read {img_path}, skipping\")\n",
    "            continue\n",
    "        try:\n",
    "            img_eq = preprocess_img(img)\n",
    "            roi = roi_from_row(img_eq, row, image_size=args.image_size, median_radius=median_radius, min_side=args.min_side)\n",
    "            # resize to target_size (keep consistent)\n",
    "            roi_resized = cv2.resize(roi, (args.target_size, args.target_size), interpolation=cv2.INTER_AREA)\n",
    "            # Method2 logic but GLCM first then LBP\n",
    "            glcm_feats = compute_glcm_features(roi_resized, distances=cfg['glcm_distances'], angles=cfg['glcm_angles'], levels=cfg['glcm_levels'])\n",
    "            lbp_feats = compute_lbp_hist(roi_resized, P=cfg['P'], radii=cfg['lbp_radii'], n_bins=cfg['lbp_bins'])\n",
    "            int_feats = intensity_stats(roi_resized)\n",
    "            feat_vec = np.concatenate([glcm_feats, lbp_feats, int_feats]).astype(float)\n",
    "            features.append(feat_vec)\n",
    "            labels.append(int(row['CANCER']))\n",
    "            groups.append(row['patient_id'])\n",
    "            if len(sample_rois) < 6:\n",
    "                sample_rois.append((ref, int(row['CANCER']), row['patient_id'], roi_resized))\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] processing {ref}: {e}\")\n",
    "\n",
    "    X = np.vstack(features) if len(features) > 0 else np.zeros((0, cfg['lbp_bins']*len(cfg['lbp_radii']) + 5))\n",
    "    y = np.array(labels, dtype=int)\n",
    "    groups_arr = np.array(groups)\n",
    "    print(\"[INFO] extracted features shape:\", X.shape)\n",
    "    print(\" label distribution:\", Counter(y))\n",
    "    print(\" unique groups:\", len(set([g for g in groups_arr if g is not None])))\n",
    "\n",
    "    # save features.pkl\n",
    "    os.makedirs(args.outdir, exist_ok=True)\n",
    "    with open(os.path.join(args.outdir, \"features.pkl\"), \"wb\") as f:\n",
    "        pickle.dump({\"X\": X, \"y\": y, \"groups\": groups_arr, \"cfg\": cfg}, f)\n",
    "    print(\"[INFO] saved features.pkl\")\n",
    "\n",
    "    # save sample rois image\n",
    "    fig = plt.figure(figsize=(10,4))\n",
    "    for idx, (ref, lab, grp, roi_img) in enumerate(sample_rois):\n",
    "        ax = fig.add_subplot(2,3, idx+1)\n",
    "        ax.imshow(roi_img, cmap='gray'); ax.set_title(f\"{ref} L={lab} G={grp}\"); ax.axis('off')\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(os.path.join(args.outdir, \"sample_rois.png\"))\n",
    "    plt.close(fig)\n",
    "    print(\"[INFO] saved sample_rois.png\")\n",
    "\n",
    "    # -------------------------\n",
    "    # Nested group-aware CV\n",
    "    # -------------------------\n",
    "    unique_groups = len(set([g for g in groups_arr if g is not None]))\n",
    "    outer_splits = min(5, max(2, unique_groups))\n",
    "    inner_splits = max(2, outer_splits - 1)\n",
    "    print(f\"[INFO] using outer_splits={outer_splits}, inner_splits={inner_splits}\")\n",
    "\n",
    "    outer_cv = GroupKFold(n_splits=outer_splits)\n",
    "    inner_cv = GroupKFold(n_splits=inner_splits)\n",
    "\n",
    "    # build pipelines (scaler + selector + clf) to avoid leakage\n",
    "    selector = SelectKBest(mutual_info_classif, k=min(args.select_k, X.shape[1]))\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    pipelines = {\n",
    "        'rf': Pipeline([('scaler', scaler), ('select', selector), ('clf', RandomForestClassifier(class_weight='balanced', random_state=args.random_state))]),\n",
    "        'svm': Pipeline([('scaler', scaler), ('select', selector), ('clf', SVC(probability=True, class_weight='balanced', random_state=args.random_state))]),\n",
    "    }\n",
    "\n",
    "    # small parameter grids (kept simple — expand if desired)\n",
    "    rf_grid = {'clf__n_estimators': [args.rf_estimators], 'clf__max_depth': [None], 'clf__min_samples_leaf': [1]}\n",
    "    svm_grid = {'clf__C': [1.0], 'clf__gamma': ['scale']}\n",
    "\n",
    "    results = {k: [] for k in pipelines.keys()}\n",
    "    best_models = {}\n",
    "\n",
    "    fold = 0\n",
    "    for train_idx, test_idx in outer_cv.split(X, y, groups_arr):\n",
    "        fold += 1\n",
    "        Xtr, Xte = X[train_idx], X[test_idx]\n",
    "        ytr, yte = y[train_idx], y[test_idx]\n",
    "        gtr, gte = groups_arr[train_idx], groups_arr[test_idx]\n",
    "        print(f\"[INFO] Outer fold {fold}: train={len(train_idx)} test={len(test_idx)} groups_train={len(set(gtr))}\")\n",
    "\n",
    "        for name, pipe in pipelines.items():\n",
    "            param_grid = rf_grid if name == 'rf' else svm_grid\n",
    "            gs = GridSearchCV(pipe, param_grid, cv=inner_cv, scoring='roc_auc', n_jobs=args.n_jobs, refit=True)\n",
    "            # IMPORTANT: pass groups so inner GroupKFold uses them\n",
    "            gs.fit(Xtr, ytr, groups=gtr)\n",
    "            best = gs.best_estimator_\n",
    "            # evaluate on outer test\n",
    "            ypred = best.predict(Xte)\n",
    "            if hasattr(best, \"predict_proba\"):\n",
    "                yprob = best.predict_proba(Xte)[:,1]\n",
    "            else:\n",
    "                yprob = best.decision_function(Xte)\n",
    "            acc = accuracy_score(yte, ypred)\n",
    "            rec = recall_score(yte, ypred, zero_division=0)\n",
    "            auc = roc_auc_score(yte, yprob) if len(np.unique(yte)) > 1 else float('nan')\n",
    "            cm = confusion_matrix(yte, ypred)\n",
    "            results[name].append({'fold': fold, 'acc': acc, 'recall': rec, 'auc': auc, 'cm': cm, 'best_params': gs.best_params_})\n",
    "            best_models[name] = gs.best_estimator_\n",
    "            print(f\"[FOLD {fold}][{name}] acc={acc:.3f} rec={rec:.3f} auc={auc:.3f}\")\n",
    "\n",
    "    # summarize\n",
    "    summary = {\n",
    "        'n_samples': int(X.shape[0]),\n",
    "        'n_features': int(X.shape[1]),\n",
    "        'label_counts': dict(pd.Series(y).value_counts()),\n",
    "        'unique_groups': int(len(set(groups_arr))),\n",
    "        'cv': {}\n",
    "    }\n",
    "    for name in results:\n",
    "        arr_acc = np.array([r['acc'] for r in results[name]])\n",
    "        arr_rec = np.array([r['recall'] for r in results[name]])\n",
    "        arr_auc = np.array([r['auc'] for r in results[name] if not math.isnan(r['auc'])])\n",
    "        summary['cv'][name] = {\n",
    "            'mean_acc': float(np.nanmean(arr_acc)),\n",
    "            'std_acc': float(np.nanstd(arr_acc)),\n",
    "            'mean_rec': float(np.nanmean(arr_rec)),\n",
    "            'std_rec': float(np.nanstd(arr_rec)),\n",
    "            'mean_auc': float(np.nanmean(arr_auc)) if arr_auc.size>0 else None,\n",
    "            'std_auc': float(np.nanstd(arr_auc)) if arr_auc.size>0 else None,\n",
    "            'per_fold': results[name]\n",
    "        }\n",
    "\n",
    "    # refit final models on full dataset and save\n",
    "    final_models = {}\n",
    "    for name, model in best_models.items():\n",
    "        try:\n",
    "            model.fit(X, y)\n",
    "            final_models[name] = model\n",
    "            with open(os.path.join(args.outdir, f\"final_model_{name}.pkl\"), \"wb\") as f:\n",
    "                pickle.dump(model, f)\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] could not refit/save {name}: {e}\")\n",
    "\n",
    "    # group-wise permutation test on RF (if present)\n",
    "    if 'rf' in final_models:\n",
    "        print(\"[INFO] Running group-wise permutation test for RF...\")\n",
    "        try:\n",
    "            # use a held-out split for permutation: create a GroupShuffleSplit held-out split\n",
    "            gss = GroupShuffleSplit(n_splits=1, test_size=args.perm_test_holdout_fraction, random_state=args.random_state)\n",
    "            train_idx_perm, test_idx_perm = next(gss.split(X, y, groups_arr))\n",
    "            Xtr_perm, Xte_perm = X[train_idx_perm], X[test_idx_perm]\n",
    "            ytr_perm, yte_perm = y[train_idx_perm], y[test_idx_perm]\n",
    "            gtr_perm, gte_perm = groups_arr[train_idx_perm], groups_arr[test_idx_perm]\n",
    "            real_auc, perm_scores, pvalue = group_permutation_test(final_models['rf'], Xtr_perm, ytr_perm, gtr_perm, Xte_perm, yte_perm, n_permutations=args.n_permutations, random_state=args.random_state)\n",
    "            summary['perm_test'] = {'real_auc': float(real_auc), 'pvalue': float(pvalue), 'n_permutations': int(args.n_permutations)}\n",
    "            summary['perm_scores_sample'] = perm_scores[:min(200, len(perm_scores))].tolist()\n",
    "            print(f\"[INFO] Permutation p-value (RF): {pvalue:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(\"[WARN] permutation test failed:\", e)\n",
    "    else:\n",
    "        print(\"[WARN] RF not available to run permutation test.\")\n",
    "\n",
    "    # save report.json\n",
    "    with open(os.path.join(args.outdir, \"report.json\"), \"w\") as f:\n",
    "        json.dump(summary, f, indent=2, default=convert)\n",
    "    print(\"[INFO] saved report.json\")\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"[DONE] elapsed seconds: {elapsed:.1f}\")\n",
    "    print(json.dumps(summary, indent=2, default=convert))\n",
    "    \n",
    "class Args:\n",
    "    images = \"all-mias\"\n",
    "    meta = \"data2.txt\"\n",
    "    outdir = \"results_method2\"\n",
    "    image_size = 1024\n",
    "    target_size = 64\n",
    "    min_side = 32\n",
    "    select_k = 25\n",
    "    rf_estimators = 100\n",
    "    n_jobs = -1\n",
    "    random_state = 42\n",
    "    perm_test_holdout_fraction = 0.3\n",
    "    n_permutations = 200\n",
    "    P = 8\n",
    "    lbp_radii = [1, 3]\n",
    "    lbp_bins = 59\n",
    "    glcm_distances = [1]\n",
    "    glcm_levels = 32\n",
    "\n",
    "args = Args()\n",
    "main(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f1e4a2d0-1961-4221-8512-af8b99b028f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['REFNUM', 'BG', 'CLASS', 'SEVERITY', 'X', 'Y', 'RADIUS', 'CANCER'], dtype='object')\n",
      "   REFNUM BG CLASS SEVERITY    X    Y  RADIUS  CANCER\n",
      "0  mdb001  G  CIRC        B  535  425   197.0       1\n",
      "1  mdb002  G  CIRC        B  522  280    69.0       1\n",
      "2  mdb003  D  NORM      NaN  NaN  NaN     NaN       0\n",
      "3  mdb004  D  NORM      NaN  NaN  NaN     NaN       0\n",
      "4  mdb005  F  CIRC        B  500  145    65.0       1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aa23147\\AppData\\Local\\Temp\\ipykernel_17120\\619499473.py:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  meta = pd.read_csv(meta_path, delim_whitespace=True, dtype=str)\n"
     ]
    }
   ],
   "source": [
    "def read_metadata(meta_path):\n",
    "    meta = pd.read_csv(meta_path, delim_whitespace=True, dtype=str)\n",
    "    meta.columns = [c.strip().upper() for c in meta.columns]\n",
    "    \n",
    "    # Now you should have proper columns like 'CLASS' or 'SEVERITY'\n",
    "    if 'SEVERITY' in meta.columns:\n",
    "        meta['CANCER'] = meta['SEVERITY'].map({'B': 1, 'M': 1}).fillna(0).astype(int)\n",
    "    elif 'CLASS' in meta.columns:\n",
    "        meta['CANCER'] = meta['CLASS'].map({'B': 1, 'M': 1}).fillna(0).astype(int)\n",
    "    else:\n",
    "        raise ValueError(\"Missing CLASS or SEVERITY column for cancer label.\")\n",
    "\n",
    "    meta['RADIUS'] = pd.to_numeric(meta['RADIUS'], errors='coerce')\n",
    "    return meta\n",
    "df = read_metadata(\"data2.txt\")\n",
    "print(df.columns)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35f7ff84-6354-488b-8dc1-88ba268e9905",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded and processed 324 images.\n",
      "Label distribution: Counter({np.int64(0): 207, np.int64(1): 117})\n",
      "\n",
      "--- Model Evaluation on Held-Out Test Set ---\n",
      "Accuracy: 0.9268\n",
      "ROC AUC Score: 0.9630\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94        51\n",
      "           1       0.96      0.84      0.90        31\n",
      "\n",
      "    accuracy                           0.93        82\n",
      "   macro avg       0.94      0.91      0.92        82\n",
      "weighted avg       0.93      0.93      0.93        82\n",
      "\n",
      "Confusion Matrix:\n",
      " [[50  1]\n",
      " [ 5 26]]\n",
      "\n",
      "--- Running Permutation Test (100 permutations) ---\n",
      "Permutation 1/100, Score: 0.4970\\rPermutation 2/100, Score: 0.4428\\rPermutation 3/100, Score: 0.5666\\rPermutation 4/100, Score: 0.4841\\rPermutation 5/100, Score: 0.5062\\rPermutation 6/100, Score: 0.4456\\rPermutation 7/100, Score: 0.4689\\rPermutation 8/100, Score: 0.4358\\rPermutation 9/100, Score: 0.4901\\rPermutation 10/100, Score: 0.5459\\rPermutation 11/100, Score: 0.4777\\rPermutation 12/100, Score: 0.5673\\rPermutation 13/100, Score: 0.4659\\rPermutation 14/100, Score: 0.4583\\rPermutation 15/100, Score: 0.5552\\rPermutation 16/100, Score: 0.5414\\rPermutation 17/100, Score: 0.5131\\rPermutation 18/100, Score: 0.6016\\rPermutation 19/100, Score: 0.5131\\rPermutation 20/100, Score: 0.5388\\rPermutation 21/100, Score: 0.4356\\rPermutation 22/100, Score: 0.5074\\rPermutation 23/100, Score: 0.5229\\rPermutation 24/100, Score: 0.5302\\rPermutation 25/100, Score: 0.5275\\rPermutation 26/100, Score: 0.4368\\rPermutation 27/100, Score: 0.4323\\rPermutation 28/100, Score: 0.5608\\rPermutation 29/100, Score: 0.5204\\rPermutation 30/100, Score: 0.5234\\rPermutation 31/100, Score: 0.5464\\rPermutation 32/100, Score: 0.5809\\rPermutation 33/100, Score: 0.5036\\rPermutation 34/100, Score: 0.4937\\rPermutation 35/100, Score: 0.4843\\rPermutation 36/100, Score: 0.5584\\rPermutation 37/100, Score: 0.5562\\rPermutation 38/100, Score: 0.5127\\rPermutation 39/100, Score: 0.4302\\rPermutation 40/100, Score: 0.4756\\rPermutation 41/100, Score: 0.4583\\rPermutation 42/100, Score: 0.5147\\rPermutation 43/100, Score: 0.4943\\rPermutation 44/100, Score: 0.5230\\rPermutation 45/100, Score: 0.4712\\rPermutation 46/100, Score: 0.4591\\rPermutation 47/100, Score: 0.5324\\rPermutation 48/100, Score: 0.5197\\rPermutation 49/100, Score: 0.4930\\rPermutation 50/100, Score: 0.5801\\rPermutation 51/100, Score: 0.5046\\rPermutation 52/100, Score: 0.5795\\rPermutation 53/100, Score: 0.5950\\rPermutation 54/100, Score: 0.5007\\rPermutation 55/100, Score: 0.4816\\rPermutation 56/100, Score: 0.4942\\rPermutation 57/100, Score: 0.5035\\rPermutation 58/100, Score: 0.4256\\rPermutation 59/100, Score: 0.6022\\rPermutation 60/100, Score: 0.4247\\rPermutation 61/100, Score: 0.5202\\rPermutation 62/100, Score: 0.6000\\rPermutation 63/100, Score: 0.5401\\rPermutation 64/100, Score: 0.5136\\rPermutation 65/100, Score: 0.5947\\rPermutation 66/100, Score: 0.5343\\rPermutation 67/100, Score: 0.5256\\rPermutation 68/100, Score: 0.4665\\rPermutation 69/100, Score: 0.5686\\rPermutation 70/100, Score: 0.4378\\rPermutation 71/100, Score: 0.5224\\rPermutation 72/100, Score: 0.4923\\rPermutation 73/100, Score: 0.5350\\rPermutation 74/100, Score: 0.5006\\rPermutation 75/100, Score: 0.5080\\rPermutation 76/100, Score: 0.5152\\rPermutation 77/100, Score: 0.5058\\rPermutation 78/100, Score: 0.4885\\rPermutation 79/100, Score: 0.4922\\rPermutation 80/100, Score: 0.4606\\rPermutation 81/100, Score: 0.5386\\rPermutation 82/100, Score: 0.4718\\rPermutation 83/100, Score: 0.4623\\rPermutation 84/100, Score: 0.5842\\rPermutation 85/100, Score: 0.4675\\rPermutation 86/100, Score: 0.5031\\rPermutation 87/100, Score: 0.5173\\rPermutation 88/100, Score: 0.5946\\rPermutation 89/100, Score: 0.4889\\rPermutation 90/100, Score: 0.4968\\rPermutation 91/100, Score: 0.4815\\rPermutation 92/100, Score: 0.4776\\rPermutation 93/100, Score: 0.4661\\rPermutation 94/100, Score: 0.5516\\rPermutation 95/100, Score: 0.4445\\rPermutation 96/100, Score: 0.4783\\rPermutation 97/100, Score: 0.4753\\rPermutation 98/100, Score: 0.4900\\rPermutation 99/100, Score: 0.4231\\rPermutation 100/100, Score: 0.4928\\r\\nReal Model ROC AUC: 0.9630\n",
      "Permutation Scores Mean: 0.5064\n",
      "P-value: 0.0000\n",
      "Result is statistically significant.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAq4AAAHWCAYAAAC2Zgs3AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAU3hJREFUeJzt3QmcTfX/x/HPDGOMZWxjHWMp2UuZ0qJNm6Ii7ShJURRSlDaJUolosaRQv5TS8stfi6RUQhhRZMmSZWxDtsHMYM7/8fly5nfvzJ39LufMvJ6Px2269557zvee73XnPd/zOd8TZlmWJQAAAIDDhYe6AQAAAEBeEFwBAADgCgRXAAAAuALBFQAAAK5AcAUAAIArEFwBAADgCgRXAAAAuALBFQAAAK5AcAUAAIArEFwBwI/++ecfCQsLk6lTp4a6Kcgj+gxwD4IrgBzpL3P9pW7fSpcuLQ0bNpSHHnpIdu3aJW70119/yXPPPWcCS0F9+OGHMmbMGHGCefPmefVRTrdQ7D9d1rMNERERUq9ePenbt6/s379fnOjrr7827QbgLCVD3QAA7vD8889L/fr1JSUlRebPny/jx483v9xXrlwpZcqUETfR4DV06FC5/PLLTYAqaHDV996/f3+vx+vWrStHjx414SxYmjRpIv/5z3+8Hhs8eLCUK1dOnnrqKcfsP/3MaJsOHz4sc+fOlTfeeEOWLVtmPk9Oo5/tt956i/AKOAzBFUCeXHfddXLuueea/7/vvvukSpUqMnr0aPnyyy/lzjvvLNS6jxw54rrwmx17VDqYqlevLl27dvV67KWXXpKYmJgsj4fSLbfcYtqkevXqJXfccYd8/PHHsnjxYmnVqlWomwfABSgVAFAgV1xxhfm5adOmjMc++OADiY+Pl6ioKKlcubIJJlu3bvV6nY7SNW/eXBISEuTSSy81gfXJJ5/MqDN89dVXzUjXaaedZp675pprzDosy5Jhw4ZJ7dq1zfo7dOgg//77r9e69fW+Rsh0VPCee+7JKH249dZbzf+3adMm4/C1Hm5XGsTbt28vtWrVksjISDn99NPNdk+cOOH1Hr766ivZvHlzxuvtkcfs6iV/+OEHueSSS6Rs2bJSsWJF0/7Vq1f7PKS+fv16015drkKFCtK9e3cT7gtLD8vrCHFcXJx5bw0aNJCXX35Z0tPTvZabPn266cfy5ctLdHS0nHnmmTJ27Ng87b/80P2hNmzY4PX4b7/9Jtdee6157/oZuOyyy+TXX3/1WubQoUPmveh+1/dSrVo1ufrqq80Irq9+96T9p7fs6Gv0M6h8lVnktH8ABBYjrgAKxA4bOvKqXnjhBXnmmWfktttuMyOySUlJ5lCwhtPff//dhDDb3r17zQiuBlsdEdQRQ9u0adMkLS1NHn74YRNMX3nlFbNODcoajh5//HET7HTdjz32mEyePDlf7db2aG3l66+/bgKzHmZX9k8NZno4e8CAAeanBs5nn31WDh48KCNHjjTL6OH3AwcOyLZt2+S1114zj+my2fn+++/N+9UwruFUSwm0/a1btzZBK/Phdn2/WpYxYsQI8/w777xjgpmGzILS4KsBMDEx0Yx21qlTRxYsWGBKCnbs2JFRrztnzhwzgn7llVdmbE8DtgbHfv365br/8sOuka1UqVLGY7q/dV9pMBwyZIiEh4fLlClTTP//8ssvGSOzDzzwgHz66aem1rpp06bmM6UlB9rWli1bSmHo/tm+fbvZF5lLMHLbPwACzAKAHEyZMsXSr4rvv//eSkpKsrZu3WpNnz7dqlKlihUVFWVt27bN+ueff6wSJUpYL7zwgtdr//zzT6tkyZJej1922WVmfRMmTPBadtOmTebxqlWrWvv37894fPDgwebxFi1aWMeOHct4/M4777RKlSplpaSkZDymyw0ZMiTLe6hbt67VrVu3jPszZswwy/74449Zlj1y5EiWx3r16mWVKVPGa1vt27c3683Mfh+632xnn322Va1aNWvv3r0Zj61YscIKDw+37r777ozHtO362nvvvddrnTfddJPZ3/nRrFkzs69tw4YNs8qWLWutW7fOa7knnnjC9N2WLVvM/X79+lnR0dHW8ePHs113TvvPF/t9rV271nyG9PMyefJk8/nR/j58+LBZLj093TrjjDOstm3bmv/37JP69etbV199dcZjFSpUsPr06ZPjdjP3u033i+e+8dVnum5fvyLzsn8ABA6lAgDy5KqrrpKqVauaw8w6UqojjF988YXExsbK559/bg4360jhnj17Mm41atSQM844Q3788UevdemhXT387YsehtZDxLbzzz/f/NSR2ZIlS3o9riOzOoLoT1qG4Hk4Wt+HHtLWEcs1a9bke306mrl8+XJz+FnLJ2xnnXWWObStJwFlpqOJnnT7OqKoo74FNWPGDLMeHd307CPtVy2D+Pnnn81yOjKuJ0/pyKK/NWrUyHyGdIT53nvvNaUK33zzTUZ9s+6nv//+Wzp37mzer91GbY+OcGob7bIGbaeWFOjIaDAFcv8AyB2lAgDyRGv+dBosDY96aF9DiB7GVRo2dMBTQ6ovmc+w17BbqlQpn8vqIWxPdojVwOzr8X379ok/rVq1Sp5++mlzyDpzUNTygPzSOlil+yszPbw+e/ZsE4S09jW7fWAfStf3qjWVBaF99Mcff5jg6Mvu3bvNz969e8snn3xiDtdrP2mNsf5BojWnhfXZZ5+Z9msZiZYaaH205x8K2kbVrVu3bNehfaD7Q0tIdDn9XGhZQbt27eTuu+825RiBFMj9AyB3BFcAeaK1hfasApnpKJievKKjZyVKlMjyfOb6T8+wkpmv1+f0+MkKgZx5nliV28lLWgeq4Uqn/9ITs3SGAK0z1drazCcxBUph3mt2tO06wjto0CCfz+sfJUpraXXkUwO19qfetMZUQ+F7770nhaH1sfasAjfccIM5qalLly7mRD39I8jev1pLfPbZZ/tch/1Z0rCoI8g66v/dd9+Z12jNqY7+a6hU2c1bq5+H7PZxbgK5fwDkjuAKoNA04Gmo0hOK7AAUCjoSl3lCey0n0MP1nrILNHrylx6i1vCjIcvmOXNCbuvITOd1VWvXrs3ynJYeaJDzHG0NZB8lJyeb0oDc6Gi4Bku9aZjUUcaJEyeak+/08L4/LmSgAVRPvtKSER3B1PITbaPSPxzy0s6aNWuatulNR4z1pCw9SdAOrr4+D/YoeG4jszm9x9z2D4DAocYVQKF16tTJjGDppPSZRwX1vobBYNDgY9dq2t5+++0sI652UMwcauxROM/3oMF33LhxWbal68hL6YCGKx091NE4z+3pxQt0pFAPcQeDjlAuXLjQjBRmpu06fvy4+f/MfaUjoVqPq1JTU3Pcf/mlo606vZl9dr4e8tc+1CnRNGRnpiUGSvsz877XkVCdwsxuo9J1LVq0yPShbdasWVmmaPMlu/eYl/0DIHAYcQVQaBoQhg8fbqZW0imOOnbsaOa41JFKPZTbs2dPM3VVoOk0XHpi080332wOi69YscIENfvwtE2DpIZUDUwagPRkMZ1u6aKLLjKjdFo7qVM+6aibTofk6xC9hiydPF+nzTrvvPPMCKKOwPmih7F1FPDCCy+UHj16ZEyHpXW6wboy08CBA2XmzJly/fXXmxPFtP1aW/vnn3+aaaW033Q/6T7Uach0f2io1NFJbavuM3vKq+z2n4bH/NDaZ51CStv27bffmjpRnfpL91WzZs3MaKzWkeoJeHqCn47E/t///Z85aU7bphc0aNGihdn3OuXYkiVLZNSoURnr1/ei703Xq8Fdp3DTuYbtkd2c6P5R+jlo27ateb86KpyX/QMggAI4YwGAIjQd1pIlS3Jd9rPPPrMuvvhiM+2S3ho3bmymFdJpkGw6DZFO1ZSZPSXRyJEjvR7XKZf0cZ2CKbd2nThxwnr88cetmJgYM32VTqu0fv16n9MiTZo0yTrttNPMVFCeUzv9+uuv1gUXXGCmaqpVq5Y1aNAga/bs2Vmmf0pOTrY6d+5sVaxY0TxnT43la2olpdOJtW7d2qxXp1O64YYbrL/++svntFE6ZZSv96rrLuh0WOrQoUNmerEGDRqYqcR0P1100UXWq6++aqWlpZllPv30U+uaa64x03fpMnXq1DHTge3YsSNP+8+X7N6XOnDggJnayrOtv//+u9WpUyczBVhkZKTZt7fddps1d+5c83xqaqo1cOBAM0Va+fLlzWdN/3/cuHFZ1j9q1CgrNjbWrEf3/9KlS/M0HZZOd/Xwww+b6brCwsIypsbK6/4BEBhh+p9ABmMAAADAH6hxBQAAgCsQXAEAAOAKBFcAAAC4AsEVAAAArkBwBQAAgCsQXAEAAOAKRf4CBHo5vu3bt5vJ0P1xmUIAAAD4l87OqhcX0Svg6RXpim1w1dAaFxcX6mYAAAAgF3pJZr0qXbENrjrSau8IvVygjsDq9a6rVq2aY6JHaNA/zkcfORv943z0kbPRP6c0biyyY4dIzZoia9ZIoB08eNAMNNq5rdgGV7s8QEOrHVxTUlLM/xfrD6RD0T/ORx85G/3jfPSRs9E/p7RpI7Jnj0hMjIYoCZbcyjqLfHAFAABAPk2bJk5UjP+UAAAAgJsQXAEAAOAKlAoAyHF6kuPHj8uJEye86r+OHTtmasCKdf2XQ9E/oRURESElSpQIdTOAIovgCsCntLQ02bFjhxw5ciRLmNVwpPPtMTey89A/oaX7XKfyKVeuXKibAhTOFVeI7NolUr26yA8/iFMQXAFkocFn06ZNZuRIJ4MuVapURgiyR2FLlixJMHIg+ie0+16nUdq2bZucccYZjLzC3datE0lMFDlwQJyE4ArA52irhledU69MmTJezxGMnI3+CS2d+/Off/4x5RoEV8D/KIACkC1qJIH84Y8FILD4rQQAAABXILgCAADAFahxBZAvW7ZskV27dpn6vWAcFo2JiZE6deoEfDtFqbxjxowZcvPNN4e6KQDgdwRXAPkKrY2bNJWUo95TZAVS6agysnbN6jyH13vuuUfee++9jDk19XV33323PPnkk+aEJafR9u7fv1/++9//5ut1zz33nHnN8uXLvR7fvn27lC9fXgJJ5/UdOXKkTJ06VTZv3ixRUVHmLPr7779f7rvvvoBuG0Dx5rxvcQCOtWfPHhNaq1z/qERUiQv49o7t3Sp7Z40y283PqOu1114rU6ZMkdTUVPn666+lT58+JsQOHjy4QCFNR5bdcqJajRo1zKwCgTR06FCZOHGivPnmm3LuuefKwYMHZenSpbJv376AznSh07IBKN7c8U0MwFE0tEbWaBDwW0HDcWRkpAlwdevWlQcffFCuuuoqmTlzpnlOw+xjjz0msbGxUrZsWTn//PNl3rx5Ga/VUcSKFSua5Zs2bWrWpSPN9erVk+HDh5vRW51cXtety+i8nR06dDCPnXXWWSbAeY6Knn322V5tGzNmjFmX/byODn/55ZcmHOvNbsvjjz8uDRs2NNORnXbaafLMM8+YKZbsNmp4XLFiRcbr9DGlAVvXZ/vzzz/liiuuMKOiVapUkZ49e0pycrLXiG/Hjh3l1VdflZo1a5plNOjb2/JF33fv3r3l1ltvlfr160uLFi2kR48eZr/adDq1V155RRo0aGD2of7h8cILL+S7XfoanUu4UaNG5vGtW7fKbbfdZvqocuXKZt/r9FM23X+tWrUyfavLtG7d2owKAygaGHFFwOgvex0pywn1iwgGDUd79+41///QQw/JX3/9JdOnTzeB6IsvvjAjtBqk9HC30quFvfzyy/LOO++YUFWtWjXz+GuvvSYvvviiCZH6/3fddZdcdNFFcu+995pD5xo2NdiuWrUqT/W/GvRWr15tRix1hFhpGFN6uF/DqLZR26aH4fWxQYMGye233y4rV66Ub7/9Vr7//nuzfIUKFbKs//Dhw9K2bVu58MILZcmSJbJ7925zKF/3gR101Y8//mhCq/5cv369Wb8Gbt2mL/pHwQ8//GDCq85b6ouObk+aNMnsp4svvthchW3NmjX5atfcuXMlOjpa5syZY+5rmLZf98svv5jSD/1jQvvvjz/+MKFdw662+6OPPjKjtIsXL2aKKqAgnn1WRP+YdNhV4AiuCFhobdS4Sa61kPmtXwTyOxm/hp/Zs2fLww8/bD6XGhD1pwZCOzxqANTHNZTaAWncuHFmJNFTu3btpFevXub/n332WRk/frycd955ZuRRaXDVUKUnr2m4y42O0mqo1lHgzMs//fTTGf+vI7TaTg3bGlz1NfpaDW45befDDz+UlJQUef/9980IpNLD+zfccIMJ5tX1Uo4iUqlSJfO4nnDXuHFjad++vdlv2QXX0aNHyy233GK23axZMxPedeTzuuuuM8/r5WbHjh1r1tmtWzfz2Omnn24CbH7apc/pHw92icAHH3xgRnL1MTuMar/pyKqOtGrZwoEDB+T6668321NNmjTJtR8A+NCzpzgRwRUhq4UsaP0ikJtZs2aZYKcBVINO586dzWF5DTdas6qH4D1pcNSRVZsGJT3sn5nnY3a4OvPMM7M8piOIeQmuOfn444/l9ddflw0bNphD6Fq3qqOP+aGjuRq+7XCo9NC57pO1a9dmtFfDp+dVnnT0VUd5s6MlFDrim5CQIL/++qv8/PPPJnTq4X0Nlbpd3adXXnllodql+9azrlVLI3REOPPJZxqCdT9dc801pg06Knv11VebEhEtK9D3A6BoILgiKLWQQDC1adPGjIZq6NGRVXs2AQ2AGtA0cGW+HKcGXZuOaPo6vKwneNns5309pgFM6aFrHfX1lFPtqG3hwoXSpUsXU8eqIUzLAHS0ddSoURIInu/Bfh/2e8iOvjcdbdZb//79zWiolk489dRTZv/5g2ewtfsvPj5epk2blmVZu2RBR2D79u1rRtE1/OvItZYaXHDBBX5pE4DQIrgCKHI08OhJQZmdc845ZsRVR0QvueSSgLdDw9TOnTtNeLVDbebpqzRca5s8LViwwJz8pSHQlvkEI1+vy0wPk2vNqNaU2iFQR0g1dNonO/mLjsIq3ZbWCmt41XIDX9NjFbRdLVu2NGFUa45zGn3Wftab1tlq6YaWJhBcgXzasUOnVRHRP/IddNSC4Aog37TMw43b0RIBHcnUE6h09FLDjc4KoAFLywC0ttOfLr/8crN+Pbtea0J1FPCbb77xCl1av6o1uHqIXMsVdHRVg5/W4eooq45ofvXVV+YkMk/6uk2bNpkgXLt2bXP4XM/e96TvdciQIabOVEsltC1a66sjo/bh+ILQ96KH9rW2VUsitB0aEnX/ao2sjnBrva/W42rA1mV123rSms4+UNB26ev0JDitp33++efN+9ZA//nnn5tt6Wj222+/LTfeeKMZadd9+vfff5v+BpBP550nkpgoEhsrsm2bOAXBFUCe6SwQekKd1iYHi25Pt+sveihZz0R/9NFHJTEx0axbR+P0hB5/05FFPclLT/oaNmyYuZqVnmSl4cqmJ0DZJxbpoXA9s1+D1yOPPGLOstdaUQ3UOpOBhjybrksDm5ZF6AUM9H1pfacnnUpLQ3G/fv1MANb7+jo9uaowtHxBz9ofMWKEORlKw6tObaXts8sytL36/3oSm14UQetMH3jggUK1S5fTeloNxZ06dTIngem0ZlpLq38MHD161MxcoFOM6SwSuk2d2ss+oQ6A+4VZmQuwihidZkZHMPTLVb/YtG5LDxPqoSa3TCjuRsuWLTO1aDW6jcm2xjV153rZ+V5/U2+ohwAV/eMMerKLjqLpHJ2lS5f2ek5HuLjkq3PpV7qeyKWhkWmgnPVvx8b3nLPRP6fUrh3UEdfMeS07jLgCyBcNkfYJTwQjAEAwFeM/JQAAAOAmBFcAAAC4AsEVAAAArkBwBQAAgCsQXAEAAOAKBFcAAAC4AtNhAQAAwNvcuSLHj4ucuqiIUzirNQAAAAi9Ro3EiSgVAIAC0MurduzYUYqSd999V6655ppQN8Ox0tLSpF69erJ06dJQNwUotgiuAIpcoNQreuktIiLCXHpz0KBB5lKcwTZp0iRp0aKFlCtXTipWrCjnnHOOjBgxQpxI988zzzwjQ4YMCeh2/v33X+nSpYu5pKPukx49ekhycnKubevTp49UqVLF7Mubb77ZXHbY05YtW6R9+/ZSpkwZc6nOgQMHmkvfepo3b565vHRkZKQ0aNBApk6dmmVbb731lgmnernW888/XxYvXpzxXKlSpeSxxx6Txx9/vND7AUDBEFwBFDnXXnut7NixQzZu3CivvfaaTJw4MeCBLLPJkydL//79pW/fvrJ8+XL59ddfTYDOLaQVdkSwoD799FMTJlu3bi2BpKF11apVMmfOHJk1a5b8/PPP0rNnzxxf88gjj8j//d//yYwZM+Snn36S7du3S6dOnTKeP3HihAmt+v4XLFgg7733ngmlzz77bMYymzZtMsu0adPG9If2zX333SezZ8/OWObjjz+WAQMGmM/KsmXLzB8dbdu2Ndet92z//PnzzXsAirQPPxR5552TP53EKuIOHDhg6dvUn+rEiRPWjh07zE8ETkJCgtnvNbqNseo+PsvnTZ/TZXRZG/3jDEePHrX++usv8zOz9PR0Ky0tzfx0om7dulkdOnTweqxTp07WOeeck3FfP18vvviiVa9ePat06dLWWWedZc2YMSPj+ePHj1v33ntvxvMNGza0xowZk+t2POlz99xzT67tfffdd62mTZtapUqVsmrUqGH16dMn47nNmzdbN954o1W2bFmrfPny1q233mrt3Lkz4/khQ4ZYLVq0sCZNmmTaGhYWZvpl9+7dpv0xMTHmdW3atLGWL1+eYzvat29vPfbYYz7f43PPPZexrl69elmpqalWQehnSv/NL1myJOOxb775xrQ7MTHR52v2799vRUREePXP6tWrzXoWLlxo7n/99ddWeHi4174ZP368FR0dndHWQYMGWc2aNfNa9+233261bds2436rVq289r9+TmrVqmWNGDHC63W6P59++ul8/9vxXC/fc85F/5wSG2tZGhP1ZwjyWnYYcQWQP6NHS8n69UXi4kRq187+duONWV+rj+X0Gvs2erTfmrty5UozCqeHeW16uP7999+XCRMmmJEzHdHr2rWrGc1T6enpUrt2bTPC99dff5mRuyeffFI++eSTPG+3Ro0asmjRItm8eXO2y4wfP94cAtcRxz///FNmzpxpDmHbbejQoYM5tK7t0hFKHUG+/fbbvdaxfv16+eyzz+Tzzz83I4nqzjvvlKSkJPnmm28kISHBHB6/8sorzbqyo6OI5557bpbH586dK6tXrzaH2T/66COznaFDh2Y8/+KLL5rD9znd9DC+WrhwoSkP8NzOVVddJeHh4fLbb7/5bJe2/9ixY2Y5W+PGjaVOnTpmffZ6zzzzTKlevXrGMjpSevDgwYyRUV3Gcx32MvY6dLRWt+W5jLZL79vL2Fq1aiW//PJLtvsSQOAwqwCA/Dl4UMISE3NfToNtZklJInl57cGDUhh6CFoDk9Y4pqammgDy5ptvmuf0voat77//Xi688ELz2GmnnWaCm5YUXHbZZaY21jOcaZ2shhcNrrfddlue2qCHm/VwttZLNmzY0GyrXbt2csstt5j2qOHDh8ujjz4q/fr1y3jdeeedlxEYNczqIe64U/tSw3azZs1kyZIlGctp4NLHq1atau5roNLntQZU6zTVq6++Kv/9739NOYCvw/L79++XAwcOSK1atbI8p4Ffyx60dlS3/fzzz5v60WHDhpn38cADD+S6T+z17ty509SfeipZsqRUrlzZPOeLPq5t0MDrSUOq/Rr96Rla7eft53JaRsPt0aNHZd++fabkwNcya9asyfJ+cvqDBEDgEFwB5E90tFixseZ/w3Ja7lSQyvLYqdfmto3C0DpGHc08fPiwqXHVcKQn9NgjlEeOHJGrr77a6zUaAPXkKc+TdDSw6WihBht9/uyzz85zG2rWrGnCro74ah2njvp269ZN3nnnHfn2229lz549plZTR0J90VFODax2aFVNmzY1AU6fs4Nr3bp1M0KrWrFihamjjYmJ8VqfvocNGzb43JY+p+yg60nrPDW02jSA6/q3bt1qtq2hU2/FSVRUlPkMAQg+giuA/BkwQI737WvCoITlGF2zmjlTgqFs2bIZh9w1fGr40qmePM9g/+qrryQ2U4jWs83V9OnTzdnjo0aNMkGtfPnyMnLkyGwPZ+ekefPm5ta7d28zOnnJJZeYQ/++DssX9L160venofnHH380Myt4yjxqadOz9XVZHXXMLx291ltOtNxCD+1r+YTniU5KR8W1hEGf80Uf1z8adFTYs/06omy/Rn96nv1vP28/Z//MPBOB3tcT0jSIlihRwtx8LZO5bdpezz8WAAQPwRVAkaaHs7U+Vc8W79y5sxm11ICqI6laFuCLzgBw0UUXmbBpy260Mj9020pHgjUMaxmBlgToCHFmTZo0MaOaerNHXTUAaoCz1+OL1rPqYXH9w0JLHPJCD8XrOnX9medx1RFcHZHVcKe0blfLMOw25adUQP8I0PZrLWl8fLx57IcffjD1vDr1lC+6nJZu6H6yR83Xrl1r+s8u9dCfL7zwggnFdimC1gRrKLX3lS7z9ddfe61bl7HXoftAt6Xbsefn1Xbp/YceesjrdTqK7jk6DyB4ODkLQJF36623mtE0PfyvgVFHU/WELJ02SQOpTn30xhtvmPvqjDPOMJPM61RJ69atM/Obat1ofjz44IOmDlRDsNZDauC7++67zUidHZaee+45M6r7+uuvy99//53RDqUnBekJRzr9kj6uI4r6eg3bOY3W6usuuOACuemmm+S7776Tf/75x5QpPPXUUzlOnK8nKmmdb2Y62qkj1RpqNfhp7a4GObtOV8sEdHQ7p5sZnT8VxnWqsvvvv9+8H903uq477rgjI9wmJiaak6/sEdQKFSqY7esfHjqKrKG3e/fuZh/q+1QatjWg3nXXXSZoa789/fTT5sQ3exRdA7ae3KZTkmnN6rhx40zNsn4ObLoNnXtXPwdajqF9qH9k6PY8aR0xF2oAQoMRVwBFngYnDUivvPJKRqDUAKmzC2iY0UPQOlKpI7OqV69e8vvvv5sz+PUQup6lr6OvepZ+XmmA1DIFrbXdu3evqTnVsKUjeHpoXmnNq06ur3W4GqZ1GT15S+l2v/zyS3n44Yfl0ksvNUFRQ58dbLOjr9PZCTRgauDS2QX0ULeuI/OJR540HGog1pO0NCzatAZXg7y+Xk9s032hgbugpk2bZvpC16vvSUdRNbjbdAYBHVH1rCHV/WMvq23QkK3B06Z/lOgJedq3uo+1fEL3rZ5IZtPRZy0P0aA6duxYM2uE1hvrumza37q/dBYJHbXWmmatR/bcb1q3rPvI7icAwRWmc2JJEaZnjOqXsH7R6GEjPfRjH06yRwzgfzpCpIfdanQbI5E1TtYaZpa6c73sfK9/xnQ9iv5xBg1Teja7/rLPfMKOfmVoXaKGwcw1lAi9wvSPjkzrv8XBgwdnXIVMD+3rjAT4X7jVmmn7j5z8/Nux8T3nbPTPKTo1oc4Co+cCbNsmwc5r2SnGPQIA8KQnoGn9KnzTsgkt3/AsLwCKrBo1TobWbE6cDBVKBQAAhp4spqUJ8E1P4NLaWaBYWJp9TXwohXTEVec2vOGGG0xRvh7Synw4Sg95aa2RTu2iZ7RqzZiewAAACLypU6dSJgDAUUIaXPVsTa0V0jN9fdETKbRoXy/LqPMnasG9FtJrDREAAACKl5CWClx33XXm5ouOto4ZM8YcltHrdSu9rKGe3akjADp9ii96xqnePIt97WJr+6br1p8IHN3HWtQeHqZ/Hfk+/888Fx7u1R+F6R+d71KvRpQTPWvb80pE8M2zH3ydv2k/VsTP7XQt+scZ/3ay+x7j95Cz0T+hkdf97dgaVz0rU6cj0fIAm55tppNU63Qk2QVXnd7G8xrjNp3iREdqdcfoGWt2sEJg6L7WWQUqVo+SiEq+f3kekyiJjY83y9pX0ylo/2j/PvBgbzmW9r8/WnyJKBUpE8aP46o3udB+0Ou261WYdPJ3T9o3+pxiVgHnoX9CS7/PdP/rVch0mi5f+D3kbPTPSdEDB0r4/v2SXrGiHBw5UgLt0KFD7g6uGlpV5nkH9b79nC86jYtOIu054qojbBpU7Omw9Mtc7xfnD2Sg6STiOs1VjWZdJDKbK9qn7joqOxMSzJQx9tVuCto/ur1FCxdIlfaPSEQV3yOqx/Zulb1fvWbODLa3h5zp/KPaD3qtes8QpHNtwrnon9DQ7y/9N6MXudC5c7P7w4HfQ85G/5wUppeNTkwUKzZWSgfhd2Z208e5JrgWlF4lxb5Siidz2PrUB1A/kJ734X+6j82hMkskPZvgap479QXh2RcF6R97eyUqx0lE9Qb52h5805MidV/paLYn+xCa7kNG9JyH/gkt3e96wnF2o602fg85G/3zP/otEhaE/ZDXfe3Y4Kp/rapdu3aZX6A2va9XMwEQ+C9u/beno9OeI3j2qJJe/Ykvdeehf0I/ZRb7HQgcxwZXveqIhle9PKIdVPWwv84uoJf1AxAcOnLkOXqkwUjrXvWwDr+gnYf+AVCUhTS46okf69ev9zoha/ny5VK5cmWpU6eO9O/fX4YPH26uk61B9plnnjGHYDp27BjKZgMAAKC4BdelS5dKmzZtMu7bJ1V169bNTHw9aNAgM9drz549zfWyL774Yvn222/zXMALAACAoiOkwfXyyy/PcZ5BrbF7/vnnzQ0AAADFGwVQAAAAcAWCKwAAAFzBsbMKAAAAIETuvFNk3z6RSpXESQiuAAAA8BaEy7wWBKUCAAAAcAWCKwAAAFyB4AoAAABXILgCAADAW+PGItHRJ386CMEVAAAA3pKTRQ4dOvnTQQiuAAAAcAWCKwAAAFyB4AoAAABXILgCAADAFQiuAAAAcAWCKwAAAFyB4AoAAABXILgCAADAFUqGugEAAABwmAkTRI4eFYmKEichuAIAAMDb9deLE1EqAAAAAFcguAIAAMAVKBUAAACAt4QEkbQ0kVKlROLjxSkIrgAAAPDWoYNIYqJIbKzItm3iFJQKAAAAwBUIrgAAAHAFgisAAABcgeAKAAAAVyC4AgAAwBUIrgAAAHAFgisAAABcgeAKAAAAVyC4AgAAwBW4chYAAAC8rV4tYlkiYWHiJARXAAAAeCtfXpyIUgEAAAC4AsEVAAAArkCpAAAAALyNHi1y8KBIdLTIgAHiFARXAAAAZA2uiYkisbGOCq6UCgAAAMAVCK4AAABwBYIrAAAAXIHgCgAAAFcguAIAAMAVCK4AAABwBYIrAAAAXIHgCgAAAFfgAgQAAADw1rKlSFycSNWq4iQEVwAAAHibOVOciFIBAAAAuALBFQAAAK5AcAUAAIArUOMKAAAAbzfeKJKUdPLkLAfVuxJcAQAA4G3ZMpHERJHYWHESSgUAAADgCgRXAAAAuIKjg+uJEyfkmWeekfr160tUVJScfvrpMmzYMLEsK9RNAwAAQJA5usb15ZdflvHjx8t7770nzZo1k6VLl0r37t2lQoUK0rdv31A3DwAAAEHk6OC6YMEC6dChg7Rv397cr1evnnz00UeyePHiUDcNAAAAQebo4HrRRRfJ22+/LevWrZOGDRvKihUrZP78+TJ69OhsX5OammputoMHD5qf6enpGTctNdCfCBzdx+Hh4RIepvUovks7zHPh4V79UdD+Kej2kH/8G3I2+sf56CNno39OCjt109+oVhD2RV73t6OD6xNPPGGCZ+PGjaVEiRKm5vWFF16QLl26ZPuaESNGyNChQ7M8npSUJCkpKWbHHDhwICPoIDB0X8fHx0vF6lESUcl3kDwmURIbH2+W3b17t3msoP1T0O0h//g35Gz0j/PRR85G/5xUNT1dSpzaH0lB+J156NAh9wfXTz75RKZNmyYffvihqXFdvny59O/fX2rVqiXdunXz+ZrBgwfLgAEDMu5r8I2Li5OqVatKdHS06YCwsDBzvzh/IAMtMTFREhISpEazLhJp/mbLKnXXUdmZkCClS5eWatWqmccK2j8F3R7yj39Dzkb/OB995Gz0z0lhp9677oNg/M7U382uD64DBw40o6533HGHuX/mmWfK5s2bzahqdsE1MjLS3DIzh5FPdYJ+ID3vw/90H5vSDEskPZsgaZ479QXh2RcF6Z/CbA/5x78hZ6N/nI8+cjb6R0R0EPDgQQmLjs4IsYGU133t6OB65MiRLG9ESwaKe90JAABAQHkcvXYSRwfXG264wdS01qlTx5QK/P777+bErHvvvTfUTQMAAECQOTq4vvHGG+YCBL179zYn02hta69eveTZZ58NddMAAAAQZI4OruXLl5cxY8aYGwAAAIJEz/LXK5WGhWkgE6coxlXHAAAA8KlJE5EKFU7+dBCCKwAAAFyB4AoAAABXILgCAADAFQiuAAAAcAWCKwAAAFyB4AoAAABXILgCAADAFQiuAAAAcAWCKwAAAFzB0Zd8BQAAQAh8+aVIWppIqVLiJARXAAAAeIuPFyeiVAAAAACuQHAFAACAK1AqAAAAAG+zZokcPSoSFSVy/fXiFARXAAAAeHvgAZHERJHYWJFt28QpKBUAAACAKxBcAQAA4AoEVwAAALgCwRUAAACuQHAFAACAKxBcAQAA4AoEVwAAALgCwRUAAACuQHAFAACAt3LlRMqXP/nTQbhyVjGxZcsW2bNnT67LxcTESJ06dQq9rtWrV+e5bZ7LWpYlKSkpkpiYKGFhYXluU37k1jZ/bw8AANdZs0aciOBaDGjQbNS4iaQcPZLrsqWjysjaNauzDW75WVduTiTvEwkLk65du2Y8Fh4eLvHx8ZKQkCDp6el5alNhtueLv7YHAAD8i+BaDOjoqAbNKtc/KhFV4rJd7tjerbJ31iizfHahLa/rOrpxqRz45YMc25WemqxDrF7rCg8TqVg9Smo06yLpVt7alFe+tpeZP7cHAAD8i+BajGhYi6zRICjr0gBYkHWFiyURlSyJlDBJl5OlAk7eDwAAIHgIrgAAAPA2cKDIvn0ilSqJjBwpTkFwBQAAgLePPhJJTBSJjXVUcGU6LAAAALgCwRUAAACuQHAFAACAKxBcAQAAUHSD68aNG/3fEgAAAMDfwbVBgwbSpk0b+eCDD8zlOQEAAABHBtdly5bJWWedJQMGDJAaNWpIr169ZPHixf5vHQAAAFCY4Hr22WfL2LFjZfv27TJ58mTZsWOHXHzxxdK8eXMZPXq0JCUlFWS1AAAAQGBOzipZsqR06tRJZsyYIS+//LKsX79eHnvsMYmLi5O7777bBFoAAAC4TPv2IrfccvJnUQmuS5culd69e0vNmjXNSKuG1g0bNsicOXPMaGyHDh3811IAAAAEx8SJIjNmnPzpIAW65KuG1ClTpsjatWulXbt28v7775uf4eEnc3D9+vVl6tSpUq9ePX+3FwAAAMVUgYLr+PHj5d5775V77rnHjLb6Uq1aNXn33XcL2z4AAACg4MH177//znWZUqVKSbdu3QqyegAAAMA/Na5aJqAnZGWmj7333nsFWSUAAACc4txzRWrXPvnT7cF1xIgREhMT47M84MUXX/RHuwAAABAqO3eKJCae/On24LplyxZzAlZmdevWNc8BAAAAjgiuOrL6xx9/ZHl8xYoVUqVKFX+0CwAAACh8cL3zzjulb9++8uOPP8qJEyfM7YcffpB+/frJHXfcUZBVAgAAAP6fVWDYsGHyzz//yJVXXmmunqXS09PN1bKocQUAAIBjgqtOdfXxxx+bAKvlAVFRUXLmmWeaGlcAAADAMcHV1rBhQ3MDAAAAHBlctaZVL+k6d+5c2b17tykT8KT1rgAAAEDIg6uehKXBtX379tK8eXMJCwvza6MAAAAAvwTX6dOnyyeffCLt2rUryMsBAADgZK+8InLkiEiZMlIkTs5q0KCB/1sDAACA0OvcWYrMPK6PPvqojB07VizLkkBLTEyUrl27mgsb2LMXLF26NODbBQAAgLh/xHX+/Pnm4gPffPONNGvWTCIiIrye//zzz/3SuH379knr1q2lTZs2ZltVq1aVv//+WypVquSX9QMAAKCIB9eKFSvKTTfdJIH28ssvS1xcnEyZMiXjsfr16wd8uwAAAMXa2rUix4+L6IWmGjUSVwdXzyAZSDNnzpS2bdvKrbfeKj/99JPExsZK79695f7778/2NampqeZmO3jwoPmpU3bZNy1xyDyFV1Gm7zc8PFzCw7Q2JPvyDvN8eHiO+ye/68ppOV/L6M8wsTJqWPLSpry2Kz9tKm6fEV+2bt0qe/bsyfK47puUlBTZtm2bOQqif1zCOYrjd5zb0EfORv+cFHbllRKWmChWbKxYW7ZIoOV1fxf4AgTHjx+XefPmyYYNG6Rz585Svnx52b59u0RHR0u5cuXEHzZu3Cjjx4+XAQMGyJNPPilLliyRvn37mpPDunXr5vM1I0aMkKFDh2Z5PCkpyfyy1R1z4MCBjKBTHOj7jo+Pl4rVoySiUvZh85hESWx8vFle5+ctzLpS4irLoVyW87WM9kjtciI6wVq6WHlqU17blZc25XV7RZ3+e3ngwd5yLO1/fwTadPo7PTlz/fr1UjKilEwYP84EWDhDcfyOcxv6yNnon5OqpqdLiVP7IykIvw8PHToUuOC6efNmufbaa2XLli1mdPPqq682wVUP7ev9CRMmiD/ozjr33HPlxRdfNPfPOeccWblypVl/dsF18ODBJuh6jrjqiJD+YtVQrevUX7x6v7h8IPUEt4SEBKnRrItEmkjoW+quo7IzIUFKly4t1apVK9S6krf+K3tzWc7XMjoSqpFyzT4NrmF5alNe25WXNuV1e0Wd7s9FCxdIlfaPSESVuCyj0hWrRcnm5JqSNOs1SUtLK9b7ymmK43ec29BHzkb/nBR26r3rPgjGd7z+3g3oBQg0UK5YscKc7W/TutecDuPnV82aNaVp06ZejzVp0kQ+++yzbF8TGRlpbpmZQ8SnOkE/kJ73izp9v6ZMwjoZBrNjnj/1Dza7fZPfdeW0XHbLaHDV++aWhzbltV35aVNu2yvq7P1ZonKcRFT3nvpO/7goWcmSEpWPsq8cqrh9x7kRfeRs9M//hHmE2EDK674uUHD95ZdfZMGCBeaQvad69eqZkRp/0RkF1mpxsId169ZJ3bp1/bYNAAAAuEOBIrSOspw4cSLL43qyhpYM+MsjjzwiixYtMqUCWk/34Ycfyttvvy19+vTx2zYAAABQhIPrNddcI2PGjPEaUk9OTpYhQ4b49TKw5513nnzxxRfy0UcfSfPmzWXYsGFmu126dPHbNgAAAOAOBSoVGDVqlJmmSutP9exrnVVALwwQExNjQqY/XX/99eYGAACA4q1AwbV27drmxKzp06fLH3/8YUZbe/ToYUZC9bKsAAAAgL8VeB7XkiVLSteuXf3bGgAAAMCfwfX999/P8fm77767IKsFAACAEyxZIqIn4pfQyxA4R4HncfV07NgxOXLkiJkeq0yZMgRXAAAAN6tZU4rMrAL79u3zummNq863evHFF/v95CwAAABA+e1SCGeccYa89NJLWUZjAQAAgJCenOVzZSVLyvbt2/25SgAAAATb22+LJCeLlCsn0rOnuDq4zpw50+u+ZVmyY8cOefPNN81lWgEAAOBizz8vkpgoEhvr/uDasWNHr/t65ayqVavKFVdcYS5OAAAAADgiuKanp/u9IQAAAEBQTs4CAAAAHDfiOmDAgDwvO3r06IJsAgAAACh8cP3999/NTS880KhRI/PYunXrpESJEtKyZUuv2lcAAAAgZMH1hhtukPLly8t7770nlSpVMo/phQi6d+8ul1xyiTz66KN+aRwAAABQqBpXnTlgxIgRGaFV6f8PHz6cWQUAAADgnOB68OBBSUpKyvK4Pnbo0CF/tAsAAAAofKnATTfdZMoCdHS1VatW5rHffvtNBg4cKJ06dSrIKgEAAOAUDRuKVKggUr26uD64TpgwQR577DHp3LmzOUHLrKhkSenRo4eMHDnS320EAABAMP3wgzhRgYJrmTJlZNy4cSakbtiwwTx2+umnS9myZf3dPgAAAKDwFyDYsWOHuZ1xxhkmtFqWVZjVAQAAAP4Nrnv37pUrr7xSGjZsKO3atTPhVWmpAFNhAQAAwDHB9ZFHHpGIiAjZsmWLKRuw3X777fLtt9/6s30AAAAIti5dRNq2PfnT7TWu3333ncyePVtq167t9biWDGzevNlfbQMAAEAo/PSTSGKiSGysuH7E9fDhw14jrbZ///1XIiMj/dEuAAAAoPDBVS/r+v7772fcDwsLk/T0dHnllVekTZs2BVklAAAA4P9SAQ2oenLW0qVLJS0tTQYNGiSrVq0yI66//vprQVZZ7Gh98J49e3JdLiYmRurUqSPBtHr16gI9F0i5bdff7crL+kLRNwAAFGcFCq7NmzeXdevWyZtvvinly5eX5ORkc8WsPn36SM2aNf3fyiIYWhs1biIpR4/kumzpqDKyds3qoASkE8n7dPhcunbtKk4R7DblZ3vB7BsAAFCA4KpXyrr22mvN1bOeeuqpwLSqiNORVg2tVa5/VCKqxGW73LG9W2XvrFFm+WCEo/TUZBHLyrFdRzculQO/fBDwtuSnTf5sV163F+y+AQAABQiuOg3WH3/8EZjWFDMajCJrNBA3tUsDmxP3lb/b5dS+AQCgOCvQyVl6GPXdd9/1f2sAAAAAf9a4Hj9+XCZPnizff/+9xMfHm8u9eho9enRBVgsAAAD4J7hu3LhR6tWrJytXrpSWLVuax/QkLU86NRYAAABc7P77RQ4cEKlQQVwbXPXKWDt27JAff/wx4xKvr7/+ulSvXj1Q7QMAAECwDRkirq9xtSzL6/4333xjrqIFAAAAOPLkrOyCLAAAAOCI4Kr1q5lrWKlpBQAAgONqXHWE9Z577pHIyEhzPyUlRR544IEsswp8/vnn/m0lAAAAgqd2bZHERJHYWJFt28SVwbVbt25e9510aVAAAAAUbfkKrlOmTAlcSwAAAIBAnZwFAAAABAvBFQAAAK5AcAUAAIArEFwBAADgCgRXAAAAuALBFQAAAK5AcAUAAEDRm8cVAAAAxcAHH4ikpoqculqqUxBcAQAA4O3yy8WJKBUAAACAKxBcAQAA4AqUCgAAAMDbvHn/q3F1UNkAwRUAAADeunYVSUwUiY0V2bZNnIJSAQAAALgCwRUAAACuQHAFAACAK7gquL700ksSFhYm/fv3D3VTAAAAEGSuCa5LliyRiRMnyllnnRXqpgAAACAEXBFck5OTpUuXLjJp0iSpVKlSqJsDAACAEHDFdFh9+vSR9u3by1VXXSXDhw/PcdnU1FRzsx08eND8TE9Pz7hZlmV+BsrWrVtlz5492T6/Zs0aCQ8Pl/Aw/cvBynY583x4eKHbq6/Pz/ZyWi4vyxRmXfozTKyMv6gCvb3Cvr/Vq1eb/ZudmJgYiYuLk2DJ7bOX1zbl9JnJ6CM/fT7hX8H4jkPh0EfORv+cFHbqpr8BrCDsi7zub8cH1+nTp8uyZctMqUBejBgxQoYOHZrl8aSkJElJSTE75sCBAxm/mP1Nt/PAg73lWNr/wrMv8fHxUrF6lERUyj70HJMoiY2PN+3evXt3gdukr8/L9lLiKsuhXJbLyzKFWZf2SO1yJ/+xpIsV8O0V9P2lppwwfTN27FjJSUSpSJkwfpxUrVpVAi2vn728tCmnz4zdR8erR0lNP3w+4V+B/o5D4dFHzkb/nFQ1PV1KnNofSUH4jj906JD7g6uOHvXr10/mzJkjpUuXztNrBg8eLAMGDPAacdXRJf0lHR0dbTpAT/DS+4H4QCYmJsqihQukSvtHJKKK71GtoxsT5MD8aVKjWReJNBHNt9RdR2VnQoJ579WqVStUmxISEnLdXvLWf2VvLsvlZZnCrEtH8zQmrdmnwTUs4Nsr8PvbuN0sl1M/H9u7VfZ+9ZqkpaUVqv/8+dnLa5ty+szYfbRq11HZ7ofPJ/wr0N9xKDz6yNnon5PCTr133QfB+I7Pa85zdHDVX5w6ktOyZcuMx06cOCE///yzvPnmm6YkoEQJ/XvgfyIjI80tM3PY81Qn6AfS874/6br1Q1+icpxEVG/gc5nUPVtPli1YJ8NZdszzp/4BFaatdpvyur2clsvLMoVdl4YivW9uQdheYd5fTv3sr/7z52cvr23K7TNjheD9Ie8C+R0H/6CPnI3+kYyrZdklA4GW133t6OB65ZVXyp9//un1WPfu3aVx48by+OOPZwmtAAAAKLocHVzLly8vzZs393qsbNmyUqVKlSyPAwAAoGgrxmPgAAAAcBNHj7j6Mm/evFA3AQAAoGgbOlTkwAGRChVEhgwRp3BdcAUAAECATZqkU8yIxMY6KrhSKgAAAABXILgCAADAFQiuAAAAcAWCKwAAAFyB4AoAAABXILgCAADAFQiuAAAAcAWCKwAAAFyBCxAAAADA22WXiezZIxITI05CcAUAAIC3adPEiSgVAAAAgCsQXAEAAOAKBFcAAAC4AsEVAAAA3q64QqRZs5M/HYSTswAAAOBt3TqRxESRAwfESRhxBQAAgCsQXAEAAOAKBFcAAAC4AsEVAAAArkBwBQAAgCsQXAEAAOAKBFcAAAC4AsEVAAAArsAFCAAAAODt2WdFkpNFypUTJyG4AgAAwFvPnuJEBFcXWL16dY7Px8TESJ06dYLWHoSm/7Zs2SJ79uwp8HYAAHA7gquDnUjeJxIWJl27ds1xudJRZWTtmtWE1yLcfxpaGzVuIilHjwSgpQAAuAPB1cHSU5NFLEuqXP+oRFSJ87nMsb1bZe+sUWYkjuBadPtPn9fQmtO6jm5cKgd++cBv7QcAFGM7doicOCFSooRIzZriFARXF9CgElmjQaibAQf0X07r0hAMAIBfnHeeSGKiSGysyLZt4hRMhwUAAABXILgCAADAFQiuAAAAcAWCKwAAAFyB4AoAAABXILgCAADAFQiuAAAAcAWCKwAAAFyB4AoAAABX4MpZAAAA8DZ3rsjx4yIlnRUVndUaAAAAhF6jRuJElAoAAADAFQiuAAAAcAVKBQAAAODtww9FjhwRKVNGpHNncQqCKwAAALwNGiSSmCgSG+uo4EqpAAAAAFyB4AoAAABXILgCAADAFQiuAAAAcAWCKwAAAFyB4AoAAABXILgCAADAFQiuAAAAcAUuQAAAAABvNWp4/3QIgisAAAC8LV0qTkSpAAAAAFzB0cF1xIgRct5550n58uWlWrVq0rFjR1m7dm2omwUAAIAQcHRw/emnn6RPnz6yaNEimTNnjhw7dkyuueYaOXz4cKibBgAAgCBzdI3rt99+63V/6tSpZuQ1ISFBLr300pC1CwAAoEjr1Uvk339FKlcWmThRnMLRwTWzAwcOmJ+VdSdmIzU11dxsBw8eND/T09MzbpZlmZ+BoOsODw+X8DAdzrZ8LmOey2WZvC5nL7N69WqzbV/WrFnj9+0Fal36M0ysjEMBgd5esN9fQfovr32Yn+3l9m8gp89xRh/lcV0IrkB/x6Hw6CNno39OCvvqKwlLTBQrNlasIOyLvO5v1wRXfUP9+/eX1q1bS/PmzXOsix06dGiWx5OSkiQlJcWsRwOw/YvZ33Qb8fHxUrF6lERU8h0eUuIqy6FclsnrcqkpJyQ2Pl7Gjh2bY7vi/bQ9f7bd1zLaI7XLiYRpn4sV8O0F+/0VtP+UPz5XxyTKbE8/p7t37y7Q59juo+PVo6RmHtaF4Ar0dxwKjz5yNvrnpKrp6VLi1P5ICsJ3/KFDh4pWcNVa15UrV8r8+fNzXG7w4MEyYMAArxHXuLg4qVq1qkRHR5sOCAsLM/cD8YFMTEw0pQw1mnWRSBO/skre+q/szWWZvC6XvHG7WaZK+0ckokqcz2WObkyQA/On+Wd7/my7j2V0NE9j0pp9GlzDAr69YL+/gvRfXvswL9tL3XVUdiYkSOnSpU3ZTUE+x3Yfrdp1VLbnYV0IrkB/x6Hw6CNno39OCjv13nUfBOM7Xn+XFJng+tBDD8msWbPk559/ltq1a+e4bGRkpLllZg57nuoE/UB63vcnXbcpSbBOBi9fzHO5LJPX5exlSlSOk4jqDXwuk7pnq9+3F8h1aSjS++YWhO0F+/3lt//y2of52Z79b6Cgn2MrH+tC8AXyOw7+QR85G/3zP2EeITaQ8rqvHR1cdZj+4Ycfli+++ELmzZsn9evXD3WTAAAAECIlnV4e8OGHH8qXX35p5nLduXOnebxChQoSFRUV6uYBAAAgiBw9Bj5+/HhTIH355ZdLzZo1M24ff/xxqJsGAACAIHP0iGtO0wMBAACgeHH0iCsAAADgihFXAAAAhMCdd4rs2ydSqZI4CcEVAAAA3kaOFCeiVAAAAACuQHAFAACAKxBcAQAA4AoEVwAAAHhr3FgkOvrkTwchuAIAAMBbcrLIoUMnfzoIwRUAAACuQHAFAACAKxBcAQAA4AoEVwAAALgCwRUAAACuQHAFAACAKxBcAQAA4AoEVwAAALhCyVA3AAAAAA4zYYLI0aMiUVHiJARXAAAAeLv+enEiSgUAAADgCgRXAAAAuAKlAgAAAPCWkCCSliZSqpRIfLw4BcEVAAAA3jp0EElMFImNFdm2TZyCUgEAAAC4AsEVAAAArkBwBQAAgCsQXAEAAOAKBFcAAAC4AsEVAAAArkBwBQAAgCsQXAEAAOAKBFcAAAC4AlfOAgAAgLfVq0UsSyQsTJyE4AoAAABv5cuLE1EqAAAAAFcguAIAAMAVKBUAAACAt9GjRQ4eFImOFhkwQJyC4AoAAICswTUxUSQ21lHBlVIBAAAAuALBFQAAAK5AcAUAAIArEFwBAADgCgRXAAAAuALBFQAAAK5AcAUAAIArEFwBAADgClyAAAAAAN5athSJixOpWlWchOAKAAAAbzNnihNRKgAAAABXILgCAADAFQiuAAAAcAVqXAEAAODtxhtFkpJOnpzloHpXgisAAAC8LVsmkpgoEhsrTkKpAAAAAFyB4AoAAABXILgCAADAFQiuAAAAcAVXBNe33npL6tWrJ6VLl5bzzz9fFi9eHOomAQAAIMgcH1w//vhjGTBggAwZMkSWLVsmLVq0kLZt28ru3btD3TQAAAAEkeOD6+jRo+X++++X7t27S9OmTWXChAlSpkwZmTx5cqibBgAAgCBy9DyuaWlpkpCQIIMHD854LDw8XK666ipZuHChz9ekpqaam+3AgQPm5/79+yU9Pd3cDh48KKVKlTLr8rdDhw5JWFiYHNu1XuRYis9lTvy7Lddl8rqcv5ZxyrrCw0RSUktLalKKpFtFf18Fe3vHTi2j/670s5qddevWZbsuu4/0OV1G16P/vuAMgf6OQ+HRR85G/5wUlp4uYSJipaeLFYTveN3nyrKsnBe0HCwxMVFbby1YsMDr8YEDB1qtWrXy+ZohQ4aY13Djxo0bN27cuHETV922bt2aYzZ09IhrQejorNbEev7l9O+//0qVKlXM6JAm+ri4ONm6datER0eHtK3Iiv5xPvrI2egf56OPnI3+CQ0dadUjeLVq1cpxOUcH15iYGClRooTs2rXL63G9X6NGDZ+viYyMNDdPFStWzLKcfhj5QDoX/eN89JGz0T/ORx85G/0TfBUqVMh1GUcXb2h9SXx8vMydO9drBFXvX3jhhSFtGwAAAILL0SOuSg/7d+vWTc4991xp1aqVjBkzRg4fPmxmGQAAAEDx4fjgevvtt0tSUpI8++yzsnPnTjn77LPl22+/lerVqxdofVpGoHPCZi4ngDPQP85HHzkb/eN89JGz0T/OFqZnaIW6EQAAAICra1wBAAAAG8EVAAAArkBwBQAAgCsQXAEAAOAKRTK4vvXWW1KvXj0pXbq0nH/++bJ48eI8vW769Onm6lodO3YMeBuLs/z0z9SpU02feN70dXDWv6H9+/dLnz59pGbNmuZM3IYNG8rXX38dtPYWN/npn8svvzzLvyG9tW/fPqhtLk7y++9Hp3ls1KiRREVFmSs2PfLII5KSkhK09hZH+emjY8eOyfPPPy+nn366Wb5FixZmdiOEiFXETJ8+3SpVqpQ1efJka9WqVdb9999vVaxY0dq1a1eOr9u0aZMVGxtrXXLJJVaHDh2C1t7iJr/9M2XKFCs6OtrasWNHxm3nzp1Bb3dxkt8+Sk1Ntc4991yrXbt21vz5882/pXnz5lnLly8PetuLg/z2z969e73+/axcudIqUaKE+beF0PfPtGnTrMjISPNT/+3Mnj3bqlmzpvXII48Eve3FRX77aNCgQVatWrWsr776ytqwYYM1btw4q3Tp0tayZcuC3nZYVpELrq1atbL69OmTcf/EiRPmAzdixIhsX3P8+HHroosust555x2rW7duBFcH9Y/+cq1QoUIQW4j89tH48eOt0047zUpLSwtiK4uvgnzHeXrttdes8uXLW8nJyQFsZfGV3/7RZa+44gqvxwYMGGC1bt064G0trvLbR/qHxJtvvun1WKdOnawuXboEvK3IqkiVCqSlpUlCQoJcddVVGY+Fh4eb+wsXLsz2dXoIoFq1atKjR48gtbR4Kmj/JCcnS926dc0htA4dOsiqVauC1OLipyB9NHPmTHMJZi0V0AuDNG/eXF588UU5ceJEEFtePBT035Cnd999V+644w4pW7ZsAFtaPBWkfy666CLzGvtQ9caNG02ZTbt27YLW7uKkIH2UmpqapURNyzrmz58f8PYiqyIVXPfs2WN+WWa+qpbe16tu+aIfPP0inzRpUpBaWXwVpH+07mvy5Mny5ZdfygcffCDp6enmi37btm1BanXxUpA+0l+0n376qXmd/sJ95plnZNSoUTJ8+PAgtbr4KEj/eNJwtHLlSrnvvvsC2MriqyD907lzZzN4cvHFF0tERISpo9S65CeffDJIrS5eCtJHbdu2ldGjR8vff/9tfgfNmTNHPv/8c9mxY0eQWo0iG1zz69ChQ3LXXXeZ0BoTExPq5sAHHcm7++67zaV+L7vsMvNlUbVqVZk4cWKom4ZT9Itcj1i8/fbbEh8fby7T/NRTT8mECRNC3TRkon+kn3nmmdKqVatQNwWnzJs3zxyhGDdunCxbtsx8x3311VcybNiwUDcNp4wdO1bOOOMMady4sZQqVUoeeugh6d69uxmpRfCVlCJEw2eJEiVk165dXo/r/Ro1amRZfsOGDfLPP//IDTfc4PVLWJUsWVLWrl1r/vpFaPrHFx2ROOecc2T9+vUBamXxVpA+0pkEtF/0dbYmTZqY0Qs9LKdf9Aj9v6HDhw+bmVN0dA/O6R89QqEDKPYouP5hoX3Vs2dP8wcg4Sj0faSDJf/973/NTA979+6VWrVqyRNPPCGnnXZakFoNT0XqX4T+gtQRn7lz53oFUb2vI3eZ6V9Pf/75pyxfvjzjduONN0qbNm3M/2tNJULXP77oIR7tMw1LcEYftW7d2vwhYf/Rp9atW2f6iNDqnH9DM2bMMLV6Xbt2DUJLi6eC9M+RI0eyhFP7j0A9gRrO+Tekda6xsbFy/Phx+eyzz8w5FwgBqwhOc6FTi0ydOtX666+/rJ49e5ppLuwplO666y7riSeeyPb1zCrgrP4ZOnSomR5GpyBJSEiw7rjjDjMNiU5hAmf00ZYtW8xZ6g899JC1du1aa9asWVa1atWs4cOHh/BdFF0F/Y67+OKLrdtvvz0ELS5e8ts/Q4YMMf9+PvroI2vjxo3Wd999Z51++unWbbfdFsJ3UbTlt48WLVpkffbZZ+b30M8//2xmgahfv761b9++EL6L4qtIlQoora9LSkqSZ5991hyq1NpInSjYLsTesmULh15c1D/79u2T+++/3yxbqVIl85fyggULpGnTpiF8F0VbfvtIj0zMnj3bTJp+1llnmRGJfv36yeOPPx7Cd1F0FeQ7Tsue9ETU7777LkStLj7y2z9PP/20uSCE/kxMTDSHpbV87YUXXgjhuyja8ttHWiKg/aMnopYrV87M+PCf//xHKlasGMJ3UXyFaXoNdSMAAACA3DD0CAAAAFcguAIAAMAVCK4AAABwBYIrAAAAXIHgCgAAAFcguAIAAMAVCK4AAABwBYIrAAAAXIHgCgAAAFcguAIo8u655x5zWU29RURESP369WXQoEHmUo6ZzZo1Sy677DIpX768lClTRs477zyZOnWqz/V+9tlncvnll0uFChXMpSD1krfPP/+8/Pvvv7m2qVevXlKiRAmZMWOGz/Z27Ngxy+Pz5s0z72H//v0Zj6Wlpckrr7wiLVq0MO2NiYmR1q1by5QpU+TYsWPZbn/SpEnmNdpuvXTlOeecIyNGjMi13QAQSgRXAMXCtddeKzt27DDXG3/ttddk4sSJMmTIEK9l3njjDenQoYMJfr/99pv88ccfcscdd8gDDzwgjz32mNeyTz31lLnmuQbbb775RlauXCmjRo2SFStWmOuY5+TIkSMyffp0E54nT55c4PekobVt27by0ksvSc+ePWXBggWyePFi6dOnj3kvq1at8vk63Wb//v2lb9++snz5cvn1119NW5KTkwvclry0FQAKzQKAIq5bt25Whw4dvB7r1KmTdc4552Tc37JlixUREWENGDAgy+tff/11S78uFy1aZO7/9ttv5v6YMWN8bm/fvn05tmfq1KnWBRdcYO3fv98qU6aM2XZu7VU//vij2a69/pdfftkKDw+3li1blmXZtLQ0Kzk52ef2dd333HOPlZt3333Xatq0qVWqVCmrRo0aVp8+fTKe27x5s3XjjTdaZcuWtcqXL2/deuut1s6dOzOeHzJkiNWiRQtr0qRJVr169aywsLCMfdOjRw8rJibGvK5NmzbW8uXLc20LAChGXAEUOzo6qqOTpUqVynjs008/NYfWM4+s2of19ZD6Rx99ZO5PmzbN3O/du7fP9euh95y8++670rVrV1NicN1112VbipAbbcdVV11lDvNnpiURZcuW9fm6GjVqyKJFi2Tz5s3Zrnv8+PFm5FZHcv/880+ZOXOmNGjQwDyXnp5uRqa1JOKnn36SOXPmmJFsHYH2tH79elNO8fnnn5uRXXXrrbfK7t27zSh1QkKCtGzZUq688so8lVcAACOuAIo8HcEsUaKEGR2MjIw0o5Y6Uvnpp59mLPPAAw9YFSpUyHYdZ511lnXdddeZ/9efer8g1q1bZ0Z2k5KSzP0vvvjCql+/vpWenp7vEdeoqCirb9+++W7D9u3bzYivrqthw4Zmex9//LF14sSJjGVq1aplPfXUUz5f/91335n96TlSvGrVKrO+xYsXZ4y46vvcvXt3xjK//PKLFR0dbaWkpHit7/TTT7cmTpyY7/cBoPhhxBVAsdCmTRsz6qe1q926dZPu3bvLzTffXKB1WZZmtILR+lKtS9WTqFS7du3kwIED8sMPPwStHTVr1pSFCxeakdR+/frJ8ePHzT7ROmAdTdUR0e3bt5uRUF9Wr14tcXFx5mZr2rSpGWnW52x169aVqlWrZtzX+l+to61SpYoZsbZvmzZtkg0bNhTovQAoXkqGugEAEAx62Nw+1K3hUc+o10P2PXr0MI81bNjQBEgNbLVq1cpyYpEGKw2/9rLz5883pQV6SD6vTpw4Ie+9957s3LlTSpYs6fW4tskOitHR0T4P4+tsAjoTgV0CoO1Ys2aNFFTz5s3NTUse9AS0Sy65xBz6P/fcc8UfMpcqaGjV0KyzI+S3vAIAFCOuAIqd8PBwefLJJ+Xpp5+Wo0ePmsd09FVDqM4MkNmECRPk8OHDcuedd5r7nTt3NiFs3LhxPtfvOV2Vp6+//loOHTokv//+uxn9tW9aO6t1oPbrGjVqZGYESE1N9Xr9smXLzFRedljWdnz//fdmfZlpqNY255WOmCp9jU4FVq9ePZk7d67PZZs0aSJbt241N9tff/1l2m+vxxetZ7VDu/4R4XmzR6ABIEehrlUAgEDzVTN67NgxKzY21ho5cmTGY6+99pqpfX3yySet1atXW+vXr7dGjRpl6mIfffRRr9cPGjTI1HkOHDjQWrBggfXPP/9Y33//vXXLLbdkO9uAtuH222/P8rjWlupZ+2+++aa5rzWs1apVs2677TZr6dKl1t9//23O8Nez8MePH5/xOq0VveSSS6xKlSqZ1+rZ+Rs2bDD1qi1btrR+//13n+3Qet7nn3/emj9/vmn3woULrfbt21tVq1a19uzZkzHzQenSpa2xY8eautyEhAQzu4LSetyzzz7bbFsf11kW4uPjrcsuuyzLrAKe9HUXX3yxeXz27NnWpk2brF9//dXs7yVLluTQgwBwEsEVQJGX3clOI0aMMGHNc9qoL7/80gQyPZFLg5sGssmTJ/tcrwbESy+91ARKXV5P2NJA6Gs6LJ0qqmTJktYnn3zic10PPvig1/Rca9eutW666SZzkpSu255ayvMkLju86vs488wzTXsrV65stW7d2gRPDee+6Elp7dq1s2rWrGmmutJt3HzzzdYff/zhtdyECROsRo0amZOsdNmHH34439NhZXbw4EGzHt2mrjcuLs7q0qVLlinBAMAXM7FezmOyAAAAQOhR4woAAABXILgCAADAFQiuAAAAcAWCKwAAAFyB4AoAAABXILgCAADAFQiuAAAAcAWCKwAAAFyB4AoAAABXILgCAADAFQiuAAAAEDf4fxEdvuE2pYGqAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Corrected_Analysis.ipynb\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "from skimage import feature\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit, cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, confusion_matrix\n",
    "from sklearn.base import clone\n",
    "\n",
    "# --- Configuration ---\n",
    "IMAGES_DIR = \"all-mias\"\n",
    "META_PATH = \"data2.txt\"\n",
    "IMAGE_SIZE = 1024\n",
    "TARGET_ROI_SIZE = 256\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# --- 1. Data Loading and Preprocessing ---\n",
    "\n",
    "def load_and_prepare_data(images_dir, meta_path):\n",
    "    \"\"\"Loads metadata, finds images, and extracts consistent ROIs for all samples.\"\"\"\n",
    "    col_names = ['REFNUM', 'BG', 'CLASS', 'SEVERITY', 'X', 'Y', 'RADIUS']\n",
    "    df = pd.read_csv(meta_path, sep=\"\\\\s+\", names=col_names, header=None)\n",
    "    df['CANCER'] = df['SEVERITY'].apply(lambda x: 1 if x in ['B', 'M'] else 0)\n",
    "\n",
    "    # Calculate median radius from abnormal cases to use for normal cases\n",
    "    radii = pd.to_numeric(df[df['CANCER'] == 1]['RADIUS'], errors='coerce').dropna()\n",
    "    median_radius = int(radii.median())\n",
    "\n",
    "    all_rois = []\n",
    "    all_labels = []\n",
    "    all_groups = []\n",
    "\n",
    "    for filename in sorted(os.listdir(images_dir)):\n",
    "        if not filename.lower().endswith('.pgm'):\n",
    "            continue\n",
    "        \n",
    "        ref_num = os.path.splitext(filename)[0]\n",
    "        record = df[df['REFNUM'] == ref_num]\n",
    "        if record.empty:\n",
    "            continue\n",
    "\n",
    "        record = record.iloc[0]\n",
    "        full_path = os.path.join(images_dir, filename)\n",
    "        img_array = cv2.imread(full_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        label = record['CANCER']\n",
    "        patient_id = int(''.join(c for c in ref_num if c.isdigit())) // 2\n",
    "        \n",
    "        # Consistent ROI Extraction\n",
    "        x, y, r = record[['X', 'Y', 'RADIUS']]\n",
    "        \n",
    "        if label == 1 and all(pd.notna([x, y, r])):\n",
    "            cx, cy, cr = int(x), int(IMAGE_SIZE - float(y)), int(r)\n",
    "        else:\n",
    "            # For normal cases, take a crop from the center\n",
    "            cx, cy, cr = IMAGE_SIZE // 2, IMAGE_SIZE // 2, median_radius\n",
    "            \n",
    "        # Crop a square ROI and apply CLAHE\n",
    "        x0, y0 = max(0, cx - cr), max(0, cy - cr)\n",
    "        x1, y1 = min(IMAGE_SIZE, cx + cr), min(IMAGE_SIZE, cy + cr)\n",
    "        roi = img_array[y0:y1, x0:x1]\n",
    "\n",
    "        if roi.size == 0:\n",
    "            continue\n",
    "        \n",
    "        # Apply CLAHE to the ROI\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        roi_enhanced = clahe.apply(roi)\n",
    "        \n",
    "        # Resize to a fixed size for consistency\n",
    "        roi_resized = cv2.resize(roi_enhanced, (TARGET_ROI_SIZE, TARGET_ROI_SIZE), interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        all_rois.append(roi_resized)\n",
    "        all_labels.append(label)\n",
    "        all_groups.append(patient_id)\n",
    "        \n",
    "    print(f\"Successfully loaded and processed {len(all_rois)} images.\")\n",
    "    print(f\"Label distribution: {Counter(all_labels)}\")\n",
    "    return np.array(all_rois), np.array(all_labels), np.array(all_groups)\n",
    "\n",
    "# --- 2. Feature Extraction ---\n",
    "\n",
    "def extract_glcm_features(patch, distances=[1, 3, 5], angles=[0, np.pi/4, np.pi/2, 3*np.pi/4]):\n",
    "    \"\"\"Computes GLCM features for a single patch.\"\"\"\n",
    "    glcm = graycomatrix(patch, distances=distances, angles=angles, levels=256, symmetric=True, normed=True)\n",
    "    props = ['contrast', 'dissimilarity', 'homogeneity', 'ASM', 'energy', 'correlation']\n",
    "    feats = {}\n",
    "    for prop in props:\n",
    "        mat = graycoprops(glcm, prop)\n",
    "        feats[f'{prop}_mean'] = mat.mean()\n",
    "        feats[f'{prop}_var'] = mat.var()\n",
    "    return feats\n",
    "\n",
    "def extract_lbp_features(patch, P=8, R=3, G=6):\n",
    "    \"\"\"Computes pooled LBP histogram features.\"\"\"\n",
    "    lbp = feature.local_binary_pattern(patch, P, R, method='uniform')\n",
    "    n_bins = int(lbp.max() + 1)\n",
    "    hist, _ = np.histogram(lbp, density=True, bins=n_bins, range=(0, n_bins))\n",
    "    return hist\n",
    "\n",
    "def create_feature_matrix(rois, labels, groups):\n",
    "    \"\"\"Loops over all ROIs to build the final feature matrix.\"\"\"\n",
    "    records = []\n",
    "    for roi, label, grp in zip(rois, labels, groups):\n",
    "        # GLCM\n",
    "        glcm_feats = extract_glcm_features(roi)\n",
    "        # LBP\n",
    "        lbp_feats_hist = extract_lbp_features(roi)\n",
    "        lbp_feats = {f'lbp_{i}': val for i, val in enumerate(lbp_feats_hist)}\n",
    "        \n",
    "        # Combine features and metadata\n",
    "        all_feats = {**glcm_feats, **lbp_feats}\n",
    "        all_feats['label'] = label\n",
    "        all_feats['group'] = grp\n",
    "        records.append(all_feats)\n",
    "        \n",
    "    df = pd.DataFrame.from_records(records)\n",
    "    return df\n",
    "\n",
    "# --- 3. Model Training and Evaluation ---\n",
    "\n",
    "# Run the pipeline\n",
    "rois, labels, groups = load_and_prepare_data(IMAGES_DIR, META_PATH)\n",
    "feature_df = create_feature_matrix(rois, labels, groups)\n",
    "\n",
    "X = feature_df.drop(columns=['label', 'group']).values\n",
    "y = feature_df['label'].values\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Group-aware train/test split to prevent data leakage\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.25, random_state=RANDOM_STATE)\n",
    "train_idx, test_idx = next(gss.split(X_scaled, y, groups))\n",
    "\n",
    "X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
    "y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "# --- Model Training ---\n",
    "clf = RandomForestClassifier(n_estimators=300, random_state=RANDOM_STATE, class_weight='balanced')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# --- Evaluation ---\n",
    "y_pred = clf.predict(X_test)\n",
    "y_prob = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\n--- Model Evaluation on Held-Out Test Set ---\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC AUC Score: {roc_auc_score(y_test, y_prob):.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# --- 4. Permutation Test ---\n",
    "print(\"\\n--- Running Permutation Test (100 permutations) ---\")\n",
    "cv = GroupShuffleSplit(n_splits=5, test_size=0.25, random_state=RANDOM_STATE)\n",
    "score_real, _, _ = roc_auc_score(y_test, y_prob), None, None # Using held-out score as the real score\n",
    "\n",
    "n_permutations = 100\n",
    "perm_scores = []\n",
    "for i in range(n_permutations):\n",
    "    y_permuted = np.random.permutation(y)\n",
    "    # Using a simple CV for the permutation test for speed\n",
    "    perm_clf = clone(clf)\n",
    "    score = cross_val_score(perm_clf, X_scaled, y_permuted, cv=cv, groups=groups, scoring='roc_auc').mean()\n",
    "    perm_scores.append(score)\n",
    "    print(f\"Permutation {i+1}/{n_permutations}, Score: {score:.4f}\", end='\\\\r')\n",
    "\n",
    "p_value = (np.sum(np.array(perm_scores) >= score_real)) / n_permutations\n",
    "print(f\"\\\\nReal Model ROC AUC: {score_real:.4f}\")\n",
    "print(f\"Permutation Scores Mean: {np.mean(perm_scores):.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "if p_value < 0.05:\n",
    "    print(\"Result is statistically significant.\")\n",
    "else:\n",
    "    print(\"Result is not statistically significant.\")\n",
    "\n",
    "# Plot permutation scores\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(perm_scores, bins=20, label='Permutation Scores', edgecolor='k')\n",
    "plt.axvline(score_real, color='red', linestyle='--', linewidth=2, label=f'Real Score (p={p_value:.4f})')\n",
    "plt.title(\"Permutation Test Results\")\n",
    "plt.xlabel(\"ROC AUC Score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e71556b-6e65-4118-8da6-865bfd14b9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing images...\n",
      "Loaded 648 images (including augmented).\n",
      "Training set size: 516 (after augmentation)\n",
      "Test set size: 66 (original images only)\n",
      "\n",
      "Extracting features for training and test sets...\n",
      "\n",
      "--- Starting Hyperparameter Tuning ---\n",
      "\n",
      "Tuning RandomForest...\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Best Score (AUC) for RandomForest: 0.9199\n",
      "Best Params for RandomForest: {'clf__max_depth': 10, 'clf__min_samples_leaf': 1, 'clf__n_estimators': 500, 'select__k': 40}\n",
      "\n",
      "Tuning SVM...\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Best Score (AUC) for SVM: 0.9140\n",
      "Best Params for SVM: {'clf__C': 100, 'clf__gamma': 0.001, 'select__k': 40}\n",
      "\n",
      "Tuning XGBoost...\n",
      "Fitting 4 folds for each of 81 candidates, totalling 324 fits\n",
      "Best Score (AUC) for XGBoost: 0.9312\n",
      "Best Params for XGBoost: {'clf__learning_rate': 0.1, 'clf__max_depth': 7, 'clf__n_estimators': 100, 'select__k': 40}\n",
      "\n",
      "--- Final Model Evaluation on Held-Out Test Set ---\n",
      "\n",
      "--- Results for Best RandomForest ---\n",
      "Accuracy: 0.8333\n",
      "ROC AUC Score: 0.8604\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.79      0.97      0.87        39\n",
      "      Cancer       0.94      0.63      0.76        27\n",
      "\n",
      "    accuracy                           0.83        66\n",
      "   macro avg       0.87      0.80      0.81        66\n",
      "weighted avg       0.85      0.83      0.83        66\n",
      "\n",
      "Confusion Matrix:\n",
      " [[38  1]\n",
      " [10 17]]\n",
      "\n",
      "--- Results for Best SVM ---\n",
      "Accuracy: 0.7576\n",
      "ROC AUC Score: 0.8367\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.76      0.87      0.81        39\n",
      "      Cancer       0.76      0.59      0.67        27\n",
      "\n",
      "    accuracy                           0.76        66\n",
      "   macro avg       0.76      0.73      0.74        66\n",
      "weighted avg       0.76      0.76      0.75        66\n",
      "\n",
      "Confusion Matrix:\n",
      " [[34  5]\n",
      " [11 16]]\n",
      "\n",
      "--- Results for Best XGBoost ---\n",
      "Accuracy: 0.8030\n",
      "ROC AUC Score: 0.8765\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.77      0.95      0.85        39\n",
      "      Cancer       0.89      0.59      0.71        27\n",
      "\n",
      "    accuracy                           0.80        66\n",
      "   macro avg       0.83      0.77      0.78        66\n",
      "weighted avg       0.82      0.80      0.79        66\n",
      "\n",
      "Confusion Matrix:\n",
      " [[37  2]\n",
      " [11 16]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aa23147\\AppData\\Roaming\\Python\\Python312\\site-packages\\xgboost\\training.py:183: UserWarning: [20:56:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Improved_LBP_GLCM_Pipeline.ipynb\n",
    "#\n",
    "# This script improves upon the robust structure of Method2 by adding\n",
    "# data augmentation, a more powerful XGBoost classifier, and a more\n",
    "# comprehensive hyperparameter search to maximize performance with LBP/GLCM features.\n",
    "#\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Scikit-learn and XGBoost imports\n",
    "from skimage import feature\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GroupKFold, GroupShuffleSplit, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "\n",
    "# --- Configuration ---\n",
    "IMAGES_DIR = \"all-mias\"\n",
    "META_PATH = \"data2.txt\"\n",
    "IMAGE_SIZE = 1024\n",
    "TARGET_ROI_SIZE = 128\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# CV and Split Configuration\n",
    "HOLDOUT_TEST_SIZE = 0.2\n",
    "INNER_CV_SPLITS = 4 # K-fold for grid search\n",
    "\n",
    "# --- 1. Data Loading and Preprocessing with Augmentation ---\n",
    "\n",
    "def load_and_prepare_data(images_dir, meta_path, augment_train=True):\n",
    "    \"\"\"Loads metadata and extracts ROIs. Includes an option for horizontal flip augmentation.\"\"\"\n",
    "    col_names = ['REFNUM', 'BG', 'CLASS', 'SEVERITY', 'X', 'Y', 'RADIUS']\n",
    "    df = pd.read_csv(meta_path, sep=\"\\\\s+\", names=col_names, header=None)\n",
    "    df['CANCER'] = df['SEVERITY'].apply(lambda x: 1 if x in ['B', 'M'] else 0)\n",
    "    radii = pd.to_numeric(df[df['CANCER'] == 1]['RADIUS'], errors='coerce').dropna()\n",
    "    median_radius = int(radii.median())\n",
    "\n",
    "    data = [] # Store tuples of (roi, label, group, is_augmented)\n",
    "\n",
    "    print(\"Loading and preprocessing images...\")\n",
    "    for filename in sorted(os.listdir(images_dir)):\n",
    "        if not filename.lower().endswith('.pgm'):\n",
    "            continue\n",
    "        \n",
    "        ref_num = os.path.splitext(filename)[0]\n",
    "        record = df[df['REFNUM'] == ref_num]\n",
    "        if record.empty: continue\n",
    "\n",
    "        record = record.iloc[0]\n",
    "        full_path = os.path.join(images_dir, filename)\n",
    "        img_array = cv2.imread(full_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        label = record['CANCER']\n",
    "        patient_id = int(''.join(c for c in ref_num if c.isdigit())) // 2 if ref_num[3:].isdigit() else ref_num\n",
    "\n",
    "        x, y, r = record[['X', 'Y', 'RADIUS']]\n",
    "        if label == 1 and all(pd.notna([x, y, r])):\n",
    "            cx, cy, cr = int(x), int(IMAGE_SIZE - float(y)), int(r)\n",
    "        else:\n",
    "            cx, cy, cr = IMAGE_SIZE // 2, IMAGE_SIZE // 2, median_radius\n",
    "            \n",
    "        x0, y0 = max(0, cx - cr), max(0, cy - cr)\n",
    "        x1, y1 = min(IMAGE_SIZE, cx + cr), min(IMAGE_SIZE, cy + cr)\n",
    "        roi = img_array[y0:y1, x0:x1]\n",
    "\n",
    "        if roi.size == 0: continue\n",
    "        \n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        roi_enhanced = clahe.apply(roi)\n",
    "        roi_resized = cv2.resize(roi_enhanced, (TARGET_ROI_SIZE, TARGET_ROI_SIZE), interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        data.append({'roi': roi_resized, 'label': label, 'group': patient_id, 'is_augmented': False})\n",
    "\n",
    "        # *** IMPROVEMENT: DATA AUGMENTATION ***\n",
    "        # Add a horizontally flipped version of the ROI\n",
    "        if augment_train:\n",
    "            roi_flipped = cv2.flip(roi_resized, 1)\n",
    "            data.append({'roi': roi_flipped, 'label': label, 'group': patient_id, 'is_augmented': True})\n",
    "\n",
    "    print(f\"Loaded {len(data)} images (including augmented).\")\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# --- 2. Feature Extraction (LBP + GLCM) ---\n",
    "\n",
    "# CORRECTED FUNCTION\n",
    "\n",
    "def extract_features(roi):\n",
    "    \"\"\"Extracts a combined feature vector of LBP and GLCM for a single ROI.\"\"\"\n",
    "    # LBP Features\n",
    "    P, R, G = 8, 3, 3 # Points, Radius, Grid size\n",
    "    lbp = feature.local_binary_pattern(roi, P, R, method='uniform')\n",
    "    \n",
    "    # --- FIX ---\n",
    "    # Use a fixed number of bins for uniform LBP (P + 2)\n",
    "    n_bins = P + 2 \n",
    "    # --- END FIX ---\n",
    "    \n",
    "    # Pooled histogram\n",
    "    H, W = lbp.shape\n",
    "    h_step, w_step = H // G, W // G\n",
    "    lbp_hist = []\n",
    "    for i in range(G):\n",
    "        for j in range(G):\n",
    "            region = lbp[i*h_step:(i+1)*h_step, j*w_step:(j+1)*w_step]\n",
    "            # Use fixed n_bins and range\n",
    "            hist, _ = np.histogram(region.ravel(), bins=n_bins, range=(0, n_bins))\n",
    "            lbp_hist.extend(hist)\n",
    "    lbp_features = np.array(lbp_hist, dtype=float)\n",
    "\n",
    "    # GLCM Features\n",
    "    glcm = graycomatrix(roi, distances=[1, 3], angles=[0, np.pi/4, np.pi/2], levels=256, symmetric=True, normed=True)\n",
    "    props = ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation', 'ASM']\n",
    "    glcm_features = []\n",
    "    for prop in props:\n",
    "        glcm_features.extend(graycoprops(glcm, prop).ravel())\n",
    "        \n",
    "    # Combine and return\n",
    "    return np.concatenate([lbp_features, glcm_features])\n",
    "# --- 3. Model Training and Evaluation Pipeline ---\n",
    "\n",
    "# Step 1: Load data\n",
    "full_dataset = load_and_prepare_data(IMAGES_DIR, META_PATH, augment_train=True)\n",
    "\n",
    "# Step 2: Group-aware train/test split (BEFORE feature extraction and augmentation handling)\n",
    "# We split based on original images to ensure augmented versions stay with their originals.\n",
    "original_indices = full_dataset[full_dataset['is_augmented'] == False].index\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=HOLDOUT_TEST_SIZE, random_state=RANDOM_STATE)\n",
    "train_idx_orig, test_idx_orig = next(gss.split(original_indices, groups=full_dataset.loc[original_indices, 'group']))\n",
    "\n",
    "# Get the full training set (originals + their augmented pairs)\n",
    "train_groups = full_dataset.loc[original_indices[train_idx_orig], 'group'].unique()\n",
    "train_df = full_dataset[full_dataset['group'].isin(train_groups)]\n",
    "\n",
    "# The test set contains ONLY original, non-augmented images\n",
    "test_df = full_dataset.loc[original_indices[test_idx_orig]]\n",
    "\n",
    "print(f\"Training set size: {len(train_df)} (after augmentation)\")\n",
    "print(f\"Test set size: {len(test_df)} (original images only)\")\n",
    "\n",
    "# Step 3: Extract features for train and test sets\n",
    "print(\"\\nExtracting features for training and test sets...\")\n",
    "X_train = np.array([extract_features(roi) for roi in train_df['roi']])\n",
    "y_train = train_df['label'].values\n",
    "groups_train = train_df['group'].values\n",
    "\n",
    "X_test = np.array([extract_features(roi) for roi in test_df['roi']])\n",
    "y_test = test_df['label'].values\n",
    "\n",
    "# Step 4: Define pipelines and hyperparameter grids\n",
    "scaler = StandardScaler()\n",
    "selector = SelectKBest(mutual_info_classif)\n",
    "\n",
    "# Pipeline definitions\n",
    "rf_pipeline = Pipeline([('scaler', scaler), ('select', selector), ('clf', RandomForestClassifier(random_state=RANDOM_STATE, class_weight='balanced'))])\n",
    "svm_pipeline = Pipeline([('scaler', scaler), ('select', selector), ('clf', SVC(probability=True, random_state=RANDOM_STATE, class_weight='balanced'))])\n",
    "xgb_pipeline = Pipeline([('scaler', scaler), ('select', selector), ('clf', XGBClassifier(random_state=RANDOM_STATE, use_label_encoder=False, eval_metric='logloss'))])\n",
    "\n",
    "\n",
    "# *** IMPROVEMENT: Expanded Hyperparameter Grids ***\n",
    "rf_params = {\n",
    "    'select__k': [40, 80, 120],\n",
    "    'clf__n_estimators': [100, 250, 500],\n",
    "    'clf__max_depth': [5, 10, 20, None],\n",
    "    'clf__min_samples_leaf': [1, 3, 5]\n",
    "}\n",
    "\n",
    "svm_params = {\n",
    "    'select__k': [40, 80, 120],\n",
    "    'clf__C': [0.1, 1, 10, 100],\n",
    "    'clf__gamma': ['scale', 0.01, 0.001]\n",
    "}\n",
    "\n",
    "xgb_params = {\n",
    "    'select__k': [40, 80, 120],\n",
    "    'clf__n_estimators': [100, 250, 500],\n",
    "    'clf__max_depth': [3, 5, 7],\n",
    "    'clf__learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "pipelines = {\n",
    "    'RandomForest': (rf_pipeline, rf_params),\n",
    "    'SVM': (svm_pipeline, svm_params),\n",
    "    'XGBoost': (xgb_pipeline, xgb_params) # *** IMPROVEMENT: Added XGBoost ***\n",
    "}\n",
    "\n",
    "# Step 5: Run GridSearchCV for each model\n",
    "print(\"\\n--- Starting Hyperparameter Tuning ---\")\n",
    "best_estimators = {}\n",
    "inner_cv = GroupKFold(n_splits=INNER_CV_SPLITS)\n",
    "\n",
    "for name, (pipeline, params) in pipelines.items():\n",
    "    print(f\"\\nTuning {name}...\")\n",
    "    gs = GridSearchCV(pipeline, params, cv=inner_cv.split(X_train, y_train, groups_train), scoring='roc_auc', n_jobs=-1, verbose=1)\n",
    "    gs.fit(X_train, y_train)\n",
    "    best_estimators[name] = gs.best_estimator_\n",
    "    print(f\"Best Score (AUC) for {name}: {gs.best_score_:.4f}\")\n",
    "    print(f\"Best Params for {name}: {gs.best_params_}\")\n",
    "\n",
    "# Step 6: Evaluate the best models on the held-out test set\n",
    "print(\"\\n--- Final Model Evaluation on Held-Out Test Set ---\")\n",
    "for name, model in best_estimators.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    print(f\"\\n--- Results for Best {name} ---\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"ROC AUC Score: {roc_auc_score(y_test, y_prob):.4f}\")\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=[\"Normal\", \"Cancer\"]))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e90909ca-2376-4610-9068-41f0231e37e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard & third-party libraries\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from scipy.stats import skew\n",
    "from skimage.feature import local_binary_pattern, graycomatrix, graycoprops\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.model_selection import GroupKFold, GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, recall_score, confusion_matrix, classification_report, roc_auc_score\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "623c9dfd-bc7c-4976-af76-f8f2989cb95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_metadata(meta_path):\n",
    "    meta = pd.read_csv(meta_path, delim_whitespace=True, dtype=str)\n",
    "    meta.columns = [c.strip().upper() for c in meta.columns]\n",
    "    if 'SEVERITY' in meta.columns:\n",
    "        meta['CANCER'] = meta['SEVERITY'].map({'B': 1, 'M': 1}).fillna(0).astype(int)\n",
    "    elif 'CLASS' in meta.columns:\n",
    "        meta['CANCER'] = meta['CLASS'].map({'B': 1, 'M': 1}).fillna(0).astype(int)\n",
    "    else:\n",
    "        raise ValueError(\"Missing CLASS or SEVERITY column for cancer label.\")\n",
    "    meta['RADIUS'] = pd.to_numeric(meta['RADIUS'], errors='coerce')\n",
    "    meta['X'] = pd.to_numeric(meta['X'], errors='coerce')\n",
    "    meta['Y'] = pd.to_numeric(meta['Y'], errors='coerce')\n",
    "    meta['patient_id'] = meta['REFNUM'].str.extract(r'([a-zA-Z]+)')[0]\n",
    "    return meta\n",
    "\n",
    "\n",
    "def preprocess_img(img, target_size=1024, min_side=32):\n",
    "    h, w = img.shape\n",
    "    if min(h, w) < min_side:\n",
    "        return None\n",
    "    scale = target_size / min(h, w)\n",
    "    new_h, new_w = int(h * scale), int(w * scale)\n",
    "    img_resized = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "    return img_resized\n",
    "\n",
    "\n",
    "def roi_from_row(img, row, fallback_radius=32, target_size=64):\n",
    "    x, y = row['X'], row['Y']\n",
    "    radius = row['RADIUS']\n",
    "    if pd.isna(radius):\n",
    "        radius = fallback_radius\n",
    "    r = int(radius)\n",
    "    x, y = int(x), int(y)\n",
    "    roi = img[max(0, y - r): y + r, max(0, x - r): x + r]\n",
    "    roi_resized = cv2.resize(roi, (target_size, target_size), interpolation=cv2.INTER_AREA)\n",
    "    return roi_resized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18d3fea6-4a9b-4fb3-a559-9786ab456bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_glcm_features(roi, levels=32, distances=[1], angles=[0]):\n",
    "    roi_scaled = (roi / (256 / levels)).astype(np.uint8)\n",
    "    glcm = graycomatrix(roi_scaled, distances=distances, angles=angles, levels=levels, symmetric=True, normed=True)\n",
    "    feats = {\n",
    "        'contrast': graycoprops(glcm, 'contrast').mean(),\n",
    "        'dissimilarity': graycoprops(glcm, 'dissimilarity').mean(),\n",
    "        'homogeneity': graycoprops(glcm, 'homogeneity').mean(),\n",
    "        'energy': graycoprops(glcm, 'energy').mean(),\n",
    "        'correlation': graycoprops(glcm, 'correlation').mean(),\n",
    "        'ASM': graycoprops(glcm, 'ASM').mean(),\n",
    "    }\n",
    "    return feats\n",
    "\n",
    "\n",
    "def compute_lbp_hist(roi, P=8, R=1, bins=59):\n",
    "    lbp = local_binary_pattern(roi, P, R, method='uniform')\n",
    "    hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, bins + 1), range=(0, bins))\n",
    "    hist = hist.astype(float)\n",
    "    hist /= (hist.sum() + 1e-6)\n",
    "    return {f'lbp_{i}': h for i, h in enumerate(hist)}\n",
    "\n",
    "\n",
    "def intensity_stats(roi):\n",
    "    return {\n",
    "        'mean': np.mean(roi),\n",
    "        'std': np.std(roi),\n",
    "        'skew': skew(roi.flatten())\n",
    "    }\n",
    "\n",
    "\n",
    "def convert(feat_dicts):\n",
    "    all_keys = sorted({k for d in feat_dicts for k in d})\n",
    "    X = np.array([[d.get(k, 0) for k in all_keys] for d in feat_dicts])\n",
    "    return X, all_keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0893076a-6f70-4866-b1e1-32ff1ab95567",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, y_true, y_pred, y_prob):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    rec = recall_score(y_true, y_pred)\n",
    "    auc = roc_auc_score(y_true, y_prob)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(f\"=== Held-out evaluation: {name} ===\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"Recall: {rec:.4f}\")\n",
    "    print(f\"AUC: {auc:.4f}\")\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "    print(classification_report(y_true, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
